{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashleyssssss/wildfire-prediction/blob/main/Modification_Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soIQNSPwB0Lp",
        "outputId": "4e048ba9-e9d5-4362-b27a-b6788de1efe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.19.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from rioxarray) (24.2)\n",
            "Collecting rasterio>=1.4.3 (from rioxarray)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: xarray>=2024.7.0 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2025.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3->rioxarray) (2025.4.26)\n",
            "Collecting affine (from rasterio>=1.4.3->rioxarray)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.4.3->rioxarray) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.4.3->rioxarray) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio>=1.4.3->rioxarray)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio>=1.4.3->rioxarray)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.4.3->rioxarray) (3.2.3)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray>=2024.7.0->rioxarray) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray>=2024.7.0->rioxarray) (1.17.0)\n",
            "Downloading rioxarray-0.19.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio, rioxarray\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3 rioxarray-0.19.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install rioxarray\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "data = np.load(\"/content/drive/MyDrive/NEW_MODIS_Combined/new_data.npz\")\n",
        "X = data[\"X\"]\n",
        "y = data[\"y\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Conv2DTranspose, Concatenate, ZeroPadding2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, Activation,\n",
        "    UpSampling2D, Concatenate, ZeroPadding2D, Layer\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "class ResizeLayer(Layer):\n",
        "    def call(self, input):\n",
        "        input_tensor, target_tensor = input\n",
        "        target_height = tf.shape(target_tensor)[1]\n",
        "        target_width = tf.shape(target_tensor)[2]\n",
        "        return tf.image.resize(input_tensor, [target_height, target_width])\n",
        "\n",
        "def decoder_block(input_tensor, skip_tensor, num_filters):\n",
        "    x = ResizeLayer()([input_tensor, skip_tensor])\n",
        "    x = Concatenate()([x, skip_tensor])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_resnetv2_unet(input_shape=(128, 128, 3)):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained ResNetV2 Encoder \"\"\"\n",
        "    base_model = ResNet50V2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    # Encoder feature maps (you can verify with model.summary())\n",
        "    s1 = base_model.get_layer(\"conv1_conv\").output       # 64x64\n",
        "    s2 = base_model.get_layer(\"conv2_block3_out\").output # 32x32\n",
        "    s3 = base_model.get_layer(\"conv3_block4_out\").output # 16x16\n",
        "    s4 = base_model.get_layer(\"conv4_block6_out\").output # 8x8\n",
        "    b1 = base_model.get_layer(\"conv5_block3_out\").output # 4x4 (bridge)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)  # 4→8\n",
        "    d2 = decoder_block(d1, s3, 256)  # 8→16\n",
        "    d3 = decoder_block(d2, s2, 128)  # 16→32\n",
        "    d4 = decoder_block(d3, s1, 64)   # 32→64\n",
        "\n",
        "    # Final upsampling to match input 128x128\n",
        "    x = UpSampling2D((2, 2))(d4)     # 64→128\n",
        "    x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "    # outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(x)\n",
        "    outputs = Conv2D(4, 1, padding=\"same\", activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"ResNetV2_U-Net\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8-I1Az9RCJQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X.shape[1:]\n",
        "model = build_resnetv2_unet(input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUoAtNY4CLYN",
        "outputId": "6bce52f5-a9d6-421d-9d40-92fb045fe90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true = tf.one_hot(y_true, depth=4)  # Convert to one-hot\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
        "\n",
        "        # Calculate focal loss\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "        weight = alpha * K.pow(1. - y_pred, gamma)\n",
        "        focal_loss = weight * cross_entropy\n",
        "\n",
        "        return K.mean(focal_loss)\n",
        "    return loss\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    # y_true: integer labels (sparse) [batch, H, W]\n",
        "    # y_pred: probabilities [batch, H, W, num_classes]\n",
        "    y_true = K.cast(y_true, 'int32')\n",
        "    y_true_one_hot = K.one_hot(y_true, num_classes=4)  # Convert to one-hot [batch, H, W, 4]\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "\n",
        "    # Compute intersection and union for each class\n",
        "    intersection = K.sum(y_true_one_hot * y_pred, axis=[1, 2])\n",
        "    union = K.sum(y_true_one_hot, axis=[1, 2]) + K.sum(y_pred, axis=[1, 2])\n",
        "\n",
        "    # Dice score per class, averaged over batch\n",
        "    dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "    return K.mean(dice)  # Average over classes\n",
        "\n",
        "\n",
        "def hybrid_loss(alpha=0.5):\n",
        "    \"\"\"\n",
        "    Combines categorical focal loss and dice loss.\n",
        "    alpha: weight for focal loss (1 - alpha for dice loss)\n",
        "    \"\"\"\n",
        "    fl = focal_loss(alpha=0.25, gamma=2.0)  # You can tune these if needed\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        focal = fl(y_true, y_pred)\n",
        "        dice = 1.0 - dice_coefficient(y_true, y_pred)  # Convert dice score to loss\n",
        "        return alpha * focal + (1 - alpha) * dice\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "OZJbHHxHCUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "]"
      ],
      "metadata": {
        "id": "FjOSmUQiCV-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import MeanIoU\n",
        "class MeanIoUMetric(tf.keras.metrics.MeanIoU):\n",
        "    def __init__(self, num_classes, name='mean_iou', **kwargs):\n",
        "        super().__init__(num_classes=num_classes, name=name, **kwargs)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        # No need to squeeze y_true if it's already shape (batch, H, W)\n",
        "        return super().update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=hybrid_loss(alpha=0.7),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=5, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av8x5UjoCZ4E",
        "outputId": "ca022702-1263-4648-d94b-e76f26e74a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 16s/step - accuracy: 0.8794 - loss: 0.2409 - learning_rate: 0.0010\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
            "  callback.on_epoch_end(epoch, logs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss,learning_rate\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 16s/step - accuracy: 0.9998 - loss: 0.2251 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m711s\u001b[0m 16s/step - accuracy: 0.9999 - loss: 0.2251 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 16s/step - accuracy: 0.9999 - loss: 0.2250 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 16s/step - accuracy: 0.9999 - loss: 0.2250 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ca12a863350>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-H2TKHKrJYV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}