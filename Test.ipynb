{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjkSAa1VOjHk",
        "outputId": "e802a86e-f931-4c62-e6f3-fac6b0a00f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.18.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from rioxarray) (24.2)\n",
            "Collecting rasterio>=1.3.7 (from rioxarray)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: xarray>=2024.7.0 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2025.1.2)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3->rioxarray) (2025.1.31)\n",
            "Collecting affine (from rasterio>=1.3.7->rioxarray)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio>=1.3.7->rioxarray)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio>=1.3.7->rioxarray)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (3.2.3)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray>=2024.7.0->rioxarray) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray>=2024.7.0->rioxarray) (1.17.0)\n",
            "Downloading rioxarray-0.18.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio, rioxarray\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3 rioxarray-0.18.2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install rioxarray\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "data = np.load(\"/content/drive/MyDrive/NEW_MODIS_Combined/new_data.npz\")\n",
        "X = data[\"X\"]\n",
        "y = data[\"y\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvY-A4nAVbbQ"
      },
      "source": [
        "# ONLY ONE PERSON NEEDS TO RUN THE CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq5yc5hpnkFb"
      },
      "source": [
        "## Fire Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtUFkTs5OWr3"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import rioxarray\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=\"ee-ashleys10125\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd39V2pOOXzN"
      },
      "outputs": [],
      "source": [
        "# Define the image collection and region\n",
        "roi = ee.Geometry.Rectangle([139.4462100998403, -39.517965336636436, 154.7391788498403,-30.46423194050125])\n",
        "\n",
        "start_date = '2023-11-01'\n",
        "end_date = '2024-01-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYrFI8Oe1tRf"
      },
      "outputs": [],
      "source": [
        "fire_ic = ee.ImageCollection(\"MODIS/061/MOD14A1\") \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(roi) \\\n",
        "    .select(\"FireMask\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-KmADMY3z5-"
      },
      "source": [
        "## Temperature Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lccuph7332Ea"
      },
      "outputs": [],
      "source": [
        "lst_ic = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(roi) \\\n",
        "    .select(\"LST_Day_1km\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_120696rxozT"
      },
      "source": [
        "## Spectral Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foIzaZ7xxnYC"
      },
      "outputs": [],
      "source": [
        "ref_ic = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(roi) \\\n",
        "    .select(['sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03'])  # Red, NIR, Blue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISMO6jfO4_Lw"
      },
      "source": [
        "## Combine and Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10qvW3BV5CzC"
      },
      "outputs": [],
      "source": [
        "def process_image(date_img):\n",
        "    img = ee.Image(date_img)\n",
        "\n",
        "    date = img.date()\n",
        "\n",
        "    # Match corresponding images from other collections\n",
        "    red_nir = ref_ic.filterDate(date, date.advance(1, 'day')).first()\n",
        "    fire = fire_ic.filterDate(date, date.advance(1, 'day')).first()\n",
        "    lst = lst_ic.filterDate(date, date.advance(1, 'day')).first()\n",
        "\n",
        "    # Compute NDVI\n",
        "    red = ee.Image(red_nir).select('sur_refl_b01').multiply(0.0001)\n",
        "    nir = ee.Image(red_nir).select('sur_refl_b02').multiply(0.0001)\n",
        "    blue = ee.Image(red_nir).select('sur_refl_b03').multiply(0.0001)\n",
        "    ndvi = nir.subtract(red).divide(nir.add(red)).rename(\"NDVI\")\n",
        "\n",
        "    #EVI (Enhanced Vegetation Index)\n",
        "    evi = nir.subtract(red).divide(nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1).multiply(2.5)).rename(\"EVI\")\n",
        "\n",
        "\n",
        "\n",
        "    # Combine all bands\n",
        "    combined = ee.Image.cat([ndvi, fire, lst, evi]) \\\n",
        "        .clip(roi) \\\n",
        "        .set('system:time_start', date.millis())\n",
        "\n",
        "    return combined\n",
        "\n",
        "# Use MOD14A1 as reference dates\n",
        "dates = fire_ic.toList(fire_ic.size())\n",
        "\n",
        "# Loop over images\n",
        "nimg = fire_ic.size().getInfo()\n",
        "\n",
        "for i in range(nimg):\n",
        "    img = ee.Image(dates.get(i))\n",
        "    date_str = img.date().format('yyyy-MM-dd').getInfo()\n",
        "\n",
        "    combined_img = process_image(img)\n",
        "\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=combined_img.toFloat(),\n",
        "        description=f\"combined_{date_str}\",\n",
        "        folder='NEW_MODIS_Combined',\n",
        "        fileNamePrefix=f\"combined_{date_str}\",\n",
        "        region=roi,\n",
        "        dimensions=(1024, 1024),\n",
        "        maxPixels=1e10\n",
        "    )\n",
        "    task.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9HIgLRdkq3Y"
      },
      "source": [
        "# Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcm-dnl5W_5c"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/NEW_MODIS_Combined/combined_2023-11-25.tif'\n",
        "# image = rioxarray.open_rasterio(file_path)\n",
        "# #image = rioxarray.open_rasterio('2024-01-01.tif')\n",
        "# dem = image[0] #getting the first band\n",
        "\n",
        "# dem.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPAst_D58rg8"
      },
      "source": [
        "### NDVI:\n",
        "+1 is health, 0 is rock or soil, -1 is water or snow\n",
        "\n",
        "### Fire Mask:\n",
        "\n",
        "\n",
        "1.   Not processed (obsolete; not used since Collection 1)\n",
        "2.   Not processed (other reason)\n",
        "3.   Non-fire water pixel\n",
        "4.   Cloud (land or water)\n",
        "5.   Non-fire land pixel\n",
        "6.   Unknown (land or water)\n",
        "7.   Fire (low confidence, land or water)\n",
        "8.   Fire (nominal confidence, land or water)\n",
        "9.   Fire (high confidence, land or water)\n",
        "\n",
        "### LST:\n",
        "Kelvin temperature, minimum value is 7500; maximum value is 65535.\n",
        "Scale is 0.02 (meaning actual temperature is value x 0.02)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "4PyNvyn87Xoc",
        "outputId": "8509cbe7-22db-4072-d3c4-7edaf6c91f99"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ndvi' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-92f17e8983ba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ndvi' is not defined"
          ]
        }
      ],
      "source": [
        "np.nanmean(ndvi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "E2oMDGeM7bM_",
        "outputId": "864daf1c-cc91-4516-a35c-fb0949ea95e3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'rasterio' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2aa0808c591a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of bands: {src.count}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CRS: {src.crs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Resolution: {src.res}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rasterio' is not defined"
          ]
        }
      ],
      "source": [
        "with rasterio.open(file_path) as src:\n",
        "    print(f\"Number of bands: {src.count}\")\n",
        "    print(f\"CRS: {src.crs}\")\n",
        "    print(f\"Resolution: {src.res}\")\n",
        "\n",
        "    # Read all bands into a NumPy array\n",
        "    bands = src.read()\n",
        "\n",
        "    # Read individual bands (1-based indexing)\n",
        "    ndvi = src.read(1)  # Band 1: NDVI\n",
        "    firemask = src.read(2)  # Band 2: FireMask\n",
        "    lst = src.read(3)  # Band 3: Land Surface Temp\n",
        "\n",
        "    fire_mask_cmap = mcolors.ListedColormap([\n",
        "        'white',    # 1: Not processed\n",
        "        'gray',     # 2: Not processed\n",
        "        'blue',     # 3: Non-fire water\n",
        "        'lightblue', # 4: Cloud\n",
        "        'green',    # 5: Non-fire land\n",
        "        'yellow',   # 6: Unknown\n",
        "        'orange',   # 7: Fire (low confidence)\n",
        "        'red',      # 8: Fire (nominal confidence)\n",
        "        'darkred'   # 9: Fire (high confidence)\n",
        "    ])\n",
        "    bounds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "\n",
        "# Plot the data\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# NDVI plot\n",
        "cax1 = axes[0].imshow(ndvi, cmap='YlGn', vmin=-1, vmax=1)\n",
        "axes[0].set_title(\"NDVI\")\n",
        "fig.colorbar(cax1, ax=axes[0], orientation='vertical', label=\"NDVI Value\")\n",
        "\n",
        "# Fire Mask plot\n",
        "cax2 = axes[1].imshow(firemask, cmap=fire_mask_cmap, vmin=1, vmax=9)\n",
        "axes[1].set_title(\"Fire Mask\")\n",
        "fig.colorbar(cax2, ax=axes[1], orientation='vertical', label=\"Fire Mask Value\")\n",
        "\n",
        "# LST plot\n",
        "cax3 = axes[2].imshow(lst, cmap='coolwarm')\n",
        "axes[2].set_title(\"LST\")\n",
        "fig.colorbar(cax3, ax=axes[2], orientation='vertical', label=\"Temperature (K)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3CLBGrik0Uy"
      },
      "outputs": [],
      "source": [
        "# Save Data\n",
        "dataset_folder = \"/content/drive/MyDrive/MODIS_Combined/\"\n",
        "fire_save_folder = \"/content/drive/MyDrive/MODIS_Combined/patches/fire\"\n",
        "nofire_save_folder = \"/content/drive/MyDrive/MODIS_Combined/patches/nofire\"\n",
        "\n",
        "os.makedirs(fire_save_folder, exist_ok=True)\n",
        "os.makedirs(nofire_save_folder, exist_ok=True)\n",
        "\n",
        "# Get list of .tif files\n",
        "tif_files = [f for f in os.listdir(dataset_folder) if f.endswith('.tif')]\n",
        "\n",
        "patch_size = 32\n",
        "\n",
        "for tif_file in tif_files:\n",
        "    file_path = os.path.join(dataset_folder, tif_file)\n",
        "\n",
        "    with rasterio.open(file_path) as src:\n",
        "        ndvi_mask = src.read(1)  # Band 1: NDVI\n",
        "        fire_mask = src.read(2)  # Band 2: FireMask\n",
        "        temp_mask = src.read(3)  # Band 3: LST\n",
        "\n",
        "    height, width = fire_mask.shape\n",
        "    num_rows = height // patch_size\n",
        "    num_cols = width // patch_size\n",
        "\n",
        "    patch_index = 0\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            y_start, y_end = i * patch_size, (i + 1) * patch_size\n",
        "            x_start, x_end = j * patch_size, (j + 1) * patch_size\n",
        "\n",
        "            fire_patch = fire_mask[y_start:y_end, x_start:x_end]\n",
        "            ndvi_patch = ndvi_mask[y_start:y_end, x_start:x_end]\n",
        "            temp_patch = temp_mask[y_start:y_end, x_start:x_end]\n",
        "\n",
        "            mostly_empty = np.sum((fire_patch < 4)) / fire_patch.size > 0.80  # Mostly water/cloud/unprocessed\n",
        "            fire_present = np.any(np.isin(fire_patch, [7, 8, 9]))  # Fire classes\n",
        "\n",
        "            if mostly_empty:\n",
        "                continue\n",
        "\n",
        "            if fire_present:\n",
        "                np.save(os.path.join(fire_save_folder, f\"Fire_{tif_file}_patch_{patch_index}.npy\"), fire_patch)\n",
        "                np.save(os.path.join(fire_save_folder, f\"NDVI_{tif_file}_patch_{patch_index}.npy\"), ndvi_patch)\n",
        "                np.save(os.path.join(fire_save_folder, f\"Temp_{tif_file}_patch_{patch_index}.npy\"), temp_patch)\n",
        "            else:\n",
        "                np.save(os.path.join(nofire_save_folder, f\"Fire_{tif_file}_patch_{patch_index}.npy\"), fire_patch)\n",
        "                np.save(os.path.join(nofire_save_folder, f\"NDVI_{tif_file}_patch_{patch_index}.npy\"), ndvi_patch)\n",
        "                np.save(os.path.join(nofire_save_folder, f\"Temp_{tif_file}_patch_{patch_index}.npy\"), temp_patch)\n",
        "\n",
        "            patch_index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "faT7DOZ8PKue",
        "outputId": "76901bfd-dccd-4cf4-f740-a390c013f2ea"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/MODIS_Combined/patches/fire/Fire_combined_2023-11-25.tif_patch_23.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b5825413e7e9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlst_patch_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/drive/MyDrive/MODIS_Combined/patches/{fire}/Temp_combined_{file_date}_patch_{patch_no}.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfiremask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfire_patch_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mndvi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndvi_patch_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_patch_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/MODIS_Combined/patches/fire/Fire_combined_2023-11-25.tif_patch_23.npy'"
          ]
        }
      ],
      "source": [
        "# File paths\n",
        "patch_no = 23\n",
        "file_date = \"2023-11-05.tif\"\n",
        "fire = \"fire\" # \"fire\" and \"nofire\"\n",
        "fire_patch_file = f\"/content/drive/MyDrive/MODIS_Combined/patches/{fire}/Fire_combined_{file_date}_patch_{patch_no}.npy\"\n",
        "ndvi_patch_file = f\"/content/drive/MyDrive/MODIS_Combined/patches/{fire}/NDVI_combined_{file_date}_patch_{patch_no}.npy\"\n",
        "lst_patch_file = f\"/content/drive/MyDrive/MODIS_Combined/patches/{fire}/Temp_combined_{file_date}_patch_{patch_no}.npy\"\n",
        "\n",
        "firemask = np.load(fire_patch_file)\n",
        "ndvi = np.load(ndvi_patch_file)\n",
        "lst = np.load(lst_patch_file)\n",
        "\n",
        "# Scale LST\n",
        "lst = lst * 0.02  # Convert to Kelvin\n",
        "\n",
        "# FireMask colormap\n",
        "fire_mask_cmap = mcolors.ListedColormap([\n",
        "    'white',     # 1: Not processed\n",
        "    'gray',      # 2: Not processed\n",
        "    'blue',      # 3: Non-fire water\n",
        "    'lightblue', # 4: Cloud\n",
        "    'green',     # 5: Non-fire land\n",
        "    'yellow',    # 6: Unknown\n",
        "    'orange',    # 7: Fire (low confidence)\n",
        "    'red',       # 8: Fire (nominal confidence)\n",
        "    'darkred'    # 9: Fire (high confidence)\n",
        "])\n",
        "bounds = np.arange(1, 10)\n",
        "norm = mcolors.BoundaryNorm(bounds, fire_mask_cmap.N)\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "# NDVI\n",
        "cax1 = axes[0].imshow(ndvi, cmap='YlGn', vmin=-1, vmax=1)\n",
        "axes[0].set_title(\"NDVI\")\n",
        "fig.colorbar(cax1, ax=axes[0], label=\"NDVI\")\n",
        "\n",
        "# Fire Mask\n",
        "cax2 = axes[1].imshow(firemask, cmap=fire_mask_cmap, norm=norm)\n",
        "axes[1].set_title(\"Fire Mask\")\n",
        "fig.colorbar(cax2, ax=axes[1], ticks=bounds, label=\"Fire Class\")\n",
        "\n",
        "# LST\n",
        "cax3 = axes[2].imshow(lst, cmap='coolwarm')\n",
        "axes[2].set_title(\"Land Surface Temp (K)\")\n",
        "fig.colorbar(cax3, ax=axes[2], label=\"Kelvin\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLv1_Gy6nLmQ"
      },
      "source": [
        "# Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3EE1ZZ9nNaE",
        "outputId": "76584766-ed96-4af9-aaf6-9af285ed6578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset size: X = (1377, 128, 128, 3), y = (1377, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "from scipy.ndimage import rotate\n",
        "\n",
        "def normalize_patch(ndvi_patch, temp_patch, evi_patch):\n",
        "    ndvi_patch = np.nan_to_num(ndvi_patch, nan=0)\n",
        "    temp_patch = np.nan_to_num(temp_patch, nan=0)\n",
        "    evi_patch = np.nan_to_num(evi_patch, nan=0)\n",
        "\n",
        "    # Normalize each patch using min-max scaling (0 to 1)\n",
        "    ndvi_min, ndvi_max = np.nanmin(ndvi_patch), np.nanmax(ndvi_patch)\n",
        "    temp_min, temp_max = np.nanmin(temp_patch), np.nanmax(temp_patch)\n",
        "    evi_min, evi_max = np.nanmin(evi_patch), np.nanmax(evi_patch)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    ndvi_patch = (ndvi_patch - ndvi_min) / (ndvi_max - ndvi_min) if ndvi_max != ndvi_min else ndvi_patch\n",
        "    temp_patch = (temp_patch - temp_min) / (temp_max - temp_min) if temp_max != temp_min else temp_patch\n",
        "    evi_patch = (evi_patch - evi_min) / (evi_max - evi_min) if evi_max != evi_min else evi_patch\n",
        "\n",
        "    return ndvi_patch, temp_patch, evi_patch\n",
        "\n",
        "def remove_outliers(patch, lower_percentile=2.5, upper_percentile=97.5):\n",
        "    \"\"\"\n",
        "    Removes outliers by clipping values outside of the specified percentiles\n",
        "    \"\"\"\n",
        "\n",
        "    patch = np.nan_to_num(patch, nan=0)\n",
        "\n",
        "    lower_bound = np.percentile(patch, lower_percentile)\n",
        "    upper_bound = np.percentile(patch, upper_percentile)\n",
        "\n",
        "    # Clip values to fall between lower and upper bounds\n",
        "    patch = np.clip(patch, lower_bound, upper_bound)\n",
        "\n",
        "    return patch\n",
        "\n",
        "\n",
        "def generate_augmented_patches(ndvi_patch, temp_patch, evi_patch, fire_patch):\n",
        "    augmented = []\n",
        "    for flip in [None, 'h', 'v']:\n",
        "        for angle in [0, 90, 180, 270]:\n",
        "            ndvi_aug = ndvi_patch.copy()\n",
        "            temp_aug = temp_patch.copy()\n",
        "            evi_aug = evi_patch.copy()\n",
        "            fire_aug = fire_patch.copy()\n",
        "\n",
        "            if flip == 'h':\n",
        "                ndvi_aug = np.fliplr(ndvi_aug)\n",
        "                temp_aug = np.fliplr(temp_aug)\n",
        "                evi_aug = np.fliplr(evi_aug)\n",
        "                fire_aug = np.fliplr(fire_aug)\n",
        "            elif flip == 'v':\n",
        "                ndvi_aug = np.flipud(ndvi_aug)\n",
        "                temp_aug = np.flipud(temp_aug)\n",
        "                evi_aug = np.flipud(evi_aug)\n",
        "                fire_aug = np.flipud(fire_aug)\n",
        "\n",
        "            if angle != 0:\n",
        "                ndvi_aug = rotate(ndvi_aug, angle, reshape=False)\n",
        "                temp_aug = rotate(temp_aug, angle, reshape=False)\n",
        "                evi_aug = rotate(evi_aug, angle, reshape=False)\n",
        "                fire_aug = rotate(fire_aug, angle, reshape=False, order=0)\n",
        "\n",
        "            input_aug = np.stack([ndvi_aug, temp_aug, evi_aug], axis=-1)  # (128,128,3)\n",
        "\n",
        "            severity_aug = np.zeros_like(fire_patch)\n",
        "            severity_aug[fire_aug == 7] = 1\n",
        "            severity_aug[fire_aug == 8] = 2\n",
        "            severity_aug[fire_aug == 9] = 3\n",
        "\n",
        "            augmented.append((input_aug, severity_aug))\n",
        "    return augmented\n",
        "\n",
        "\n",
        "dataset_folder = \"/content/drive/MyDrive/NEW_MODIS_Combined/\"\n",
        "\n",
        "tif_files = [f for f in os.listdir(dataset_folder) if f.endswith('.tif')]\n",
        "patch_size = 128\n",
        "threshold = 0.80\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for tif_file in tif_files:\n",
        "    file_path = os.path.join(dataset_folder, tif_file)\n",
        "\n",
        "    with rasterio.open(file_path) as src:\n",
        "        ndvi_mask = src.read(1)  # Band 1: NDVI\n",
        "        fire_mask = src.read(2)  # Band 2: FireMask\n",
        "        temp_mask = src.read(3)  # Band 3: LST\n",
        "        evi_mask = src.read(4)   # Band 4: EVI\n",
        "\n",
        "    height, width = fire_mask.shape\n",
        "    num_rows = height // patch_size\n",
        "    num_cols = width // patch_size\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            y_start, y_end = i * patch_size, (i + 1) * patch_size\n",
        "            x_start, x_end = j * patch_size, (j + 1) * patch_size\n",
        "\n",
        "            fire_patch = fire_mask[y_start:y_end, x_start:x_end]\n",
        "            ndvi_patch = ndvi_mask[y_start:y_end, x_start:x_end]\n",
        "            temp_patch = temp_mask[y_start:y_end, x_start:x_end]\n",
        "            evi_patch = evi_mask[y_start:y_end, x_start:x_end]\n",
        "\n",
        "            fire_mostly_empty = np.sum((fire_patch < 4)) / fire_patch.size > threshold\n",
        "            ndvi_mostly_empty = np.isnan(ndvi_patch).sum() / ndvi_patch.size > threshold\n",
        "            lst_mostly_empty = np.isnan(temp_patch).sum() / temp_patch.size > threshold\n",
        "            evi_mostly_empty = np.isnan(evi_patch).sum() / evi_patch.size > threshold\n",
        "            fire_present = np.any(np.isin(fire_patch, [7, 8, 9]))\n",
        "\n",
        "            if fire_mostly_empty or ndvi_mostly_empty or lst_mostly_empty or evi_mostly_empty:\n",
        "                continue\n",
        "\n",
        "            # Normalize each patch\n",
        "            ndvi_patch, temp_patch, evi_patch = normalize_patch(ndvi_patch, temp_patch, evi_patch)\n",
        "\n",
        "            # Remove outliers\n",
        "            ndvi_patch = remove_outliers(ndvi_patch)\n",
        "            temp_patch = remove_outliers(temp_patch)\n",
        "            evi_patch = remove_outliers(evi_patch)\n",
        "\n",
        "\n",
        "            if fire_present:\n",
        "                augmented = generate_augmented_patches(ndvi_patch, temp_patch, evi_patch, fire_patch)\n",
        "                for input_aug, label_aug in augmented:\n",
        "                    X.append(input_aug)\n",
        "                    y.append(label_aug)\n",
        "            else:\n",
        "                input_patch = np.stack([ndvi_patch, temp_patch, evi_patch], axis=-1)\n",
        "                severity_patch = np.zeros_like(fire_patch)  # Default: 0 (no fire)\n",
        "                severity_patch[fire_patch == 7] = 1\n",
        "                severity_patch[fire_patch == 8] = 2\n",
        "                severity_patch[fire_patch == 9] = 3\n",
        "\n",
        "                X.append(input_patch)\n",
        "                y.append(severity_patch)\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Final dataset size: X = {X.shape}, y = {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A62vzYCns-uT",
        "outputId": "03a45ceb-5c64-4779-ee26-8fabfe51de97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float32(3.0)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:,:,:].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBCTzwWP9Ipe"
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "np.savez_compressed(f\"/content/drive/MyDrive/NEW_MODIS_Combined/new_data.npz\", X=X, y=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HYXYlrr9W9G"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, ZeroPadding2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZCrko6dhqAA"
      },
      "outputs": [],
      "source": [
        "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver(\"j\")\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ4IX0tXXxaC"
      },
      "source": [
        "BIMO's CODE TRIAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnmp3DKHIqrV"
      },
      "outputs": [],
      "source": [
        "# New Vince Data (augmented ~400 new fire patches)\n",
        "data = np.load(\"/content/drive/MyDrive/new_data.npz\")\n",
        "X = data[\"X\"]\n",
        "y = data[\"y\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5R74NOnI-1p",
        "outputId": "c1641750-de5c-4762-f01b-0bb10a0838a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1377, 128, 128, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_25faIVqXxCF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Conv2DTranspose, Concatenate, ZeroPadding2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, Activation,\n",
        "    UpSampling2D, Concatenate, ZeroPadding2D, Layer\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "class ResizeLayer(Layer):\n",
        "    def call(self, input):\n",
        "        input_tensor, target_tensor = input\n",
        "        target_height = tf.shape(target_tensor)[1]\n",
        "        target_width = tf.shape(target_tensor)[2]\n",
        "        return tf.image.resize(input_tensor, [target_height, target_width])\n",
        "\n",
        "def decoder_block(input_tensor, skip_tensor, num_filters):\n",
        "    x = ResizeLayer()([input_tensor, skip_tensor])\n",
        "    x = Concatenate()([x, skip_tensor])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_resnetv2_unet(input_shape=(128, 128, 3)):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained ResNetV2 Encoder \"\"\"\n",
        "    base_model = ResNet50V2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    # Encoder feature maps (you can verify with model.summary())\n",
        "    s1 = base_model.get_layer(\"conv1_conv\").output       # 64x64\n",
        "    s2 = base_model.get_layer(\"conv2_block3_out\").output # 32x32\n",
        "    s3 = base_model.get_layer(\"conv3_block4_out\").output # 16x16\n",
        "    s4 = base_model.get_layer(\"conv4_block6_out\").output # 8x8\n",
        "    b1 = base_model.get_layer(\"conv5_block3_out\").output # 4x4 (bridge)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)  # 4→8\n",
        "    d2 = decoder_block(d1, s3, 256)  # 8→16\n",
        "    d3 = decoder_block(d2, s2, 128)  # 16→32\n",
        "    d4 = decoder_block(d3, s1, 64)   # 32→64\n",
        "\n",
        "    # Final upsampling to match input 128x128\n",
        "    x = UpSampling2D((2, 2))(d4)     # 64→128\n",
        "    x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "    # outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(x)\n",
        "    outputs = Conv2D(4, 1, padding=\"same\", activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"ResNetV2_U-Net\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl5vU-AGX__Z",
        "outputId": "34eeb288-3753-42ae-dc09-6c03674c049e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "input_shape = X.shape[1:]\n",
        "model = build_resnetv2_unet(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMwvf-rAYnW9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# def focal_loss(gamma=2., alpha=0.25):\n",
        "#     def loss(y_true, y_pred):\n",
        "#         epsilon = K.epsilon()\n",
        "#         y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "#         pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "#         return -K.mean(alpha * K.pow(1. - pt, gamma) * K.log(pt))\n",
        "#     return loss\n",
        "\n",
        "\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true = tf.one_hot(y_true, depth=4)  # Convert to one-hot\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
        "\n",
        "        # Calculate focal loss\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "        weight = alpha * K.pow(1. - y_pred, gamma)\n",
        "        focal_loss = weight * cross_entropy\n",
        "\n",
        "        return K.mean(focal_loss)\n",
        "    return loss\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    # y_true: integer labels (sparse) [batch, H, W]\n",
        "    # y_pred: probabilities [batch, H, W, num_classes]\n",
        "    y_true = K.cast(y_true, 'int32')\n",
        "    y_true_one_hot = K.one_hot(y_true, num_classes=4)  # Convert to one-hot [batch, H, W, 4]\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "\n",
        "    # Compute intersection and union for each class\n",
        "    intersection = K.sum(y_true_one_hot * y_pred, axis=[1, 2])\n",
        "    union = K.sum(y_true_one_hot, axis=[1, 2]) + K.sum(y_pred, axis=[1, 2])\n",
        "\n",
        "    # Dice score per class, averaged over batch\n",
        "    dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "    return K.mean(dice)  # Average over classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXP0Ng4Vspxt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vBesfuzYMFC",
        "outputId": "ebe01c34-5f20-4fd5-fa8f-ff21521f2cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m908s\u001b[0m 19s/step - accuracy: 0.9999 - dice_coefficient: 0.2461 - loss: 1.0346e-04 - mean_iou: 0.2518 - learning_rate: 0.0010\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,dice_coefficient,loss,mean_iou,learning_rate.\n",
            "  callback.on_epoch_end(epoch, logs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,dice_coefficient,loss,mean_iou,learning_rate\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m842s\u001b[0m 19s/step - accuracy: 0.9999 - dice_coefficient: 0.2440 - loss: 7.6957e-05 - mean_iou: 0.2500 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m866s\u001b[0m 19s/step - accuracy: 0.9999 - dice_coefficient: 0.2441 - loss: 6.9834e-05 - mean_iou: 0.2596 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m854s\u001b[0m 19s/step - accuracy: 0.9999 - dice_coefficient: 0.2447 - loss: 8.7383e-05 - mean_iou: 0.2500 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m860s\u001b[0m 19s/step - accuracy: 0.9999 - dice_coefficient: 0.2444 - loss: 6.2686e-05 - mean_iou: 0.2537 - learning_rate: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e05c4c57410>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.metrics import MeanIoU\n",
        "class MeanIoUMetric(tf.keras.metrics.MeanIoU):\n",
        "    def __init__(self, num_classes, name='mean_iou', **kwargs):\n",
        "        super().__init__(num_classes=num_classes, name=name, **kwargs)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        # No need to squeeze y_true if it's already shape (batch, H, W)\n",
        "        return super().update_state(y_true, y_pred, sample_weight)\n",
        "# # model.compile(\n",
        "# #     optimizer='adam',\n",
        "# #     loss=SparseCategoricalCrossentropy(from_logits=False),\n",
        "# #     metrics=['Recall']\n",
        "# # )\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss=SparseCategoricalCrossentropy(from_logits=False),\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=focal_loss(alpha=0.75, gamma=3.0),\n",
        "    metrics=[ \"accuracy\", dice_coefficient, MeanIoUMetric(num_classes=4)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=5, callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swtxfHqyp01P",
        "outputId": "9b570f7b-e8ef-45c3-8e5a-701a21f027d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset size: X = (82, 128, 128, 3), y = (82, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Final dataset size: X = {X.shape}, y = {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp2NsKf7kRT5",
        "outputId": "e072b0c7-f0be-4bd9-bff0-d22967b400a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "Model output: [[[[nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]]\n",
            "\n",
            "  [[nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]]\n",
            "\n",
            "  [[nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]]\n",
            "\n",
            "  [[nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]]\n",
            "\n",
            "  [[nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]\n",
            "   [nan nan nan nan]]]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_clean[:1])  # Check first sample\n",
        "print(\"Model output:\", y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "IX5cKFEtYglf",
        "outputId": "ed43d26d-ac74-4afb-9052-dc1b93fe47c4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_checkpoint' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cb1673ec618d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr_on_plateau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_checkpoint' is not defined"
          ]
        }
      ],
      "source": [
        "history = model.fit(X, y, validation_split=0.1, batch_size=16, epochs=10, callbacks=[model_checkpoint, reduce_lr_on_plateau, early_stopping])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bq5yc5hpnkFb",
        "K-KmADMY3z5-",
        "_120696rxozT",
        "ISMO6jfO4_Lw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}