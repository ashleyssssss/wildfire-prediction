{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EjkSAa1VOjHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e735c9bc-1772-4c63-8718-e5defa2c07d4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.19.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from rioxarray) (24.2)\n",
            "Collecting rasterio>=1.4.3 (from rioxarray)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: xarray>=2024.7.0 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2025.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3->rioxarray) (2025.4.26)\n",
            "Collecting affine (from rasterio>=1.4.3->rioxarray)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.4.3->rioxarray) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.4.3->rioxarray) (8.2.0)\n",
            "Collecting cligj>=0.5 (from rasterio>=1.4.3->rioxarray)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio>=1.4.3->rioxarray)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.4.3->rioxarray) (3.2.3)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray>=2024.7.0->rioxarray) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray>=2024.7.0->rioxarray) (1.17.0)\n",
            "Downloading rioxarray-0.19.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio, rioxarray\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3 rioxarray-0.19.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install rioxarray\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "data = np.load(\"/content/drive/MyDrive/new_modis_data.npz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLv1_Gy6nLmQ"
      },
      "source": [
        "# Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4HYXYlrr9W9G"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, Activation, UpSampling2D,\n",
        "    Concatenate, Layer, Dropout, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        ")\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import EfficientNetB4, MobileNetV2, EfficientNetB0, MobileNetV3Large, VGG16\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.metrics import MeanIoU\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.model_selection import KFold\n",
        "import uuid\n",
        "import time\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T5R74NOnI-1p"
      },
      "outputs": [],
      "source": [
        "X_train = data[\"X_train\"]\n",
        "y_train = data[\"y_train\"]\n",
        "\n",
        "X_val = data[\"X_val\"]\n",
        "y_val = data[\"y_val\"]\n",
        "\n",
        "X_test = data[\"X_test\"]\n",
        "y_test = data[\"y_test\"]\n",
        "\n",
        "X_train.shape\n",
        "data.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32, 32, 3)"
      ],
      "metadata": {
        "id": "TPTekwQRsY_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls-HW7kN_0tM",
        "outputId": "da607fe1-47cc-49f6-a2e7-c980f84f1f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11080, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall = tf.keras.metrics.Recall(name='recall')\n",
        "precision = tf.keras.metrics.Precision(name='precision')"
      ],
      "metadata": {
        "id": "8jAjH70YmUcl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_new = np.concatenate([X_train, X_val], axis=0)\n",
        "y_train_new = np.concatenate([y_train, y_val], axis=0)"
      ],
      "metadata": {
        "id": "i468Y9tttrZo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNetB0 - Ashley"
      ],
      "metadata": {
        "id": "JrqyBN0tGNPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_efficientnetb0():\n",
        "    base_model = EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Yp2VEvrLsdX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnetb0 = create_efficientnetb0()\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "]\n",
        "\n",
        "efficientnetb0.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[recall, precision, 'accuracy']\n",
        ")\n",
        "\n",
        "efficientnetb0.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=16, epochs=20, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Ie7YNs0V3o",
        "outputId": "173ea0b1-4d72-4e1b-c4f1-34a58a23acd5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6575 - loss: 0.6514 - precision: 0.2939 - recall: 0.0094\n",
            "Epoch 1: val_loss improved from inf to 0.63697, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.6575 - loss: 0.6514 - precision: 0.2939 - recall: 0.0094 - val_accuracy: 0.6668 - val_loss: 0.6370 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6651 - loss: 0.6441 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 2: val_loss improved from 0.63697 to 0.63651, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6651 - loss: 0.6441 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6703 - loss: 0.6383 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 3: val_loss did not improve from 0.63651\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.6702 - loss: 0.6383 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6698 - loss: 0.6386 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 4: val_loss did not improve from 0.63651\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6698 - loss: 0.6386 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6377 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6741 - loss: 0.6339 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 5: val_loss did not improve from 0.63651\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.6740 - loss: 0.6340 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6370 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6675 - loss: 0.6370 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 6: val_loss did not improve from 0.63651\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6675 - loss: 0.6370 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6367 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6661 - loss: 0.6376 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 7: val_loss improved from 0.63651 to 0.63645, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6661 - loss: 0.6376 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6671 - loss: 0.6368 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 8: val_loss improved from 0.63645 to 0.63645, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6671 - loss: 0.6368 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6632 - loss: 0.6389 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 9: val_loss did not improve from 0.63645\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6633 - loss: 0.6389 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6650 - loss: 0.6378 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 10: val_loss did not improve from 0.63645\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6650 - loss: 0.6378 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.5000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6660 - loss: 0.6369 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 11: val_loss did not improve from 0.63645\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6660 - loss: 0.6369 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.5000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6626 - loss: 0.6393 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 12: val_loss did not improve from 0.63645\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6627 - loss: 0.6393 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.2500e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6737 - loss: 0.6318 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 13: val_loss did not improve from 0.63645\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6737 - loss: 0.6318 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6668 - val_loss: 0.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.2500e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d83c99d0b90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_efficientnetb0 = load_model(\"best_model.keras\", custom_objects={\n",
        "    'recall': recall,\n",
        "    'precision': precision\n",
        "})\n",
        "\n",
        "best_efficientnetb0.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "BAW8iwfmvEKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1b8c8a-2989-4cbb-c0da-f118082fb1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.6811 - loss: 0.6266 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6364513039588928, 0.0, 0.0, 0.6667569279670715]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileNetV2 - Shirina"
      ],
      "metadata": {
        "id": "DKgbUvu-GTkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mobilenetv2():\n",
        "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "JiRgD5YMseO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenetv2 = create_mobilenetv2()\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "]\n",
        "\n",
        "mobilenetv2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[recall, precision, 'accuracy']\n",
        ")\n",
        "\n",
        "mobilenetv2.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=16, epochs=50, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yg1rbsx0kkM",
        "outputId": "5a7a91f4-322e-4e86-de9a-53da4d0c1bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-7b699983fec9>:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6719 - loss: 0.6056 - precision: 0.5175 - recall: 0.1285\n",
            "Epoch 1: val_loss improved from inf to 0.51378, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6720 - loss: 0.6056 - precision: 0.5178 - recall: 0.1287 - val_accuracy: 0.7545 - val_loss: 0.5138 - val_precision: 0.7051 - val_recall: 0.4525 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7568 - loss: 0.5145 - precision: 0.7108 - recall: 0.4569\n",
            "Epoch 2: val_loss improved from 0.51378 to 0.49678, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7568 - loss: 0.5145 - precision: 0.7108 - recall: 0.4570 - val_accuracy: 0.7607 - val_loss: 0.4968 - val_precision: 0.7433 - val_recall: 0.4305 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7666 - loss: 0.4949 - precision: 0.7335 - recall: 0.4725\n",
            "Epoch 3: val_loss improved from 0.49678 to 0.48797, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7666 - loss: 0.4949 - precision: 0.7335 - recall: 0.4726 - val_accuracy: 0.7650 - val_loss: 0.4880 - val_precision: 0.7379 - val_recall: 0.4574 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m684/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7711 - loss: 0.4888 - precision: 0.7348 - recall: 0.4769\n",
            "Epoch 4: val_loss improved from 0.48797 to 0.47879, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7711 - loss: 0.4887 - precision: 0.7350 - recall: 0.4770 - val_accuracy: 0.7704 - val_loss: 0.4788 - val_precision: 0.7557 - val_recall: 0.4598 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.4860 - precision: 0.7462 - recall: 0.4911\n",
            "Epoch 5: val_loss improved from 0.47879 to 0.47324, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7706 - loss: 0.4859 - precision: 0.7462 - recall: 0.4911 - val_accuracy: 0.7748 - val_loss: 0.4732 - val_precision: 0.7622 - val_recall: 0.4712 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m686/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7765 - loss: 0.4809 - precision: 0.7543 - recall: 0.4903\n",
            "Epoch 6: val_loss improved from 0.47324 to 0.46855, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7765 - loss: 0.4808 - precision: 0.7544 - recall: 0.4904 - val_accuracy: 0.7772 - val_loss: 0.4685 - val_precision: 0.7506 - val_recall: 0.4963 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.4666 - precision: 0.7562 - recall: 0.5256\n",
            "Epoch 7: val_loss improved from 0.46855 to 0.46353, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7808 - loss: 0.4666 - precision: 0.7562 - recall: 0.5256 - val_accuracy: 0.7823 - val_loss: 0.4635 - val_precision: 0.7720 - val_recall: 0.4923 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.4513 - precision: 0.7677 - recall: 0.5109\n",
            "Epoch 8: val_loss improved from 0.46353 to 0.45999, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7898 - loss: 0.4513 - precision: 0.7677 - recall: 0.5109 - val_accuracy: 0.7859 - val_loss: 0.4600 - val_precision: 0.8064 - val_recall: 0.4703 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7917 - loss: 0.4531 - precision: 0.7799 - recall: 0.5150\n",
            "Epoch 9: val_loss improved from 0.45999 to 0.45908, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.7917 - loss: 0.4531 - precision: 0.7799 - recall: 0.5150 - val_accuracy: 0.7818 - val_loss: 0.4591 - val_precision: 0.7385 - val_recall: 0.5345 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7944 - loss: 0.4510 - precision: 0.7803 - recall: 0.5403\n",
            "Epoch 10: val_loss improved from 0.45908 to 0.45442, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7944 - loss: 0.4510 - precision: 0.7803 - recall: 0.5402 - val_accuracy: 0.7883 - val_loss: 0.4544 - val_precision: 0.7889 - val_recall: 0.4980 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7951 - loss: 0.4458 - precision: 0.7721 - recall: 0.5463\n",
            "Epoch 11: val_loss improved from 0.45442 to 0.45086, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7951 - loss: 0.4458 - precision: 0.7721 - recall: 0.5462 - val_accuracy: 0.7905 - val_loss: 0.4509 - val_precision: 0.7831 - val_recall: 0.5134 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7961 - loss: 0.4382 - precision: 0.7727 - recall: 0.5385\n",
            "Epoch 12: val_loss improved from 0.45086 to 0.44888, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7961 - loss: 0.4382 - precision: 0.7727 - recall: 0.5384 - val_accuracy: 0.7924 - val_loss: 0.4489 - val_precision: 0.7704 - val_recall: 0.5370 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m685/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.4322 - precision: 0.7837 - recall: 0.5558\n",
            "Epoch 13: val_loss did not improve from 0.44888\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8016 - loss: 0.4323 - precision: 0.7836 - recall: 0.5557 - val_accuracy: 0.7899 - val_loss: 0.4505 - val_precision: 0.8182 - val_recall: 0.4752 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7938 - loss: 0.4361 - precision: 0.7667 - recall: 0.5423\n",
            "Epoch 14: val_loss did not improve from 0.44888\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7938 - loss: 0.4361 - precision: 0.7667 - recall: 0.5424 - val_accuracy: 0.7948 - val_loss: 0.4491 - val_precision: 0.7895 - val_recall: 0.5240 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8004 - loss: 0.4268 - precision: 0.7753 - recall: 0.5504\n",
            "Epoch 15: val_loss improved from 0.44888 to 0.44489, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8004 - loss: 0.4269 - precision: 0.7754 - recall: 0.5505 - val_accuracy: 0.7924 - val_loss: 0.4449 - val_precision: 0.7809 - val_recall: 0.5240 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7989 - loss: 0.4298 - precision: 0.7831 - recall: 0.5453\n",
            "Epoch 16: val_loss improved from 0.44489 to 0.44428, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7989 - loss: 0.4298 - precision: 0.7831 - recall: 0.5453 - val_accuracy: 0.7962 - val_loss: 0.4443 - val_precision: 0.7987 - val_recall: 0.5191 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8070 - loss: 0.4262 - precision: 0.7900 - recall: 0.5587\n",
            "Epoch 17: val_loss did not improve from 0.44428\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8070 - loss: 0.4262 - precision: 0.7899 - recall: 0.5587 - val_accuracy: 0.7986 - val_loss: 0.4447 - val_precision: 0.8277 - val_recall: 0.4996 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8115 - loss: 0.4177 - precision: 0.8014 - recall: 0.5757\n",
            "Epoch 18: val_loss improved from 0.44428 to 0.44287, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8114 - loss: 0.4178 - precision: 0.8012 - recall: 0.5756 - val_accuracy: 0.7978 - val_loss: 0.4429 - val_precision: 0.8201 - val_recall: 0.5037 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7999 - loss: 0.4271 - precision: 0.7839 - recall: 0.5571\n",
            "Epoch 19: val_loss did not improve from 0.44287\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7999 - loss: 0.4271 - precision: 0.7838 - recall: 0.5571 - val_accuracy: 0.7964 - val_loss: 0.4431 - val_precision: 0.7997 - val_recall: 0.5191 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8054 - loss: 0.4316 - precision: 0.7854 - recall: 0.5748\n",
            "Epoch 20: val_loss did not improve from 0.44287\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8055 - loss: 0.4316 - precision: 0.7855 - recall: 0.5748 - val_accuracy: 0.7951 - val_loss: 0.4445 - val_precision: 0.7948 - val_recall: 0.5191 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.4210 - precision: 0.7821 - recall: 0.5949\n",
            "Epoch 21: val_loss improved from 0.44287 to 0.44043, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8071 - loss: 0.4210 - precision: 0.7821 - recall: 0.5949 - val_accuracy: 0.7997 - val_loss: 0.4404 - val_precision: 0.7969 - val_recall: 0.5353 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.4245 - precision: 0.7891 - recall: 0.5721\n",
            "Epoch 22: val_loss did not improve from 0.44043\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8068 - loss: 0.4245 - precision: 0.7891 - recall: 0.5721 - val_accuracy: 0.8005 - val_loss: 0.4453 - val_precision: 0.7446 - val_recall: 0.6109 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m685/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.4174 - precision: 0.7809 - recall: 0.5823\n",
            "Epoch 23: val_loss did not improve from 0.44043\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8073 - loss: 0.4175 - precision: 0.7808 - recall: 0.5821 - val_accuracy: 0.7962 - val_loss: 0.4430 - val_precision: 0.8283 - val_recall: 0.4898 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8048 - loss: 0.4217 - precision: 0.7981 - recall: 0.5534\n",
            "Epoch 24: val_loss did not improve from 0.44043\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8048 - loss: 0.4217 - precision: 0.7980 - recall: 0.5534 - val_accuracy: 0.7991 - val_loss: 0.4415 - val_precision: 0.7609 - val_recall: 0.5792 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8123 - loss: 0.4101 - precision: 0.7874 - recall: 0.5962\n",
            "Epoch 25: val_loss did not improve from 0.44043\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8123 - loss: 0.4102 - precision: 0.7874 - recall: 0.5960 - val_accuracy: 0.8005 - val_loss: 0.4405 - val_precision: 0.8049 - val_recall: 0.5297 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8085 - loss: 0.4195 - precision: 0.8005 - recall: 0.5708\n",
            "Epoch 26: val_loss improved from 0.44043 to 0.44031, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8085 - loss: 0.4195 - precision: 0.8005 - recall: 0.5708 - val_accuracy: 0.8024 - val_loss: 0.4403 - val_precision: 0.8120 - val_recall: 0.5297 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8026 - loss: 0.4270 - precision: 0.7890 - recall: 0.5595\n",
            "Epoch 27: val_loss improved from 0.44031 to 0.44025, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8027 - loss: 0.4270 - precision: 0.7890 - recall: 0.5595 - val_accuracy: 0.8016 - val_loss: 0.4403 - val_precision: 0.7869 - val_recall: 0.5548 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8096 - loss: 0.4161 - precision: 0.7917 - recall: 0.5833\n",
            "Epoch 28: val_loss improved from 0.44025 to 0.43955, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8096 - loss: 0.4161 - precision: 0.7917 - recall: 0.5833 - val_accuracy: 0.8021 - val_loss: 0.4396 - val_precision: 0.7790 - val_recall: 0.5670 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m685/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8078 - loss: 0.4219 - precision: 0.7808 - recall: 0.5967\n",
            "Epoch 29: val_loss did not improve from 0.43955\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8079 - loss: 0.4218 - precision: 0.7810 - recall: 0.5965 - val_accuracy: 0.8021 - val_loss: 0.4403 - val_precision: 0.7976 - val_recall: 0.5443 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8073 - loss: 0.4097 - precision: 0.7802 - recall: 0.5661\n",
            "Epoch 30: val_loss improved from 0.43955 to 0.43887, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8073 - loss: 0.4097 - precision: 0.7803 - recall: 0.5663 - val_accuracy: 0.8008 - val_loss: 0.4389 - val_precision: 0.7699 - val_recall: 0.5735 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8077 - loss: 0.4121 - precision: 0.7865 - recall: 0.5966\n",
            "Epoch 31: val_loss did not improve from 0.43887\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8077 - loss: 0.4121 - precision: 0.7865 - recall: 0.5964 - val_accuracy: 0.7999 - val_loss: 0.4419 - val_precision: 0.7536 - val_recall: 0.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8022 - loss: 0.4231 - precision: 0.7765 - recall: 0.5741\n",
            "Epoch 32: val_loss improved from 0.43887 to 0.43797, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8022 - loss: 0.4230 - precision: 0.7765 - recall: 0.5742 - val_accuracy: 0.8051 - val_loss: 0.4380 - val_precision: 0.8031 - val_recall: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8123 - loss: 0.4083 - precision: 0.7841 - recall: 0.5729\n",
            "Epoch 33: val_loss did not improve from 0.43797\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.8123 - loss: 0.4083 - precision: 0.7841 - recall: 0.5729 - val_accuracy: 0.8032 - val_loss: 0.4395 - val_precision: 0.7806 - val_recall: 0.5695 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - loss: 0.4124 - precision: 0.7883 - recall: 0.5883\n",
            "Epoch 34: val_loss did not improve from 0.43797\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8099 - loss: 0.4124 - precision: 0.7883 - recall: 0.5882 - val_accuracy: 0.8059 - val_loss: 0.4387 - val_precision: 0.8024 - val_recall: 0.5540 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m686/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.4023 - precision: 0.7883 - recall: 0.5943\n",
            "Epoch 35: val_loss did not improve from 0.43797\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.8140 - loss: 0.4023 - precision: 0.7884 - recall: 0.5942 - val_accuracy: 0.8002 - val_loss: 0.4400 - val_precision: 0.8181 - val_recall: 0.5150 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4155 - precision: 0.8048 - recall: 0.5629\n",
            "Epoch 36: val_loss did not improve from 0.43797\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8076 - loss: 0.4155 - precision: 0.8047 - recall: 0.5630 - val_accuracy: 0.8059 - val_loss: 0.4381 - val_precision: 0.8096 - val_recall: 0.5459 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8151 - loss: 0.4035 - precision: 0.7914 - recall: 0.5831\n",
            "Epoch 37: val_loss improved from 0.43797 to 0.43759, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.8151 - loss: 0.4035 - precision: 0.7915 - recall: 0.5832 - val_accuracy: 0.8062 - val_loss: 0.4376 - val_precision: 0.7950 - val_recall: 0.5638 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8193 - loss: 0.3971 - precision: 0.7976 - recall: 0.6059\n",
            "Epoch 38: val_loss did not improve from 0.43759\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8193 - loss: 0.3973 - precision: 0.7976 - recall: 0.6058 - val_accuracy: 0.8054 - val_loss: 0.4381 - val_precision: 0.8107 - val_recall: 0.5426 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8159 - loss: 0.4043 - precision: 0.8016 - recall: 0.5872\n",
            "Epoch 39: val_loss did not improve from 0.43759\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8159 - loss: 0.4043 - precision: 0.8016 - recall: 0.5873 - val_accuracy: 0.8067 - val_loss: 0.4379 - val_precision: 0.7850 - val_recall: 0.5784 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8160 - loss: 0.4110 - precision: 0.8006 - recall: 0.6022\n",
            "Epoch 40: val_loss did not improve from 0.43759\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8160 - loss: 0.4109 - precision: 0.8006 - recall: 0.6022 - val_accuracy: 0.8040 - val_loss: 0.4383 - val_precision: 0.8000 - val_recall: 0.5491 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8145 - loss: 0.4050 - precision: 0.7922 - recall: 0.5866\n",
            "Epoch 41: val_loss did not improve from 0.43759\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8145 - loss: 0.4050 - precision: 0.7922 - recall: 0.5866 - val_accuracy: 0.8043 - val_loss: 0.4379 - val_precision: 0.7900 - val_recall: 0.5621 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8153 - loss: 0.4025 - precision: 0.7896 - recall: 0.6045\n",
            "Epoch 42: val_loss did not improve from 0.43759\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8153 - loss: 0.4025 - precision: 0.7896 - recall: 0.6045 - val_accuracy: 0.8045 - val_loss: 0.4380 - val_precision: 0.7991 - val_recall: 0.5524 - learning_rate: 1.2500e-04\n",
            "Epoch 42: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d83689c6e10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_mobilenetv2 = load_model(\"best_model.keras\", custom_objects={\n",
        "    'recall': recall,\n",
        "    'precision': precision\n",
        "})\n",
        "\n",
        "best_mobilenetv2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "bhcdtdNf8Fi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624a456c-2dd8-4dea-9849-9ed3f62002bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8059 - loss: 0.4381 - precision: 0.7686 - recall: 0.5608\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4421641528606415, 0.5434606075286865, 0.77073734998703, 0.7939902544021606]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SqueezeNet - Ashley"
      ],
      "metadata": {
        "id": "GmupddkdGX-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fire_module(x, squeeze, expand):\n",
        "    x = layers.Conv2D(squeeze, (1,1), activation='relu', padding='same')(x)\n",
        "    left = layers.Conv2D(expand, (1,1), activation='relu', padding='same')(x)\n",
        "    right = layers.Conv2D(expand, (3,3), activation='relu', padding='same')(x)\n",
        "    return layers.concatenate([left, right], axis=-1)\n",
        "\n",
        "def create_squeezenet(input_shape=(32, 32, 3), squeeze=16):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(96, (7,7), strides=(2,2), activation='relu', padding='same')(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
        "    x = fire_module(x, squeeze, 64)\n",
        "    x = fire_module(x, squeeze, 64)\n",
        "    x = fire_module(x, squeeze * 2, 128)\n",
        "    x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
        "    x = fire_module(x, 32, 128)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "h3xSJIjD_eHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squeezenet = create_squeezenet()\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "]\n",
        "\n",
        "squeezenet.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[recall, precision, 'accuracy']\n",
        ")\n",
        "\n",
        "squeezenet.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=16, epochs=20, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-1k642I_hln",
        "outputId": "4c723f37-6624-40dc-ab87-c40e52d2bb9e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7284 - loss: 0.5354 - precision: 0.8479 - recall: 0.6168\n",
            "Epoch 1: val_loss improved from inf to 0.32407, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 58ms/step - accuracy: 0.7286 - loss: 0.5352 - precision: 0.8478 - recall: 0.6169 - val_accuracy: 0.8714 - val_loss: 0.3241 - val_precision: 0.8987 - val_recall: 0.6921 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8854 - loss: 0.3015 - precision: 0.8619 - recall: 0.7730\n",
            "Epoch 2: val_loss improved from 0.32407 to 0.27172, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 52ms/step - accuracy: 0.8854 - loss: 0.3015 - precision: 0.8620 - recall: 0.7730 - val_accuracy: 0.8971 - val_loss: 0.2717 - val_precision: 0.8782 - val_recall: 0.8026 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8956 - loss: 0.2716 - precision: 0.8935 - recall: 0.7834\n",
            "Epoch 3: val_loss improved from 0.27172 to 0.22746, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - accuracy: 0.8956 - loss: 0.2716 - precision: 0.8935 - recall: 0.7835 - val_accuracy: 0.9191 - val_loss: 0.2275 - val_precision: 0.9380 - val_recall: 0.8107 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9141 - loss: 0.2312 - precision: 0.9177 - recall: 0.8172\n",
            "Epoch 4: val_loss did not improve from 0.22746\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 58ms/step - accuracy: 0.9141 - loss: 0.2312 - precision: 0.9177 - recall: 0.8172 - val_accuracy: 0.9139 - val_loss: 0.2301 - val_precision: 0.8649 - val_recall: 0.8790 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9265 - loss: 0.2004 - precision: 0.9353 - recall: 0.8377\n",
            "Epoch 5: val_loss did not improve from 0.22746\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 54ms/step - accuracy: 0.9265 - loss: 0.2004 - precision: 0.9353 - recall: 0.8377 - val_accuracy: 0.8936 - val_loss: 0.2843 - val_precision: 0.8085 - val_recall: 0.8920 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9373 - loss: 0.1745 - precision: 0.9444 - recall: 0.8593\n",
            "Epoch 6: val_loss did not improve from 0.22746\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.9373 - loss: 0.1745 - precision: 0.9444 - recall: 0.8593 - val_accuracy: 0.9153 - val_loss: 0.2292 - val_precision: 0.8672 - val_recall: 0.8806 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9473 - loss: 0.1584 - precision: 0.9621 - recall: 0.8768\n",
            "Epoch 7: val_loss improved from 0.22746 to 0.18225, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.9473 - loss: 0.1583 - precision: 0.9621 - recall: 0.8768 - val_accuracy: 0.9318 - val_loss: 0.1822 - val_precision: 0.9187 - val_recall: 0.8725 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9491 - loss: 0.1478 - precision: 0.9638 - recall: 0.8829\n",
            "Epoch 8: val_loss did not improve from 0.18225\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - accuracy: 0.9491 - loss: 0.1478 - precision: 0.9638 - recall: 0.8829 - val_accuracy: 0.9288 - val_loss: 0.1897 - val_precision: 0.9540 - val_recall: 0.8262 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9479 - loss: 0.1450 - precision: 0.9663 - recall: 0.8772\n",
            "Epoch 9: val_loss improved from 0.18225 to 0.17813, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 53ms/step - accuracy: 0.9479 - loss: 0.1450 - precision: 0.9662 - recall: 0.8772 - val_accuracy: 0.9329 - val_loss: 0.1781 - val_precision: 0.9255 - val_recall: 0.8684 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9550 - loss: 0.1253 - precision: 0.9682 - recall: 0.8919\n",
            "Epoch 10: val_loss improved from 0.17813 to 0.17628, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 55ms/step - accuracy: 0.9550 - loss: 0.1253 - precision: 0.9682 - recall: 0.8919 - val_accuracy: 0.9361 - val_loss: 0.1763 - val_precision: 0.9430 - val_recall: 0.8603 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9542 - loss: 0.1219 - precision: 0.9634 - recall: 0.8947\n",
            "Epoch 11: val_loss did not improve from 0.17628\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - accuracy: 0.9542 - loss: 0.1219 - precision: 0.9634 - recall: 0.8947 - val_accuracy: 0.9342 - val_loss: 0.1810 - val_precision: 0.9687 - val_recall: 0.8294 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9584 - loss: 0.1111 - precision: 0.9700 - recall: 0.9031\n",
            "Epoch 12: val_loss improved from 0.17628 to 0.17250, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - accuracy: 0.9584 - loss: 0.1111 - precision: 0.9699 - recall: 0.9031 - val_accuracy: 0.9383 - val_loss: 0.1725 - val_precision: 0.9522 - val_recall: 0.8578 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9645 - loss: 0.1046 - precision: 0.9757 - recall: 0.9175\n",
            "Epoch 13: val_loss did not improve from 0.17250\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.9645 - loss: 0.1046 - precision: 0.9757 - recall: 0.9175 - val_accuracy: 0.9391 - val_loss: 0.1796 - val_precision: 0.9292 - val_recall: 0.8846 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9644 - loss: 0.0997 - precision: 0.9713 - recall: 0.9175\n",
            "Epoch 14: val_loss did not improve from 0.17250\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 53ms/step - accuracy: 0.9644 - loss: 0.0997 - precision: 0.9713 - recall: 0.9175 - val_accuracy: 0.9402 - val_loss: 0.1898 - val_precision: 0.9346 - val_recall: 0.8822 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9647 - loss: 0.0908 - precision: 0.9710 - recall: 0.9232\n",
            "Epoch 15: val_loss did not improve from 0.17250\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 54ms/step - accuracy: 0.9647 - loss: 0.0908 - precision: 0.9710 - recall: 0.9232 - val_accuracy: 0.9280 - val_loss: 0.2345 - val_precision: 0.9726 - val_recall: 0.8067 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9725 - loss: 0.0764 - precision: 0.9787 - recall: 0.9370\n",
            "Epoch 16: val_loss did not improve from 0.17250\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 54ms/step - accuracy: 0.9725 - loss: 0.0764 - precision: 0.9787 - recall: 0.9370 - val_accuracy: 0.9399 - val_loss: 0.2222 - val_precision: 0.9152 - val_recall: 0.9033 - learning_rate: 2.5000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9783 - loss: 0.0600 - precision: 0.9855 - recall: 0.9484\n",
            "Epoch 17: val_loss did not improve from 0.17250\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 51ms/step - accuracy: 0.9783 - loss: 0.0600 - precision: 0.9855 - recall: 0.9484 - val_accuracy: 0.9345 - val_loss: 0.2428 - val_precision: 0.9011 - val_recall: 0.9025 - learning_rate: 2.5000e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c3f0ceaf990>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_squeezenet = load_model(\"best_model.keras\", custom_objects={\n",
        "    'recall': recall,\n",
        "    'precision': precision\n",
        "})\n",
        "\n",
        "best_squeezenet.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "YWCkEu6-8Phi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a07b64-9704-4252-d361-7880ff89a1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9428 - loss: 0.1732 - precision: 0.9524 - recall: 0.8629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16746650636196136,\n",
              " 0.8740860819816589,\n",
              " 0.9547471404075623,\n",
              " 0.9442338943481445]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CV"
      ],
      "metadata": {
        "id": "y7q76oq2Fj85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [8, 16, 32]\n",
        "squeeze_values = [8, 16, 32]\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_recall_queezenet = -np.inf\n",
        "best_config_queezenet = None\n",
        "best_squeezenet = None\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    for squeeze in squeeze_values:\n",
        "          val_acc, val_rec, val_prec = [], [], []\n",
        "          for train_index, val_index in kf.split(X_train_new):\n",
        "              X_train, X_val = X_train_new[train_index], X_train_new[val_index]\n",
        "              y_train, y_val = y_train_new[train_index], y_train_new[val_index]\n",
        "\n",
        "              squeezenet = create_squeezenet(squeeze=squeeze)\n",
        "\n",
        "              callbacks = [\n",
        "                  ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
        "                  ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=0),\n",
        "                  EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=0),\n",
        "              ]\n",
        "\n",
        "              squeezenet.compile(\n",
        "                  optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[recall, precision, 'accuracy']\n",
        "              )\n",
        "\n",
        "              squeezenet.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=20, callbacks=callbacks, verbose=0)\n",
        "\n",
        "              best_model = load_model(\"best_model.keras\", custom_objects={\n",
        "                  'recall': recall,\n",
        "                  'precision': precision\n",
        "              })\n",
        "\n",
        "              scores = best_model.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "              val_acc.append(scores[3])\n",
        "              val_rec.append(scores[1])\n",
        "              val_prec.append(scores[2])\n",
        "\n",
        "          if np.mean(val_rec) > best_recall_queezenet:\n",
        "              best_recall_queezenet = np.mean(val_rec)\n",
        "              best_config_queezenet = {\n",
        "                  'batch_size': batch_size,\n",
        "                  'squeeze': squeeze,\n",
        "                  'accuracy': np.mean(val_acc),\n",
        "                  'recall': np.mean(val_rec),\n",
        "                  'precision': np.mean(val_prec)\n",
        "              }\n",
        "              best_squeezenet = best_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuUxZ7E0Fh0U",
        "outputId": "35097ca9-f8a5-49ff-816f-8d2ffd0d4a20",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.33170, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.33170 to 0.29955, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.29955 to 0.21581, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.21581 to 0.21263, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.21263\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21263 to 0.17855, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.17855\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17855\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.17855\n",
            "\n",
            "Epoch 10: val_loss improved from 0.17855 to 0.16800, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16800\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16800\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16800\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16800\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16800\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.33177, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.33177 to 0.27407, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.27407 to 0.21772, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.21772\n",
            "\n",
            "Epoch 5: val_loss improved from 0.21772 to 0.18427, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.18427\n",
            "\n",
            "Epoch 7: val_loss improved from 0.18427 to 0.18340, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss improved from 0.18340 to 0.15799, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.15799\n",
            "\n",
            "Epoch 10: val_loss improved from 0.15799 to 0.15615, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.15615\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.15615\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15615\n",
            "\n",
            "Epoch 14: val_loss improved from 0.15615 to 0.15337, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15337\n",
            "\n",
            "Epoch 16: val_loss improved from 0.15337 to 0.14553, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14553\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14553\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14553\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.14553\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32177, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32177 to 0.26506, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.26506 to 0.22581, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22581 to 0.21194, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.21194\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21194 to 0.20524, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.20524\n",
            "\n",
            "Epoch 8: val_loss improved from 0.20524 to 0.17871, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.17871\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17871\n",
            "\n",
            "Epoch 11: val_loss improved from 0.17871 to 0.17173, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.17173\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.17173\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.17173\n",
            "\n",
            "Epoch 15: val_loss improved from 0.17173 to 0.16598, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16598\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16598\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16598\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.16598\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.16598\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.31168, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.31168\n",
            "\n",
            "Epoch 3: val_loss improved from 0.31168 to 0.24475, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.24475 to 0.19803, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.19803\n",
            "\n",
            "Epoch 6: val_loss improved from 0.19803 to 0.18478, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.18478\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.18478\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.18478\n",
            "\n",
            "Epoch 10: val_loss improved from 0.18478 to 0.16917, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16917\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16917\n",
            "\n",
            "Epoch 13: val_loss improved from 0.16917 to 0.16911, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16911\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16911\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16911\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16911\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16911\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.38412, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.38412 to 0.30567, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.30567 to 0.25102, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.25102 to 0.20450, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.20450\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.20450\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20450 to 0.19493, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.19493\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.19493\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.19493\n",
            "\n",
            "Epoch 11: val_loss improved from 0.19493 to 0.18460, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.18460\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.18460\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.18460\n",
            "\n",
            "Epoch 15: val_loss improved from 0.18460 to 0.18083, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.18083\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.18083\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.18083\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.18083\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.18083\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.50448, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.50448 to 0.25782, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.25782 to 0.22457, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22457 to 0.20007, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.20007\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.20007\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.20007\n",
            "\n",
            "Epoch 8: val_loss improved from 0.20007 to 0.16629, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.16629\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16629\n",
            "\n",
            "Epoch 11: val_loss improved from 0.16629 to 0.16120, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16120\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16120\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16120\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16120\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16120\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.30560, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.30560 to 0.23238, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.23238\n",
            "\n",
            "Epoch 4: val_loss improved from 0.23238 to 0.21234, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.21234\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21234 to 0.20350, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20350 to 0.17503, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17503\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17503 to 0.15874, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.15874\n",
            "\n",
            "Epoch 11: val_loss improved from 0.15874 to 0.15730, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.15730\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15730\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.15730\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15730\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.15730\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.39079, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.39079 to 0.25543, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.25543 to 0.23366, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.23366\n",
            "\n",
            "Epoch 5: val_loss improved from 0.23366 to 0.21378, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21378 to 0.19307, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19307 to 0.19046, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.19046\n",
            "\n",
            "Epoch 9: val_loss improved from 0.19046 to 0.18337, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.18337\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.18337\n",
            "\n",
            "Epoch 12: val_loss improved from 0.18337 to 0.17078, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.17078\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.17078\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.17078\n",
            "\n",
            "Epoch 16: val_loss improved from 0.17078 to 0.16488, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16488\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16488\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.16488\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.16488\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.34511, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.34511 to 0.23368, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.23368 to 0.22459, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22459 to 0.22403, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.22403 to 0.17995, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.17995\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.17995\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17995\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17995 to 0.16992, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16992\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16992\n",
            "\n",
            "Epoch 12: val_loss improved from 0.16992 to 0.16526, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16526\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16526\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16526\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16526\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16526\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.34123, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.34123 to 0.28565, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.28565 to 0.21850, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.21850 to 0.21029, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.21029 to 0.20145, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.20145 to 0.19792, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19792 to 0.18264, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.18264\n",
            "\n",
            "Epoch 9: val_loss improved from 0.18264 to 0.17906, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss improved from 0.17906 to 0.16818, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16818\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16818\n",
            "\n",
            "Epoch 13: val_loss improved from 0.16818 to 0.16534, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16534\n",
            "\n",
            "Epoch 15: val_loss improved from 0.16534 to 0.16500, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16500\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16500\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16500\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.16500\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.16500\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.31609, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.31609 to 0.31387, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.31387 to 0.23089, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.23089 to 0.22756, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.22756 to 0.21778, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21778 to 0.18759, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.18759\n",
            "\n",
            "Epoch 8: val_loss improved from 0.18759 to 0.17005, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.17005\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17005\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.17005\n",
            "\n",
            "Epoch 12: val_loss improved from 0.17005 to 0.16299, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16299\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16299\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16299\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16299\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16299\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.34016, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.34016 to 0.27748, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.27748 to 0.19524, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.19524\n",
            "\n",
            "Epoch 5: val_loss improved from 0.19524 to 0.17960, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.17960 to 0.16253, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.16253\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.16253\n",
            "\n",
            "Epoch 9: val_loss improved from 0.16253 to 0.15476, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.15476\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.15476\n",
            "\n",
            "Epoch 12: val_loss improved from 0.15476 to 0.13491, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.13491\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.13491\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.13491\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.13491\n",
            "\n",
            "Epoch 17: val_loss improved from 0.13491 to 0.12900, saving model to best_model.keras\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.12900\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.12900\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.12900\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.35170, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.35170\n",
            "\n",
            "Epoch 3: val_loss improved from 0.35170 to 0.22827, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22827 to 0.20983, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.20983 to 0.20178, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.20178 to 0.19434, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.19434\n",
            "\n",
            "Epoch 8: val_loss improved from 0.19434 to 0.17953, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17953 to 0.17403, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17403\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.17403\n",
            "\n",
            "Epoch 12: val_loss improved from 0.17403 to 0.17165, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.17165\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.17165\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.17165\n",
            "\n",
            "Epoch 16: val_loss improved from 0.17165 to 0.17159, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.17159\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.17159\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.17159\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.17159\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32648, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32648 to 0.24289, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.24289 to 0.24088, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.24088 to 0.19049, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.19049\n",
            "\n",
            "Epoch 6: val_loss improved from 0.19049 to 0.16780, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.16780\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.16780\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.16780\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16780\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16780\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.37141, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.37141 to 0.31862, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.31862 to 0.22349, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.22349\n",
            "\n",
            "Epoch 5: val_loss improved from 0.22349 to 0.19322, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19322\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.19322\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.19322\n",
            "\n",
            "Epoch 9: val_loss improved from 0.19322 to 0.18705, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.18705\n",
            "\n",
            "Epoch 11: val_loss improved from 0.18705 to 0.18213, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.18213\n",
            "\n",
            "Epoch 13: val_loss improved from 0.18213 to 0.17097, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.17097\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.17097\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.17097\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.17097\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.17097\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.31270, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.31270 to 0.27760, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.27760 to 0.20304, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.20304\n",
            "\n",
            "Epoch 5: val_loss improved from 0.20304 to 0.19512, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19512\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.19512\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.19512\n",
            "\n",
            "Epoch 9: val_loss improved from 0.19512 to 0.16614, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16614\n",
            "\n",
            "Epoch 11: val_loss improved from 0.16614 to 0.15698, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss improved from 0.15698 to 0.15494, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss improved from 0.15494 to 0.15290, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.15290\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15290\n",
            "\n",
            "Epoch 16: val_loss improved from 0.15290 to 0.14497, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14497\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14497\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14497\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.14497\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32243, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32243 to 0.27767, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.27767\n",
            "\n",
            "Epoch 4: val_loss improved from 0.27767 to 0.20218, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.20218 to 0.19556, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19556\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19556 to 0.18656, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.18656\n",
            "\n",
            "Epoch 9: val_loss improved from 0.18656 to 0.16043, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16043\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16043\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16043\n",
            "\n",
            "Epoch 13: val_loss improved from 0.16043 to 0.14120, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.14120\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14120\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14120\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14120\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14120\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.33371, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.33371 to 0.27089, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.27089 to 0.24795, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.24795 to 0.21261, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.21261\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21261 to 0.20116, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20116 to 0.20052, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.20052\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.20052\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.20052\n",
            "\n",
            "Epoch 11: val_loss improved from 0.20052 to 0.18256, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.18256\n",
            "\n",
            "Epoch 13: val_loss improved from 0.18256 to 0.18129, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss improved from 0.18129 to 0.17574, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss improved from 0.17574 to 0.17159, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss improved from 0.17159 to 0.16913, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss improved from 0.16913 to 0.16621, saving model to best_model.keras\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16621\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.16621\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.16621\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.33119, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.33119 to 0.26278, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.26278 to 0.22401, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22401 to 0.20915, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.20915 to 0.19355, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.19355 to 0.18366, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.18366\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.18366\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.18366\n",
            "\n",
            "Epoch 10: val_loss improved from 0.18366 to 0.16866, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss improved from 0.16866 to 0.16266, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16266\n",
            "\n",
            "Epoch 13: val_loss improved from 0.16266 to 0.15564, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.15564\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15564\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.15564\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.15564\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.15564\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.35626, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.35626 to 0.26736, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.26736\n",
            "\n",
            "Epoch 4: val_loss improved from 0.26736 to 0.25974, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.25974 to 0.19722, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19722\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19722 to 0.19238, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.19238\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.19238\n",
            "\n",
            "Epoch 10: val_loss improved from 0.19238 to 0.18168, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.18168\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.18168\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.18168\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.18168\n",
            "\n",
            "Epoch 15: val_loss improved from 0.18168 to 0.18089, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.18089\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.18089\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.18089\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.18089\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.18089\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32765, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32765 to 0.31455, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.31455\n",
            "\n",
            "Epoch 4: val_loss improved from 0.31455 to 0.21758, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.21758\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21758 to 0.20002, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.20002\n",
            "\n",
            "Epoch 8: val_loss improved from 0.20002 to 0.18419, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.18419\n",
            "\n",
            "Epoch 10: val_loss improved from 0.18419 to 0.17737, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss improved from 0.17737 to 0.17538, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss improved from 0.17538 to 0.15949, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15949\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.15949\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15949\n",
            "\n",
            "Epoch 16: val_loss improved from 0.15949 to 0.14116, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14116\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14116\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14116\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.14116\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32544, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32544 to 0.21677, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.21677\n",
            "\n",
            "Epoch 4: val_loss improved from 0.21677 to 0.17709, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.17709\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.17709\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.17709\n",
            "\n",
            "Epoch 8: val_loss improved from 0.17709 to 0.15837, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.15837\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.15837\n",
            "\n",
            "Epoch 11: val_loss improved from 0.15837 to 0.14650, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.14650\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.14650\n",
            "\n",
            "Epoch 14: val_loss improved from 0.14650 to 0.14277, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14277\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14277\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14277\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14277\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14277\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.34361, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.34361 to 0.24576, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.24576 to 0.22004, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22004 to 0.21383, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.21383 to 0.21260, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21260 to 0.20053, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20053 to 0.16978, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.16978\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.16978\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16978\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16978\n",
            "\n",
            "Epoch 12: val_loss improved from 0.16978 to 0.16200, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16200\n",
            "\n",
            "Epoch 14: val_loss improved from 0.16200 to 0.14802, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14802\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14802\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14802\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14802\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14802\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.30323, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.30323 to 0.28445, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.28445 to 0.20796, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.20796 to 0.20280, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.20280 to 0.18482, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.18482\n",
            "\n",
            "Epoch 7: val_loss improved from 0.18482 to 0.18105, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss improved from 0.18105 to 0.16950, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss improved from 0.16950 to 0.16577, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16577\n",
            "\n",
            "Epoch 11: val_loss improved from 0.16577 to 0.16097, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16097\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16097\n",
            "\n",
            "Epoch 14: val_loss improved from 0.16097 to 0.15571, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15571\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.15571\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.15571\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.15571\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.15571\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.43862, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.43862 to 0.24165, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.24165 to 0.23642, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.23642 to 0.21854, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.21854 to 0.20831, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.20831 to 0.19830, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.19830\n",
            "\n",
            "Epoch 8: val_loss improved from 0.19830 to 0.19559, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.19559\n",
            "\n",
            "Epoch 10: val_loss improved from 0.19559 to 0.18190, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss improved from 0.18190 to 0.17600, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss improved from 0.17600 to 0.16983, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss improved from 0.16983 to 0.16541, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16541\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16541\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16541\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16541\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16541\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.41419, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.41419 to 0.24528, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.24528 to 0.20760, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.20760\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.20760\n",
            "\n",
            "Epoch 6: val_loss improved from 0.20760 to 0.17730, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.17730\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17730\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.17730\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17730\n",
            "\n",
            "Epoch 11: val_loss improved from 0.17730 to 0.17075, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss improved from 0.17075 to 0.16588, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16588\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16588\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16588\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16588\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16588\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32619, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32619 to 0.21827, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.21827\n",
            "\n",
            "Epoch 4: val_loss improved from 0.21827 to 0.16759, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.16759 to 0.15612, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.15612\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.15612\n",
            "\n",
            "Epoch 8: val_loss improved from 0.15612 to 0.14469, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.14469\n",
            "\n",
            "Epoch 10: val_loss improved from 0.14469 to 0.14149, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.14149\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.14149\n",
            "\n",
            "Epoch 13: val_loss improved from 0.14149 to 0.13829, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.13829\n",
            "\n",
            "Epoch 15: val_loss improved from 0.13829 to 0.13443, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.13443\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.13443\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.13443\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.13443\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.13443\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.31776, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.31776 to 0.24969, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.24969 to 0.20423, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.20423 to 0.19309, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.19309\n",
            "\n",
            "Epoch 6: val_loss improved from 0.19309 to 0.17552, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.17552\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17552\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.17552\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17552\n",
            "\n",
            "Epoch 11: val_loss improved from 0.17552 to 0.15771, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 15: val_loss improved from 0.15771 to 0.15353, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.15353\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.15353\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.15353\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.15353\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.15353\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.37636, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.37636 to 0.23887, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.23887 to 0.21280, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.21280 to 0.19773, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.19773\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19773\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.19773\n",
            "\n",
            "Epoch 8: val_loss improved from 0.19773 to 0.15066, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.15066\n",
            "\n",
            "Epoch 10: val_loss improved from 0.15066 to 0.14576, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss improved from 0.14576 to 0.14290, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.14290\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.14290\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.14290\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14290\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14290\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32984, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32984 to 0.26441, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.26441 to 0.21919, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.21919 to 0.19633, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.19633\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19633\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19633 to 0.17380, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17380\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17380 to 0.17239, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17239\n",
            "\n",
            "Epoch 11: val_loss improved from 0.17239 to 0.15771, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.15771\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32570, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.32570\n",
            "\n",
            "Epoch 3: val_loss improved from 0.32570 to 0.22558, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22558 to 0.19334, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.19334\n",
            "\n",
            "Epoch 6: val_loss improved from 0.19334 to 0.18654, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.18654 to 0.16872, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss improved from 0.16872 to 0.16739, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.16739\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16739\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16739\n",
            "\n",
            "Epoch 12: val_loss improved from 0.16739 to 0.15156, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15156\n",
            "\n",
            "Epoch 14: val_loss improved from 0.15156 to 0.14513, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14513\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14513\n",
            "\n",
            "Epoch 17: val_loss improved from 0.14513 to 0.14280, saving model to best_model.keras\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14280\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14280\n",
            "\n",
            "Epoch 20: val_loss improved from 0.14280 to 0.13896, saving model to best_model.keras\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.31766, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.31766 to 0.26386, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.26386 to 0.23243, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.23243 to 0.19025, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.19025 to 0.17885, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.17885\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.17885\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17885\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17885 to 0.15062, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.15062\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.15062\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.15062\n",
            "\n",
            "Epoch 13: val_loss improved from 0.15062 to 0.14945, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.14945\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14945\n",
            "\n",
            "Epoch 16: val_loss improved from 0.14945 to 0.14786, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss improved from 0.14786 to 0.13932, saving model to best_model.keras\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.13932\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.13932\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.13932\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.37036, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.37036 to 0.30194, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.30194 to 0.25900, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.25900 to 0.24298, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.24298 to 0.21113, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21113 to 0.20552, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20552 to 0.17850, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17850\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17850 to 0.17316, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17316\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.17316\n",
            "\n",
            "Epoch 12: val_loss improved from 0.17316 to 0.16591, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16591\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16591\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16591\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16591\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16591\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.34525, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.34525 to 0.28488, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.28488 to 0.25310, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.25310\n",
            "\n",
            "Epoch 5: val_loss improved from 0.25310 to 0.21546, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21546 to 0.18105, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.18105\n",
            "\n",
            "Epoch 8: val_loss improved from 0.18105 to 0.18025, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss improved from 0.18025 to 0.16306, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16306\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16306\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16306\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16306\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16306\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.36095, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.36095 to 0.27423, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.27423\n",
            "\n",
            "Epoch 4: val_loss improved from 0.27423 to 0.21832, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.21832 to 0.20867, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.20867 to 0.20841, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20841 to 0.20601, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.20601\n",
            "\n",
            "Epoch 9: val_loss improved from 0.20601 to 0.19407, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss improved from 0.19407 to 0.19002, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss improved from 0.19002 to 0.17706, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.17706\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.17706\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.17706\n",
            "\n",
            "Epoch 15: val_loss improved from 0.17706 to 0.17052, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.17052\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.17052\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.17052\n",
            "\n",
            "Epoch 19: val_loss improved from 0.17052 to 0.17008, saving model to best_model.keras\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.17008\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32889, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32889 to 0.26542, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.26542 to 0.20265, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.20265\n",
            "\n",
            "Epoch 5: val_loss improved from 0.20265 to 0.20048, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.20048\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20048 to 0.17598, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss improved from 0.17598 to 0.17116, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.17116\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.17116\n",
            "\n",
            "Epoch 11: val_loss improved from 0.17116 to 0.16122, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16122\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16122\n",
            "\n",
            "Epoch 14: val_loss improved from 0.16122 to 0.16001, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16001\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16001\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16001\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16001\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.16001\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.31708, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.31708 to 0.26535, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.26535 to 0.21140, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.21140 to 0.18459, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.18459 to 0.16725, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.16725\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.16725\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.16725\n",
            "\n",
            "Epoch 9: val_loss improved from 0.16725 to 0.13820, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.13820\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.13820\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.13820\n",
            "\n",
            "Epoch 13: val_loss improved from 0.13820 to 0.13504, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss improved from 0.13504 to 0.12851, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.12851\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.12851\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.12851\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.12851\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.12851\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.33696, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.33696 to 0.28930, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.28930 to 0.23889, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.23889 to 0.22194, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.22194\n",
            "\n",
            "Epoch 6: val_loss improved from 0.22194 to 0.21238, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.21238 to 0.18016, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.18016\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.18016\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.18016\n",
            "\n",
            "Epoch 11: val_loss improved from 0.18016 to 0.16992, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16992\n",
            "\n",
            "Epoch 13: val_loss improved from 0.16992 to 0.16092, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16092\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16092\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16092\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16092\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.16092\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32128, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32128 to 0.25258, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.25258\n",
            "\n",
            "Epoch 4: val_loss improved from 0.25258 to 0.23286, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.23286 to 0.19728, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19728\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.19728\n",
            "\n",
            "Epoch 8: val_loss improved from 0.19728 to 0.18424, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.18424\n",
            "\n",
            "Epoch 10: val_loss improved from 0.18424 to 0.16567, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.16567\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.16567\n",
            "\n",
            "Epoch 13: val_loss improved from 0.16567 to 0.16492, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16492\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16492\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16492\n",
            "\n",
            "Epoch 17: val_loss improved from 0.16492 to 0.14116, saving model to best_model.keras\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14116\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14116\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.14116\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.32194, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.32194 to 0.26434, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.26434 to 0.24290, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.24290 to 0.20955, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.20955 to 0.20245, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.20245 to 0.19356, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19356 to 0.18515, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss improved from 0.18515 to 0.18103, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.18103\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.18103\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.18103\n",
            "\n",
            "Epoch 12: val_loss improved from 0.18103 to 0.16229, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16229\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.16229\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.16229\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.16229\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.16229\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.36118, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.36118 to 0.24413, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.24413\n",
            "\n",
            "Epoch 4: val_loss improved from 0.24413 to 0.24147, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss improved from 0.24147 to 0.22828, saving model to best_model.keras\n",
            "\n",
            "Epoch 6: val_loss improved from 0.22828 to 0.19324, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.19324\n",
            "\n",
            "Epoch 8: val_loss improved from 0.19324 to 0.16529, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss improved from 0.16529 to 0.15955, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss improved from 0.15955 to 0.15724, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss improved from 0.15724 to 0.14685, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.14685\n",
            "\n",
            "Epoch 13: val_loss improved from 0.14685 to 0.14550, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.14550\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14550\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14550\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14550\n",
            "\n",
            "Epoch 18: val_loss improved from 0.14550 to 0.14018, saving model to best_model.keras\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14018\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.14018\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.38724, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.38724 to 0.25449, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.25449\n",
            "\n",
            "Epoch 4: val_loss improved from 0.25449 to 0.19090, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.19090\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.19090\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19090 to 0.17183, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss improved from 0.17183 to 0.16872, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss improved from 0.16872 to 0.16501, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss improved from 0.16501 to 0.14779, saving model to best_model.keras\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.14779\n",
            "\n",
            "Epoch 12: val_loss improved from 0.14779 to 0.14601, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.14601\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.14601\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14601\n",
            "\n",
            "Epoch 16: val_loss improved from 0.14601 to 0.13273, saving model to best_model.keras\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.13273\n",
            "\n",
            "Epoch 18: val_loss improved from 0.13273 to 0.13104, saving model to best_model.keras\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.13104\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.13104\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.34310, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.34310 to 0.24342, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.24342 to 0.22910, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.22910 to 0.20047, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.20047\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.20047\n",
            "\n",
            "Epoch 7: val_loss improved from 0.20047 to 0.17334, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17334\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17334 to 0.16943, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16943\n",
            "\n",
            "Epoch 11: val_loss improved from 0.16943 to 0.16759, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss improved from 0.16759 to 0.16738, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.16738\n",
            "\n",
            "Epoch 14: val_loss improved from 0.16738 to 0.15801, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15801\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.15801\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.15801\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.15801\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.15801\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.33432, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.33432 to 0.25712, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.25712\n",
            "\n",
            "Epoch 4: val_loss improved from 0.25712 to 0.20407, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.20407\n",
            "\n",
            "Epoch 6: val_loss improved from 0.20407 to 0.19682, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.19682 to 0.17120, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.17120\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17120 to 0.15263, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.15263\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.15263\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.15263\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15263\n",
            "\n",
            "Epoch 14: val_loss improved from 0.15263 to 0.14891, saving model to best_model.keras\n",
            "\n",
            "Epoch 15: val_loss improved from 0.14891 to 0.14388, saving model to best_model.keras\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14388\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14388\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14388\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.14388\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.14388\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.38584, saving model to best_model.keras\n",
            "\n",
            "Epoch 2: val_loss improved from 0.38584 to 0.34860, saving model to best_model.keras\n",
            "\n",
            "Epoch 3: val_loss improved from 0.34860 to 0.30031, saving model to best_model.keras\n",
            "\n",
            "Epoch 4: val_loss improved from 0.30031 to 0.21153, saving model to best_model.keras\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.21153\n",
            "\n",
            "Epoch 6: val_loss improved from 0.21153 to 0.18301, saving model to best_model.keras\n",
            "\n",
            "Epoch 7: val_loss improved from 0.18301 to 0.17803, saving model to best_model.keras\n",
            "\n",
            "Epoch 8: val_loss improved from 0.17803 to 0.17093, saving model to best_model.keras\n",
            "\n",
            "Epoch 9: val_loss improved from 0.17093 to 0.16328, saving model to best_model.keras\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.16328\n",
            "\n",
            "Epoch 11: val_loss improved from 0.16328 to 0.16073, saving model to best_model.keras\n",
            "\n",
            "Epoch 12: val_loss improved from 0.16073 to 0.15013, saving model to best_model.keras\n",
            "\n",
            "Epoch 13: val_loss improved from 0.15013 to 0.14785, saving model to best_model.keras\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.14785\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.14785\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.14785\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.14785\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.14785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best configuration for SuqeezeNet:\", best_config_queezenet)"
      ],
      "metadata": {
        "id": "WIGD93vnOR6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655f0017-d295-43dd-cfab-191ff63ab853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best configuration for SuqeezeNet: {'batch_size': 32, 'squeeze': 32, 'accuracy': np.float64(0.9514008641242981), 'recall': np.float64(0.8972260594367981), 'precision': np.float64(0.9544788479804993)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_squeezenet.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "zXEKKhZGxdD2",
        "outputId": "d05f2e2a-61ed-4643-cc6e-1c7f0457388c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9410 - loss: 0.1622 - precision: 0.9278 - recall: 0.8830\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15424826741218567,\n",
              " 0.8976441621780396,\n",
              " 0.9324894547462463,\n",
              " 0.9442338943481445]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGGNet - Ashley"
      ],
      "metadata": {
        "id": "_3a03WfHLhfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg(input_shape=(32, 32, 3)):\n",
        "    base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "E4bC587RLhJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = build_vgg()\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "]\n",
        "\n",
        "vgg.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[recall, precision, 'accuracy']\n",
        ")\n",
        "\n",
        "vgg.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=16, epochs=50, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42_Btx8nNpQ2",
        "outputId": "926460e2-3b93-42e8-8b2c-71913c94b09d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8269 - loss: 0.4163 - precision: 0.9017 - recall: 0.7320\n",
            "Epoch 1: val_loss improved from inf to 0.24397, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8270 - loss: 0.4162 - precision: 0.9017 - recall: 0.7320 - val_accuracy: 0.9136 - val_loss: 0.2440 - val_precision: 0.9262 - val_recall: 0.8050 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9169 - loss: 0.2291 - precision: 0.9118 - recall: 0.8296\n",
            "Epoch 2: val_loss improved from 0.24397 to 0.21743, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9169 - loss: 0.2291 - precision: 0.9118 - recall: 0.8296 - val_accuracy: 0.9207 - val_loss: 0.2174 - val_precision: 0.9114 - val_recall: 0.8440 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9254 - loss: 0.2016 - precision: 0.9276 - recall: 0.8454\n",
            "Epoch 3: val_loss did not improve from 0.21743\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9254 - loss: 0.2015 - precision: 0.9276 - recall: 0.8454 - val_accuracy: 0.9220 - val_loss: 0.2210 - val_precision: 0.9729 - val_recall: 0.7880 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9318 - loss: 0.1826 - precision: 0.9450 - recall: 0.8449\n",
            "Epoch 4: val_loss improved from 0.21743 to 0.21382, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9318 - loss: 0.1826 - precision: 0.9450 - recall: 0.8450 - val_accuracy: 0.9185 - val_loss: 0.2138 - val_precision: 0.8787 - val_recall: 0.8765 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9382 - loss: 0.1721 - precision: 0.9485 - recall: 0.8631\n",
            "Epoch 5: val_loss improved from 0.21382 to 0.21185, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9382 - loss: 0.1721 - precision: 0.9485 - recall: 0.8631 - val_accuracy: 0.9274 - val_loss: 0.2119 - val_precision: 0.9716 - val_recall: 0.8058 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9370 - loss: 0.1645 - precision: 0.9494 - recall: 0.8590\n",
            "Epoch 6: val_loss improved from 0.21185 to 0.18744, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.1645 - precision: 0.9495 - recall: 0.8590 - val_accuracy: 0.9296 - val_loss: 0.1874 - val_precision: 0.9466 - val_recall: 0.8359 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.1572 - precision: 0.9561 - recall: 0.8623\n",
            "Epoch 7: val_loss did not improve from 0.18744\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.1572 - precision: 0.9561 - recall: 0.8623 - val_accuracy: 0.9337 - val_loss: 0.1970 - val_precision: 0.9722 - val_recall: 0.8245 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9431 - loss: 0.1572 - precision: 0.9575 - recall: 0.8634\n",
            "Epoch 8: val_loss did not improve from 0.18744\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9431 - loss: 0.1572 - precision: 0.9575 - recall: 0.8634 - val_accuracy: 0.9358 - val_loss: 0.1879 - val_precision: 0.9706 - val_recall: 0.8327 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.1418 - precision: 0.9633 - recall: 0.8786\n",
            "Epoch 9: val_loss improved from 0.18744 to 0.18239, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.9494 - loss: 0.1419 - precision: 0.9632 - recall: 0.8785 - val_accuracy: 0.9334 - val_loss: 0.1824 - val_precision: 0.9722 - val_recall: 0.8237 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9460 - loss: 0.1494 - precision: 0.9579 - recall: 0.8704\n",
            "Epoch 10: val_loss did not improve from 0.18239\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9460 - loss: 0.1494 - precision: 0.9579 - recall: 0.8704 - val_accuracy: 0.9323 - val_loss: 0.1882 - val_precision: 0.9071 - val_recall: 0.8879 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m686/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.1396 - precision: 0.9608 - recall: 0.8880\n",
            "Epoch 11: val_loss improved from 0.18239 to 0.17898, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.1396 - precision: 0.9608 - recall: 0.8879 - val_accuracy: 0.9350 - val_loss: 0.1790 - val_precision: 0.9715 - val_recall: 0.8294 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.1367 - precision: 0.9667 - recall: 0.8830\n",
            "Epoch 12: val_loss improved from 0.17898 to 0.17711, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1367 - precision: 0.9667 - recall: 0.8830 - val_accuracy: 0.9348 - val_loss: 0.1771 - val_precision: 0.9260 - val_recall: 0.8741 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9483 - loss: 0.1423 - precision: 0.9601 - recall: 0.8785\n",
            "Epoch 13: val_loss improved from 0.17711 to 0.17579, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9483 - loss: 0.1423 - precision: 0.9601 - recall: 0.8785 - val_accuracy: 0.9396 - val_loss: 0.1758 - val_precision: 0.9684 - val_recall: 0.8465 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9487 - loss: 0.1404 - precision: 0.9626 - recall: 0.8779\n",
            "Epoch 14: val_loss improved from 0.17579 to 0.17235, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9487 - loss: 0.1403 - precision: 0.9626 - recall: 0.8779 - val_accuracy: 0.9391 - val_loss: 0.1724 - val_precision: 0.9710 - val_recall: 0.8424 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9524 - loss: 0.1305 - precision: 0.9652 - recall: 0.8916\n",
            "Epoch 15: val_loss did not improve from 0.17235\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9524 - loss: 0.1305 - precision: 0.9652 - recall: 0.8916 - val_accuracy: 0.9321 - val_loss: 0.1841 - val_precision: 0.9202 - val_recall: 0.8716 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9512 - loss: 0.1273 - precision: 0.9619 - recall: 0.8891\n",
            "Epoch 16: val_loss improved from 0.17235 to 0.17188, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1273 - precision: 0.9619 - recall: 0.8891 - val_accuracy: 0.9345 - val_loss: 0.1719 - val_precision: 0.9223 - val_recall: 0.8773 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.1245 - precision: 0.9659 - recall: 0.8889\n",
            "Epoch 17: val_loss did not improve from 0.17188\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9531 - loss: 0.1245 - precision: 0.9660 - recall: 0.8889 - val_accuracy: 0.9361 - val_loss: 0.1724 - val_precision: 0.9292 - val_recall: 0.8749 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m686/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9529 - loss: 0.1227 - precision: 0.9646 - recall: 0.8910\n",
            "Epoch 18: val_loss improved from 0.17188 to 0.16903, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9529 - loss: 0.1227 - precision: 0.9646 - recall: 0.8910 - val_accuracy: 0.9385 - val_loss: 0.1690 - val_precision: 0.9531 - val_recall: 0.8578 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.1188 - precision: 0.9767 - recall: 0.9006\n",
            "Epoch 19: val_loss did not improve from 0.16903\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9596 - loss: 0.1188 - precision: 0.9766 - recall: 0.9005 - val_accuracy: 0.9429 - val_loss: 0.1722 - val_precision: 0.9811 - val_recall: 0.8448 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9576 - loss: 0.1176 - precision: 0.9718 - recall: 0.9018\n",
            "Epoch 20: val_loss did not improve from 0.16903\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9576 - loss: 0.1176 - precision: 0.9718 - recall: 0.9018 - val_accuracy: 0.9399 - val_loss: 0.1743 - val_precision: 0.9755 - val_recall: 0.8408 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9532 - loss: 0.1228 - precision: 0.9680 - recall: 0.8893\n",
            "Epoch 21: val_loss improved from 0.16903 to 0.16277, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.9532 - loss: 0.1228 - precision: 0.9680 - recall: 0.8894 - val_accuracy: 0.9396 - val_loss: 0.1628 - val_precision: 0.9444 - val_recall: 0.8700 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m686/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9576 - loss: 0.1185 - precision: 0.9682 - recall: 0.9027\n",
            "Epoch 22: val_loss did not improve from 0.16277\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9575 - loss: 0.1185 - precision: 0.9682 - recall: 0.9026 - val_accuracy: 0.9413 - val_loss: 0.1676 - val_precision: 0.9535 - val_recall: 0.8660 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9612 - loss: 0.1076 - precision: 0.9718 - recall: 0.9095\n",
            "Epoch 23: val_loss did not improve from 0.16277\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9612 - loss: 0.1076 - precision: 0.9718 - recall: 0.9095 - val_accuracy: 0.9429 - val_loss: 0.1683 - val_precision: 0.9628 - val_recall: 0.8619 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.1122 - precision: 0.9695 - recall: 0.9073\n",
            "Epoch 24: val_loss did not improve from 0.16277\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9596 - loss: 0.1122 - precision: 0.9695 - recall: 0.9073 - val_accuracy: 0.9402 - val_loss: 0.1651 - val_precision: 0.9493 - val_recall: 0.8668 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.1047 - precision: 0.9791 - recall: 0.9080\n",
            "Epoch 25: val_loss did not improve from 0.16277\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9626 - loss: 0.1047 - precision: 0.9791 - recall: 0.9080 - val_accuracy: 0.9423 - val_loss: 0.1711 - val_precision: 0.9636 - val_recall: 0.8595 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9606 - loss: 0.1001 - precision: 0.9752 - recall: 0.9064\n",
            "Epoch 26: val_loss improved from 0.16277 to 0.16113, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9606 - loss: 0.1001 - precision: 0.9752 - recall: 0.9064 - val_accuracy: 0.9413 - val_loss: 0.1611 - val_precision: 0.9535 - val_recall: 0.8660 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.0954 - precision: 0.9809 - recall: 0.9156\n",
            "Epoch 27: val_loss did not improve from 0.16113\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9657 - loss: 0.0954 - precision: 0.9809 - recall: 0.9156 - val_accuracy: 0.9434 - val_loss: 0.1629 - val_precision: 0.9571 - val_recall: 0.8692 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9615 - loss: 0.1002 - precision: 0.9742 - recall: 0.9092\n",
            "Epoch 28: val_loss did not improve from 0.16113\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9615 - loss: 0.1002 - precision: 0.9742 - recall: 0.9093 - val_accuracy: 0.9429 - val_loss: 0.1666 - val_precision: 0.9645 - val_recall: 0.8603 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9618 - loss: 0.1010 - precision: 0.9729 - recall: 0.9097\n",
            "Epoch 29: val_loss did not improve from 0.16113\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9618 - loss: 0.1010 - precision: 0.9729 - recall: 0.9097 - val_accuracy: 0.9429 - val_loss: 0.1636 - val_precision: 0.9466 - val_recall: 0.8781 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9649 - loss: 0.0926 - precision: 0.9748 - recall: 0.9207\n",
            "Epoch 30: val_loss did not improve from 0.16113\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9649 - loss: 0.0926 - precision: 0.9748 - recall: 0.9207 - val_accuracy: 0.9429 - val_loss: 0.1628 - val_precision: 0.9570 - val_recall: 0.8676 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.0877 - precision: 0.9789 - recall: 0.9205\n",
            "Epoch 31: val_loss did not improve from 0.16113\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.0877 - precision: 0.9789 - recall: 0.9205 - val_accuracy: 0.9429 - val_loss: 0.1624 - val_precision: 0.9513 - val_recall: 0.8733 - learning_rate: 2.5000e-04\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c22f0677690>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_vgg = load_model(\"best_model.keras\", custom_objects={\n",
        "    'recall': recall,\n",
        "    'precision': precision\n",
        "})\n",
        "\n",
        "best_vgg.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLbBtSgXR2uJ",
        "outputId": "daf25a21-5386-4c6a-c12e-a1a86badb196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9501 - loss: 0.1571 - precision: 0.9593 - recall: 0.8800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16228215396404266,\n",
              " 0.8813972473144531,\n",
              " 0.9576346278190613,\n",
              " 0.9474824070930481]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cv-Shirina"
      ],
      "metadata": {
        "id": "X8ed7hqVt-DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================== (1) Configure paths ===================\n",
        "MODEL_FILE = '/content/drive/MyDrive/best_vgg_model.keras'\n",
        "CONFIG_FILE = '/content/drive/MyDrive/best_vgg_config.pkl'\n",
        "\n",
        "# =================== (2) Check files ===================\n",
        "if os.path.exists(MODEL_FILE) and os.path.exists(CONFIG_FILE):\n",
        "    print(\"Detected saved model, loading automatically!\")\n",
        "    best_vgg_model = load_model(\n",
        "        MODEL_FILE, custom_objects={'recall': recall, 'precision': precision}\n",
        "    )\n",
        "    with open(CONFIG_FILE, \"rb\") as f:\n",
        "        best_config_vgg = pickle.load(f)\n",
        "    print(\"Loaded best parameters:\", best_config_vgg)\n",
        "else:\n",
        "    print(\"No saved model detected, retraining...\")\n",
        "\n",
        "    # ======== Hyperparameter settings ========\n",
        "    batch_sizes = [8, 16, 32]\n",
        "    learning_rates = [1e-3, 1e-4]\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    best_recall_vgg = -np.inf\n",
        "    best_config_vgg = None\n",
        "    best_vgg_model = None\n",
        "\n",
        "    total_combinations = len(batch_sizes) * len(learning_rates)\n",
        "    finished_combinations = 0\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "        for lr in learning_rates:\n",
        "            group_start_time = time.time()\n",
        "            val_acc, val_rec, val_prec = [], [], []\n",
        "\n",
        "            for fold, (train_index, val_index) in enumerate(kf.split(X_train_new)):\n",
        "                X_train_fold, X_val_fold = X_train_new[train_index], X_train_new[val_index]\n",
        "                y_train_fold, y_val_fold = y_train_new[train_index], y_train_new[val_index]\n",
        "\n",
        "                model = build_vgg()\n",
        "                model.compile(\n",
        "                    optimizer=Adam(learning_rate=lr),\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=[recall, precision, 'accuracy']\n",
        "                )\n",
        "\n",
        "                callbacks = [\n",
        "                    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=0),\n",
        "                    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=0),\n",
        "                ]\n",
        "\n",
        "                model.fit(\n",
        "                    X_train_fold, y_train_fold,\n",
        "                    validation_data=(X_val_fold, y_val_fold),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=20,\n",
        "                    callbacks=callbacks,\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "                scores = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "                val_acc.append(scores[3])\n",
        "                val_rec.append(scores[1])\n",
        "                val_prec.append(scores[2])\n",
        "\n",
        "            mean_rec = np.mean(val_rec)\n",
        "            if mean_rec > best_recall_vgg:\n",
        "                best_recall_vgg = mean_rec\n",
        "                best_config_vgg = {\n",
        "                    'batch_size': batch_size,\n",
        "                    'learning_rate': lr,\n",
        "                    'accuracy': np.mean(val_acc),\n",
        "                    'recall': mean_rec,\n",
        "                    'precision': np.mean(val_prec)\n",
        "                }\n",
        "                best_vgg_model = model  # Note: the model from the last fold (not saved per fold)\n",
        "\n",
        "            # ETA progress bar\n",
        "            finished_combinations += 1\n",
        "            group_time = time.time() - group_start_time\n",
        "            elapsed = time.time() - total_start_time\n",
        "            avg_group_time = elapsed / finished_combinations\n",
        "            remaining_combinations = total_combinations - finished_combinations\n",
        "            eta = avg_group_time * remaining_combinations\n",
        "            print(f\"[{finished_combinations}/{total_combinations}] Finished batch_size={batch_size}, lr={lr} in {group_time/60:.2f} min. Estimated remaining: {eta/60:.2f} min ({eta:.1f} sec)\")\n",
        "\n",
        "    # ========== Save model and parameters ==========\n",
        "    best_vgg_model.save(MODEL_FILE)\n",
        "    with open(CONFIG_FILE, \"wb\") as f:\n",
        "        pickle.dump(best_config_vgg, f)\n",
        "    print(\"Best model and parameters saved:\", best_config_vgg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7OXAIQ0Bk9I",
        "outputId": "784589f6-b107-46df-be3b-9235881846ee",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟡 未检测到模型，将重新训练...\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8223 - loss: 0.4049 - precision: 0.8064 - recall: 0.6202 - val_accuracy: 0.9191 - val_loss: 0.2172 - val_precision: 0.9335 - val_recall: 0.8038 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9192 - loss: 0.2166 - precision: 0.9200 - recall: 0.8303 - val_accuracy: 0.9249 - val_loss: 0.1969 - val_precision: 0.9523 - val_recall: 0.8049 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9281 - loss: 0.1915 - precision: 0.9352 - recall: 0.8402 - val_accuracy: 0.9283 - val_loss: 0.1910 - val_precision: 0.9854 - val_recall: 0.7869 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9373 - loss: 0.1782 - precision: 0.9534 - recall: 0.8558 - val_accuracy: 0.9398 - val_loss: 0.1638 - val_precision: 0.9659 - val_recall: 0.8409 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9426 - loss: 0.1628 - precision: 0.9611 - recall: 0.8673 - val_accuracy: 0.9387 - val_loss: 0.1686 - val_precision: 0.9727 - val_recall: 0.8314 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9401 - loss: 0.1616 - precision: 0.9565 - recall: 0.8610 - val_accuracy: 0.9431 - val_loss: 0.1566 - val_precision: 0.9755 - val_recall: 0.8431 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1519 - precision: 0.9646 - recall: 0.8689 - val_accuracy: 0.9455 - val_loss: 0.1584 - val_precision: 0.9374 - val_recall: 0.8887 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9448 - loss: 0.1489 - precision: 0.9602 - recall: 0.8763 - val_accuracy: 0.9465 - val_loss: 0.1507 - val_precision: 0.9496 - val_recall: 0.8791 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9467 - loss: 0.1427 - precision: 0.9600 - recall: 0.8772 - val_accuracy: 0.9469 - val_loss: 0.1483 - val_precision: 0.9528 - val_recall: 0.8770 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9475 - loss: 0.1430 - precision: 0.9589 - recall: 0.8800 - val_accuracy: 0.9482 - val_loss: 0.1504 - val_precision: 0.9636 - val_recall: 0.8706 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9475 - loss: 0.1409 - precision: 0.9637 - recall: 0.8783 - val_accuracy: 0.9401 - val_loss: 0.1676 - val_precision: 0.9836 - val_recall: 0.8261 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9443 - loss: 0.1442 - precision: 0.9581 - recall: 0.8733 - val_accuracy: 0.9479 - val_loss: 0.1474 - val_precision: 0.9408 - val_recall: 0.8929 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.1385 - precision: 0.9626 - recall: 0.8829 - val_accuracy: 0.9482 - val_loss: 0.1475 - val_precision: 0.9540 - val_recall: 0.8802 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9493 - loss: 0.1388 - precision: 0.9650 - recall: 0.8821 - val_accuracy: 0.9503 - val_loss: 0.1422 - val_precision: 0.9738 - val_recall: 0.8674 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9516 - loss: 0.1323 - precision: 0.9681 - recall: 0.8863 - val_accuracy: 0.9513 - val_loss: 0.1448 - val_precision: 0.9673 - val_recall: 0.8770 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9486 - loss: 0.1340 - precision: 0.9612 - recall: 0.8841 - val_accuracy: 0.9472 - val_loss: 0.1436 - val_precision: 0.9301 - val_recall: 0.9024 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9522 - loss: 0.1271 - precision: 0.9613 - recall: 0.8931 - val_accuracy: 0.9442 - val_loss: 0.1487 - val_precision: 0.9284 - val_recall: 0.8940 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.1149 - precision: 0.9749 - recall: 0.9044 - val_accuracy: 0.9530 - val_loss: 0.1393 - val_precision: 0.9741 - val_recall: 0.8759 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9617 - loss: 0.1095 - precision: 0.9774 - recall: 0.9067 - val_accuracy: 0.9526 - val_loss: 0.1375 - val_precision: 0.9652 - val_recall: 0.8834 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9559 - loss: 0.1133 - precision: 0.9713 - recall: 0.8930 - val_accuracy: 0.9540 - val_loss: 0.1372 - val_precision: 0.9611 - val_recall: 0.8918 - learning_rate: 5.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8345 - loss: 0.3876 - precision: 0.9015 - recall: 0.7467 - val_accuracy: 0.9283 - val_loss: 0.2066 - val_precision: 0.9563 - val_recall: 0.8270 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.2234 - precision: 0.9316 - recall: 0.8315 - val_accuracy: 0.9431 - val_loss: 0.1752 - val_precision: 0.9656 - val_recall: 0.8638 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9308 - loss: 0.1910 - precision: 0.9403 - recall: 0.8433 - val_accuracy: 0.9387 - val_loss: 0.1624 - val_precision: 0.9630 - val_recall: 0.8529 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.1763 - precision: 0.9540 - recall: 0.8512 - val_accuracy: 0.9472 - val_loss: 0.1519 - val_precision: 0.9590 - val_recall: 0.8827 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9385 - loss: 0.1709 - precision: 0.9514 - recall: 0.8531 - val_accuracy: 0.9377 - val_loss: 0.1763 - val_precision: 0.9110 - val_recall: 0.9056 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9396 - loss: 0.1652 - precision: 0.9571 - recall: 0.8576 - val_accuracy: 0.9455 - val_loss: 0.1506 - val_precision: 0.9471 - val_recall: 0.8897 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9410 - loss: 0.1637 - precision: 0.9563 - recall: 0.8620 - val_accuracy: 0.9482 - val_loss: 0.1421 - val_precision: 0.9692 - val_recall: 0.8757 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.1602 - precision: 0.9552 - recall: 0.8596 - val_accuracy: 0.9472 - val_loss: 0.1444 - val_precision: 0.9712 - val_recall: 0.8708 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9437 - loss: 0.1550 - precision: 0.9630 - recall: 0.8664 - val_accuracy: 0.9506 - val_loss: 0.1380 - val_precision: 0.9799 - val_recall: 0.8728 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9499 - loss: 0.1432 - precision: 0.9680 - recall: 0.8808 - val_accuracy: 0.9465 - val_loss: 0.1421 - val_precision: 0.9829 - val_recall: 0.8579 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9458 - loss: 0.1438 - precision: 0.9603 - recall: 0.8716 - val_accuracy: 0.9516 - val_loss: 0.1305 - val_precision: 0.9757 - val_recall: 0.8797 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9504 - loss: 0.1389 - precision: 0.9660 - recall: 0.8827 - val_accuracy: 0.9523 - val_loss: 0.1291 - val_precision: 0.9616 - val_recall: 0.8956 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9487 - loss: 0.1410 - precision: 0.9622 - recall: 0.8810 - val_accuracy: 0.9530 - val_loss: 0.1294 - val_precision: 0.9597 - val_recall: 0.8996 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9488 - loss: 0.1350 - precision: 0.9610 - recall: 0.8836 - val_accuracy: 0.9550 - val_loss: 0.1255 - val_precision: 0.9719 - val_recall: 0.8936 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.1416 - precision: 0.9649 - recall: 0.8745 - val_accuracy: 0.9526 - val_loss: 0.1279 - val_precision: 0.9606 - val_recall: 0.8976 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9537 - loss: 0.1338 - precision: 0.9697 - recall: 0.8865 - val_accuracy: 0.9526 - val_loss: 0.1311 - val_precision: 0.9686 - val_recall: 0.8897 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9566 - loss: 0.1210 - precision: 0.9682 - recall: 0.8987 - val_accuracy: 0.9526 - val_loss: 0.1391 - val_precision: 0.9400 - val_recall: 0.9195 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9562 - loss: 0.1178 - precision: 0.9689 - recall: 0.8965 - val_accuracy: 0.9530 - val_loss: 0.1265 - val_precision: 0.9568 - val_recall: 0.9026 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9579 - loss: 0.1104 - precision: 0.9703 - recall: 0.9030 - val_accuracy: 0.9526 - val_loss: 0.1261 - val_precision: 0.9636 - val_recall: 0.8946 - learning_rate: 5.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8242 - loss: 0.3981 - precision: 0.9026 - recall: 0.7523 - val_accuracy: 0.9225 - val_loss: 0.2113 - val_precision: 0.9283 - val_recall: 0.8368 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.9234 - loss: 0.2113 - precision: 0.9293 - recall: 0.8302 - val_accuracy: 0.9327 - val_loss: 0.1811 - val_precision: 0.9409 - val_recall: 0.8557 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9307 - loss: 0.1918 - precision: 0.9403 - recall: 0.8446 - val_accuracy: 0.9377 - val_loss: 0.1756 - val_precision: 0.9659 - val_recall: 0.8468 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9354 - loss: 0.1705 - precision: 0.9509 - recall: 0.8512 - val_accuracy: 0.9266 - val_loss: 0.1863 - val_precision: 0.8893 - val_recall: 0.8955 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9355 - loss: 0.1696 - precision: 0.9437 - recall: 0.8573 - val_accuracy: 0.9387 - val_loss: 0.1767 - val_precision: 0.9355 - val_recall: 0.8806 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9391 - loss: 0.1622 - precision: 0.9566 - recall: 0.8525 - val_accuracy: 0.9435 - val_loss: 0.1638 - val_precision: 0.9676 - val_recall: 0.8627 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9474 - loss: 0.1450 - precision: 0.9623 - recall: 0.8780 - val_accuracy: 0.9428 - val_loss: 0.1611 - val_precision: 0.9634 - val_recall: 0.8647 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.1464 - precision: 0.9661 - recall: 0.8729 - val_accuracy: 0.9411 - val_loss: 0.1650 - val_precision: 0.9531 - val_recall: 0.8697 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9498 - loss: 0.1446 - precision: 0.9749 - recall: 0.8712 - val_accuracy: 0.9391 - val_loss: 0.1662 - val_precision: 0.9266 - val_recall: 0.8915 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9481 - loss: 0.1376 - precision: 0.9593 - recall: 0.8795 - val_accuracy: 0.9459 - val_loss: 0.1595 - val_precision: 0.9617 - val_recall: 0.8756 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9460 - loss: 0.1420 - precision: 0.9569 - recall: 0.8767 - val_accuracy: 0.9459 - val_loss: 0.1608 - val_precision: 0.9731 - val_recall: 0.8647 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9488 - loss: 0.1328 - precision: 0.9685 - recall: 0.8712 - val_accuracy: 0.9428 - val_loss: 0.1588 - val_precision: 0.9729 - val_recall: 0.8557 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.1270 - precision: 0.9629 - recall: 0.8831 - val_accuracy: 0.9459 - val_loss: 0.1596 - val_precision: 0.9617 - val_recall: 0.8756 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9528 - loss: 0.1304 - precision: 0.9705 - recall: 0.8840 - val_accuracy: 0.9469 - val_loss: 0.1523 - val_precision: 0.9540 - val_recall: 0.8866 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1280 - precision: 0.9686 - recall: 0.8859 - val_accuracy: 0.9482 - val_loss: 0.1543 - val_precision: 0.9754 - val_recall: 0.8697 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.1286 - precision: 0.9690 - recall: 0.8830 - val_accuracy: 0.9475 - val_loss: 0.1532 - val_precision: 0.9650 - val_recall: 0.8776 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.1171 - precision: 0.9620 - recall: 0.9038 - val_accuracy: 0.9452 - val_loss: 0.1607 - val_precision: 0.9839 - val_recall: 0.8527 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.1170 - precision: 0.9778 - recall: 0.8904 - val_accuracy: 0.9475 - val_loss: 0.1613 - val_precision: 0.9640 - val_recall: 0.8786 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9588 - loss: 0.1049 - precision: 0.9781 - recall: 0.8936 - val_accuracy: 0.9479 - val_loss: 0.1588 - val_precision: 0.9590 - val_recall: 0.8846 - learning_rate: 5.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8282 - loss: 0.3957 - precision: 0.8952 - recall: 0.7486 - val_accuracy: 0.9259 - val_loss: 0.2172 - val_precision: 0.9077 - val_recall: 0.8706 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2194 - precision: 0.9197 - recall: 0.8258 - val_accuracy: 0.9255 - val_loss: 0.1976 - val_precision: 0.9701 - val_recall: 0.8060 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9280 - loss: 0.1914 - precision: 0.9339 - recall: 0.8433 - val_accuracy: 0.9306 - val_loss: 0.1870 - val_precision: 0.9082 - val_recall: 0.8856 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1872 - precision: 0.9473 - recall: 0.8478 - val_accuracy: 0.9343 - val_loss: 0.1784 - val_precision: 0.9412 - val_recall: 0.8607 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.1715 - precision: 0.9516 - recall: 0.8536 - val_accuracy: 0.9313 - val_loss: 0.1798 - val_precision: 0.9797 - val_recall: 0.8149 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9389 - loss: 0.1666 - precision: 0.9541 - recall: 0.8624 - val_accuracy: 0.9394 - val_loss: 0.1602 - val_precision: 0.9747 - val_recall: 0.8438 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9359 - loss: 0.1625 - precision: 0.9488 - recall: 0.8575 - val_accuracy: 0.9371 - val_loss: 0.1670 - val_precision: 0.9417 - val_recall: 0.8687 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9431 - loss: 0.1557 - precision: 0.9586 - recall: 0.8651 - val_accuracy: 0.9415 - val_loss: 0.1569 - val_precision: 0.9473 - val_recall: 0.8766 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9461 - loss: 0.1473 - precision: 0.9585 - recall: 0.8732 - val_accuracy: 0.9445 - val_loss: 0.1526 - val_precision: 0.9646 - val_recall: 0.8687 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9467 - loss: 0.1384 - precision: 0.9575 - recall: 0.8755 - val_accuracy: 0.9415 - val_loss: 0.1570 - val_precision: 0.9653 - val_recall: 0.8587 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9447 - loss: 0.1477 - precision: 0.9556 - recall: 0.8734 - val_accuracy: 0.9431 - val_loss: 0.1531 - val_precision: 0.9438 - val_recall: 0.8856 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9474 - loss: 0.1389 - precision: 0.9599 - recall: 0.8766 - val_accuracy: 0.9391 - val_loss: 0.1602 - val_precision: 0.9347 - val_recall: 0.8826 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9522 - loss: 0.1330 - precision: 0.9674 - recall: 0.8849 - val_accuracy: 0.9435 - val_loss: 0.1444 - val_precision: 0.9439 - val_recall: 0.8866 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9572 - loss: 0.1232 - precision: 0.9746 - recall: 0.8959 - val_accuracy: 0.9459 - val_loss: 0.1432 - val_precision: 0.9548 - val_recall: 0.8826 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.1199 - precision: 0.9638 - recall: 0.8977 - val_accuracy: 0.9452 - val_loss: 0.1501 - val_precision: 0.9637 - val_recall: 0.8716 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9571 - loss: 0.1138 - precision: 0.9725 - recall: 0.8985 - val_accuracy: 0.9469 - val_loss: 0.1463 - val_precision: 0.9454 - val_recall: 0.8955 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9541 - loss: 0.1221 - precision: 0.9629 - recall: 0.8966 - val_accuracy: 0.9472 - val_loss: 0.1435 - val_precision: 0.9560 - val_recall: 0.8856 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9598 - loss: 0.1107 - precision: 0.9756 - recall: 0.9027 - val_accuracy: 0.9455 - val_loss: 0.1460 - val_precision: 0.9451 - val_recall: 0.8915 - learning_rate: 2.5000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9610 - loss: 0.1055 - precision: 0.9725 - recall: 0.9081 - val_accuracy: 0.9455 - val_loss: 0.1453 - val_precision: 0.9528 - val_recall: 0.8836 - learning_rate: 2.5000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8178 - loss: 0.3993 - precision: 0.8925 - recall: 0.7438 - val_accuracy: 0.9248 - val_loss: 0.2121 - val_precision: 0.9356 - val_recall: 0.8271 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9208 - loss: 0.2199 - precision: 0.9278 - recall: 0.8297 - val_accuracy: 0.9252 - val_loss: 0.2021 - val_precision: 0.9018 - val_recall: 0.8654 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9339 - loss: 0.1892 - precision: 0.9451 - recall: 0.8547 - val_accuracy: 0.9316 - val_loss: 0.1808 - val_precision: 0.9216 - val_recall: 0.8644 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9318 - loss: 0.1788 - precision: 0.9406 - recall: 0.8499 - val_accuracy: 0.9353 - val_loss: 0.1939 - val_precision: 0.9911 - val_recall: 0.8095 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.1688 - precision: 0.9458 - recall: 0.8512 - val_accuracy: 0.9232 - val_loss: 0.1882 - val_precision: 0.8813 - val_recall: 0.8841 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9414 - loss: 0.1619 - precision: 0.9559 - recall: 0.8683 - val_accuracy: 0.9397 - val_loss: 0.1747 - val_precision: 0.9876 - val_recall: 0.8261 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9426 - loss: 0.1508 - precision: 0.9527 - recall: 0.8686 - val_accuracy: 0.9428 - val_loss: 0.1683 - val_precision: 0.9878 - val_recall: 0.8354 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9424 - loss: 0.1526 - precision: 0.9533 - recall: 0.8673 - val_accuracy: 0.9438 - val_loss: 0.1621 - val_precision: 0.9706 - val_recall: 0.8540 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9453 - loss: 0.1429 - precision: 0.9587 - recall: 0.8748 - val_accuracy: 0.9414 - val_loss: 0.1675 - val_precision: 0.9841 - val_recall: 0.8344 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9452 - loss: 0.1462 - precision: 0.9566 - recall: 0.8769 - val_accuracy: 0.9441 - val_loss: 0.1598 - val_precision: 0.9796 - val_recall: 0.8468 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.1387 - precision: 0.9581 - recall: 0.8853 - val_accuracy: 0.9469 - val_loss: 0.1562 - val_precision: 0.9633 - val_recall: 0.8706 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9513 - loss: 0.1293 - precision: 0.9581 - recall: 0.8928 - val_accuracy: 0.9438 - val_loss: 0.1618 - val_precision: 0.9866 - val_recall: 0.8395 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.1396 - precision: 0.9594 - recall: 0.8812 - val_accuracy: 0.9441 - val_loss: 0.1597 - val_precision: 0.9556 - val_recall: 0.8696 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.1302 - precision: 0.9667 - recall: 0.8938 - val_accuracy: 0.9381 - val_loss: 0.1611 - val_precision: 0.9205 - val_recall: 0.8872 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9525 - loss: 0.1252 - precision: 0.9652 - recall: 0.8900 - val_accuracy: 0.9465 - val_loss: 0.1573 - val_precision: 0.9821 - val_recall: 0.8520 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9560 - loss: 0.1132 - precision: 0.9716 - recall: 0.8940 - val_accuracy: 0.9469 - val_loss: 0.1499 - val_precision: 0.9602 - val_recall: 0.8737 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9522 - loss: 0.1200 - precision: 0.9648 - recall: 0.8904 - val_accuracy: 0.9469 - val_loss: 0.1531 - val_precision: 0.9666 - val_recall: 0.8675 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.1148 - precision: 0.9680 - recall: 0.8982 - val_accuracy: 0.9458 - val_loss: 0.1601 - val_precision: 0.9752 - val_recall: 0.8561 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9613 - loss: 0.1117 - precision: 0.9764 - recall: 0.9067 - val_accuracy: 0.9475 - val_loss: 0.1564 - val_precision: 0.9677 - val_recall: 0.8685 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9636 - loss: 0.1032 - precision: 0.9810 - recall: 0.9118 - val_accuracy: 0.9462 - val_loss: 0.1526 - val_precision: 0.9643 - val_recall: 0.8675 - learning_rate: 2.5000e-04\n",
            "[1/6] Finished batch_size=8, lr=0.001 in 27.79 min. Estimated remaining: 138.93 min (8335.5 sec)\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.7074 - loss: 0.5593 - precision: 0.8308 - recall: 0.5596 - val_accuracy: 0.8748 - val_loss: 0.3622 - val_precision: 0.9134 - val_recall: 0.6713 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.3511 - precision: 0.8941 - recall: 0.6769 - val_accuracy: 0.8897 - val_loss: 0.2937 - val_precision: 0.9491 - val_recall: 0.6914 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8931 - loss: 0.2921 - precision: 0.9090 - recall: 0.7615 - val_accuracy: 0.9073 - val_loss: 0.2531 - val_precision: 0.9176 - val_recall: 0.7794 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9034 - loss: 0.2615 - precision: 0.9192 - recall: 0.7915 - val_accuracy: 0.9147 - val_loss: 0.2378 - val_precision: 0.8904 - val_recall: 0.8356 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9172 - loss: 0.2349 - precision: 0.9265 - recall: 0.8180 - val_accuracy: 0.9181 - val_loss: 0.2210 - val_precision: 0.9301 - val_recall: 0.8038 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9211 - loss: 0.2206 - precision: 0.9317 - recall: 0.8245 - val_accuracy: 0.9212 - val_loss: 0.2136 - val_precision: 0.9090 - val_recall: 0.8367 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9218 - loss: 0.2179 - precision: 0.9284 - recall: 0.8303 - val_accuracy: 0.9255 - val_loss: 0.2047 - val_precision: 0.9319 - val_recall: 0.8271 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.2055 - precision: 0.9328 - recall: 0.8511 - val_accuracy: 0.9296 - val_loss: 0.1995 - val_precision: 0.9268 - val_recall: 0.8462 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9341 - loss: 0.1907 - precision: 0.9432 - recall: 0.8574 - val_accuracy: 0.9249 - val_loss: 0.1944 - val_precision: 0.9434 - val_recall: 0.8134 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.1839 - precision: 0.9460 - recall: 0.8547 - val_accuracy: 0.9279 - val_loss: 0.1898 - val_precision: 0.9419 - val_recall: 0.8250 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9346 - loss: 0.1847 - precision: 0.9420 - recall: 0.8501 - val_accuracy: 0.9343 - val_loss: 0.1840 - val_precision: 0.9300 - val_recall: 0.8590 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.1788 - precision: 0.9481 - recall: 0.8548 - val_accuracy: 0.9337 - val_loss: 0.1843 - val_precision: 0.9155 - val_recall: 0.8727 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9362 - loss: 0.1783 - precision: 0.9472 - recall: 0.8579 - val_accuracy: 0.9367 - val_loss: 0.1764 - val_precision: 0.9385 - val_recall: 0.8579 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.1711 - precision: 0.9582 - recall: 0.8701 - val_accuracy: 0.9354 - val_loss: 0.1741 - val_precision: 0.9362 - val_recall: 0.8558 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9385 - loss: 0.1740 - precision: 0.9557 - recall: 0.8598 - val_accuracy: 0.9371 - val_loss: 0.1717 - val_precision: 0.9366 - val_recall: 0.8611 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9406 - loss: 0.1662 - precision: 0.9529 - recall: 0.8628 - val_accuracy: 0.9371 - val_loss: 0.1704 - val_precision: 0.9326 - val_recall: 0.8653 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9419 - loss: 0.1617 - precision: 0.9498 - recall: 0.8671 - val_accuracy: 0.9371 - val_loss: 0.1701 - val_precision: 0.9220 - val_recall: 0.8770 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9388 - loss: 0.1627 - precision: 0.9545 - recall: 0.8580 - val_accuracy: 0.9404 - val_loss: 0.1670 - val_precision: 0.9615 - val_recall: 0.8473 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9400 - loss: 0.1615 - precision: 0.9593 - recall: 0.8604 - val_accuracy: 0.9391 - val_loss: 0.1673 - val_precision: 0.9263 - val_recall: 0.8791 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9437 - loss: 0.1525 - precision: 0.9589 - recall: 0.8694 - val_accuracy: 0.9384 - val_loss: 0.1679 - val_precision: 0.9214 - val_recall: 0.8823 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.7318 - loss: 0.5483 - precision: 0.9089 - recall: 0.5227 - val_accuracy: 0.8626 - val_loss: 0.3586 - val_precision: 0.9438 - val_recall: 0.6342 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8668 - loss: 0.3457 - precision: 0.8981 - recall: 0.6798 - val_accuracy: 0.9036 - val_loss: 0.2818 - val_precision: 0.9307 - val_recall: 0.7744 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8940 - loss: 0.2844 - precision: 0.9117 - recall: 0.7546 - val_accuracy: 0.9052 - val_loss: 0.2553 - val_precision: 0.9572 - val_recall: 0.7555 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9164 - loss: 0.2454 - precision: 0.9327 - recall: 0.8079 - val_accuracy: 0.9269 - val_loss: 0.2307 - val_precision: 0.9369 - val_recall: 0.8419 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.2327 - precision: 0.9284 - recall: 0.8122 - val_accuracy: 0.9293 - val_loss: 0.2161 - val_precision: 0.9374 - val_recall: 0.8489 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9218 - loss: 0.2233 - precision: 0.9302 - recall: 0.8281 - val_accuracy: 0.9306 - val_loss: 0.2096 - val_precision: 0.9211 - val_recall: 0.8708 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9249 - loss: 0.2086 - precision: 0.9362 - recall: 0.8318 - val_accuracy: 0.9367 - val_loss: 0.1964 - val_precision: 0.9505 - val_recall: 0.8588 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9291 - loss: 0.2022 - precision: 0.9384 - recall: 0.8450 - val_accuracy: 0.9272 - val_loss: 0.1986 - val_precision: 0.9658 - val_recall: 0.8151 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9268 - loss: 0.1973 - precision: 0.9415 - recall: 0.8330 - val_accuracy: 0.9381 - val_loss: 0.1878 - val_precision: 0.9364 - val_recall: 0.8777 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9297 - loss: 0.1933 - precision: 0.9385 - recall: 0.8421 - val_accuracy: 0.9371 - val_loss: 0.1806 - val_precision: 0.9496 - val_recall: 0.8608 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9316 - loss: 0.1867 - precision: 0.9446 - recall: 0.8445 - val_accuracy: 0.9394 - val_loss: 0.1761 - val_precision: 0.9451 - val_recall: 0.8728 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1825 - precision: 0.9417 - recall: 0.8506 - val_accuracy: 0.9401 - val_loss: 0.1719 - val_precision: 0.9501 - val_recall: 0.8698 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9367 - loss: 0.1789 - precision: 0.9539 - recall: 0.8538 - val_accuracy: 0.9425 - val_loss: 0.1682 - val_precision: 0.9514 - val_recall: 0.8757 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9405 - loss: 0.1722 - precision: 0.9554 - recall: 0.8614 - val_accuracy: 0.9415 - val_loss: 0.1658 - val_precision: 0.9582 - val_recall: 0.8658 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9392 - loss: 0.1700 - precision: 0.9538 - recall: 0.8588 - val_accuracy: 0.9428 - val_loss: 0.1625 - val_precision: 0.9574 - val_recall: 0.8708 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9389 - loss: 0.1761 - precision: 0.9542 - recall: 0.8529 - val_accuracy: 0.9428 - val_loss: 0.1624 - val_precision: 0.9429 - val_recall: 0.8857 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.1749 - precision: 0.9468 - recall: 0.8550 - val_accuracy: 0.9435 - val_loss: 0.1615 - val_precision: 0.9430 - val_recall: 0.8877 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.1630 - precision: 0.9547 - recall: 0.8638 - val_accuracy: 0.9435 - val_loss: 0.1568 - val_precision: 0.9525 - val_recall: 0.8777 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.1647 - precision: 0.9586 - recall: 0.8687 - val_accuracy: 0.9442 - val_loss: 0.1545 - val_precision: 0.9576 - val_recall: 0.8748 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9384 - loss: 0.1632 - precision: 0.9524 - recall: 0.8567 - val_accuracy: 0.9442 - val_loss: 0.1524 - val_precision: 0.9556 - val_recall: 0.8767 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.7280 - loss: 0.5415 - precision: 0.8266 - recall: 0.6027 - val_accuracy: 0.8768 - val_loss: 0.3589 - val_precision: 0.9302 - val_recall: 0.6896 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8689 - loss: 0.3467 - precision: 0.8901 - recall: 0.6921 - val_accuracy: 0.8992 - val_loss: 0.2886 - val_precision: 0.9154 - val_recall: 0.7751 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8977 - loss: 0.2856 - precision: 0.9059 - recall: 0.7699 - val_accuracy: 0.9113 - val_loss: 0.2559 - val_precision: 0.9449 - val_recall: 0.7851 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9097 - loss: 0.2553 - precision: 0.9271 - recall: 0.7930 - val_accuracy: 0.9151 - val_loss: 0.2354 - val_precision: 0.9425 - val_recall: 0.7990 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.2234 - precision: 0.9301 - recall: 0.8227 - val_accuracy: 0.9208 - val_loss: 0.2242 - val_precision: 0.9204 - val_recall: 0.8398 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9202 - loss: 0.2255 - precision: 0.9245 - recall: 0.8234 - val_accuracy: 0.9235 - val_loss: 0.2135 - val_precision: 0.9534 - val_recall: 0.8149 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9287 - loss: 0.2045 - precision: 0.9410 - recall: 0.8359 - val_accuracy: 0.9255 - val_loss: 0.2085 - val_precision: 0.9645 - val_recall: 0.8109 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9268 - loss: 0.2087 - precision: 0.9333 - recall: 0.8357 - val_accuracy: 0.9272 - val_loss: 0.1988 - val_precision: 0.9408 - val_recall: 0.8388 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9305 - loss: 0.1980 - precision: 0.9428 - recall: 0.8439 - val_accuracy: 0.9316 - val_loss: 0.1948 - val_precision: 0.9557 - val_recall: 0.8378 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9312 - loss: 0.1896 - precision: 0.9428 - recall: 0.8427 - val_accuracy: 0.9252 - val_loss: 0.1965 - val_precision: 0.9016 - val_recall: 0.8756 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.1802 - precision: 0.9467 - recall: 0.8569 - val_accuracy: 0.9330 - val_loss: 0.1869 - val_precision: 0.9590 - val_recall: 0.8388 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9373 - loss: 0.1834 - precision: 0.9589 - recall: 0.8482 - val_accuracy: 0.9333 - val_loss: 0.1833 - val_precision: 0.9459 - val_recall: 0.8527 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.1720 - precision: 0.9512 - recall: 0.8593 - val_accuracy: 0.9350 - val_loss: 0.1819 - val_precision: 0.9452 - val_recall: 0.8587 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 0.1697 - precision: 0.9533 - recall: 0.8600 - val_accuracy: 0.9347 - val_loss: 0.1782 - val_precision: 0.9423 - val_recall: 0.8607 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.1708 - precision: 0.9566 - recall: 0.8579 - val_accuracy: 0.9364 - val_loss: 0.1769 - val_precision: 0.9534 - val_recall: 0.8547 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.1695 - precision: 0.9502 - recall: 0.8602 - val_accuracy: 0.9374 - val_loss: 0.1747 - val_precision: 0.9607 - val_recall: 0.8507 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9398 - loss: 0.1666 - precision: 0.9525 - recall: 0.8618 - val_accuracy: 0.9354 - val_loss: 0.1736 - val_precision: 0.9453 - val_recall: 0.8597 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.1625 - precision: 0.9535 - recall: 0.8656 - val_accuracy: 0.9354 - val_loss: 0.1743 - val_precision: 0.9330 - val_recall: 0.8726 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9449 - loss: 0.1541 - precision: 0.9596 - recall: 0.8725 - val_accuracy: 0.9394 - val_loss: 0.1725 - val_precision: 0.9661 - val_recall: 0.8517 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9442 - loss: 0.1578 - precision: 0.9607 - recall: 0.8667 - val_accuracy: 0.9401 - val_loss: 0.1694 - val_precision: 0.9520 - val_recall: 0.8677 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.6938 - loss: 0.5798 - precision: 0.8003 - recall: 0.5595 - val_accuracy: 0.8616 - val_loss: 0.3748 - val_precision: 0.9331 - val_recall: 0.6388 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.8607 - loss: 0.3667 - precision: 0.8819 - recall: 0.6761 - val_accuracy: 0.8924 - val_loss: 0.2948 - val_precision: 0.9490 - val_recall: 0.7224 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8876 - loss: 0.3028 - precision: 0.8970 - recall: 0.7445 - val_accuracy: 0.9076 - val_loss: 0.2573 - val_precision: 0.9496 - val_recall: 0.7692 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9067 - loss: 0.2598 - precision: 0.9233 - recall: 0.7819 - val_accuracy: 0.9198 - val_loss: 0.2378 - val_precision: 0.9076 - val_recall: 0.8507 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9083 - loss: 0.2488 - precision: 0.9171 - recall: 0.7984 - val_accuracy: 0.9239 - val_loss: 0.2205 - val_precision: 0.9462 - val_recall: 0.8229 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9206 - loss: 0.2259 - precision: 0.9322 - recall: 0.8190 - val_accuracy: 0.9249 - val_loss: 0.2113 - val_precision: 0.9485 - val_recall: 0.8239 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9239 - loss: 0.2175 - precision: 0.9358 - recall: 0.8301 - val_accuracy: 0.9276 - val_loss: 0.2044 - val_precision: 0.9520 - val_recall: 0.8289 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9264 - loss: 0.2042 - precision: 0.9360 - recall: 0.8353 - val_accuracy: 0.9299 - val_loss: 0.1977 - val_precision: 0.9493 - val_recall: 0.8388 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9287 - loss: 0.1984 - precision: 0.9420 - recall: 0.8371 - val_accuracy: 0.9313 - val_loss: 0.1922 - val_precision: 0.9465 - val_recall: 0.8458 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9352 - loss: 0.1862 - precision: 0.9484 - recall: 0.8522 - val_accuracy: 0.9316 - val_loss: 0.1882 - val_precision: 0.9486 - val_recall: 0.8448 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9339 - loss: 0.1897 - precision: 0.9475 - recall: 0.8498 - val_accuracy: 0.9316 - val_loss: 0.1843 - val_precision: 0.9417 - val_recall: 0.8517 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.1825 - precision: 0.9507 - recall: 0.8470 - val_accuracy: 0.9320 - val_loss: 0.1819 - val_precision: 0.9332 - val_recall: 0.8617 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1781 - precision: 0.9509 - recall: 0.8558 - val_accuracy: 0.9333 - val_loss: 0.1787 - val_precision: 0.9489 - val_recall: 0.8498 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9397 - loss: 0.1710 - precision: 0.9528 - recall: 0.8595 - val_accuracy: 0.9313 - val_loss: 0.1791 - val_precision: 0.9266 - val_recall: 0.8667 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9417 - loss: 0.1684 - precision: 0.9565 - recall: 0.8647 - val_accuracy: 0.9337 - val_loss: 0.1743 - val_precision: 0.9345 - val_recall: 0.8657 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9419 - loss: 0.1607 - precision: 0.9546 - recall: 0.8629 - val_accuracy: 0.9367 - val_loss: 0.1722 - val_precision: 0.9524 - val_recall: 0.8567 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.1729 - precision: 0.9481 - recall: 0.8621 - val_accuracy: 0.9371 - val_loss: 0.1704 - val_precision: 0.9555 - val_recall: 0.8547 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.1583 - precision: 0.9564 - recall: 0.8733 - val_accuracy: 0.9364 - val_loss: 0.1688 - val_precision: 0.9388 - val_recall: 0.8697 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9408 - loss: 0.1617 - precision: 0.9601 - recall: 0.8612 - val_accuracy: 0.9381 - val_loss: 0.1670 - val_precision: 0.9536 - val_recall: 0.8597 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9428 - loss: 0.1599 - precision: 0.9666 - recall: 0.8590 - val_accuracy: 0.9394 - val_loss: 0.1656 - val_precision: 0.9569 - val_recall: 0.8607 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.7040 - loss: 0.5597 - precision: 0.8193 - recall: 0.5877 - val_accuracy: 0.8751 - val_loss: 0.3523 - val_precision: 0.9210 - val_recall: 0.6760 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8650 - loss: 0.3543 - precision: 0.8916 - recall: 0.6876 - val_accuracy: 0.9042 - val_loss: 0.2831 - val_precision: 0.9149 - val_recall: 0.7795 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8946 - loss: 0.2911 - precision: 0.9048 - recall: 0.7652 - val_accuracy: 0.9133 - val_loss: 0.2534 - val_precision: 0.9471 - val_recall: 0.7785 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9061 - loss: 0.2620 - precision: 0.9177 - recall: 0.7936 - val_accuracy: 0.9188 - val_loss: 0.2331 - val_precision: 0.9251 - val_recall: 0.8178 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2369 - precision: 0.9246 - recall: 0.8082 - val_accuracy: 0.9245 - val_loss: 0.2207 - val_precision: 0.9471 - val_recall: 0.8147 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9232 - loss: 0.2218 - precision: 0.9383 - recall: 0.8251 - val_accuracy: 0.9269 - val_loss: 0.2107 - val_precision: 0.9433 - val_recall: 0.8261 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9283 - loss: 0.2031 - precision: 0.9336 - recall: 0.8417 - val_accuracy: 0.9276 - val_loss: 0.2057 - val_precision: 0.9498 - val_recall: 0.8219 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.2075 - precision: 0.9347 - recall: 0.8359 - val_accuracy: 0.9316 - val_loss: 0.1983 - val_precision: 0.9401 - val_recall: 0.8447 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9270 - loss: 0.2013 - precision: 0.9349 - recall: 0.8400 - val_accuracy: 0.9309 - val_loss: 0.1963 - val_precision: 0.9281 - val_recall: 0.8551 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9272 - loss: 0.1961 - precision: 0.9336 - recall: 0.8442 - val_accuracy: 0.9326 - val_loss: 0.1894 - val_precision: 0.9549 - val_recall: 0.8333 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9321 - loss: 0.1898 - precision: 0.9443 - recall: 0.8489 - val_accuracy: 0.9360 - val_loss: 0.1864 - val_precision: 0.9491 - val_recall: 0.8499 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9356 - loss: 0.1810 - precision: 0.9461 - recall: 0.8544 - val_accuracy: 0.9360 - val_loss: 0.1837 - val_precision: 0.9491 - val_recall: 0.8499 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9381 - loss: 0.1768 - precision: 0.9481 - recall: 0.8618 - val_accuracy: 0.9374 - val_loss: 0.1822 - val_precision: 0.9688 - val_recall: 0.8354 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9396 - loss: 0.1700 - precision: 0.9522 - recall: 0.8639 - val_accuracy: 0.9367 - val_loss: 0.1778 - val_precision: 0.9556 - val_recall: 0.8458 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9409 - loss: 0.1650 - precision: 0.9508 - recall: 0.8639 - val_accuracy: 0.9381 - val_loss: 0.1787 - val_precision: 0.9711 - val_recall: 0.8354 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9440 - loss: 0.1601 - precision: 0.9580 - recall: 0.8727 - val_accuracy: 0.9377 - val_loss: 0.1797 - val_precision: 0.9792 - val_recall: 0.8271 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9392 - loss: 0.1650 - precision: 0.9550 - recall: 0.8570 - val_accuracy: 0.9401 - val_loss: 0.1750 - val_precision: 0.9747 - val_recall: 0.8385 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1648 - precision: 0.9579 - recall: 0.8662 - val_accuracy: 0.9397 - val_loss: 0.1702 - val_precision: 0.9690 - val_recall: 0.8427 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9421 - loss: 0.1595 - precision: 0.9545 - recall: 0.8667 - val_accuracy: 0.9387 - val_loss: 0.1695 - val_precision: 0.9475 - val_recall: 0.8602 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9411 - loss: 0.1587 - precision: 0.9524 - recall: 0.8672 - val_accuracy: 0.9408 - val_loss: 0.1675 - val_precision: 0.9637 - val_recall: 0.8509 - learning_rate: 1.0000e-04\n",
            "[2/6] Finished batch_size=8, lr=0.0001 in 26.31 min. Estimated remaining: 108.20 min (6491.9 sec)\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8154 - loss: 0.4151 - precision: 0.9004 - recall: 0.7105 - val_accuracy: 0.9130 - val_loss: 0.2360 - val_precision: 0.9561 - val_recall: 0.7625 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9158 - loss: 0.2278 - precision: 0.9219 - recall: 0.8249 - val_accuracy: 0.9276 - val_loss: 0.1937 - val_precision: 0.9429 - val_recall: 0.8229 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9264 - loss: 0.1992 - precision: 0.9338 - recall: 0.8374 - val_accuracy: 0.9320 - val_loss: 0.1830 - val_precision: 0.9122 - val_recall: 0.8706 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9302 - loss: 0.1923 - precision: 0.9438 - recall: 0.8479 - val_accuracy: 0.9337 - val_loss: 0.1753 - val_precision: 0.9594 - val_recall: 0.8271 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9358 - loss: 0.1727 - precision: 0.9473 - recall: 0.8543 - val_accuracy: 0.9350 - val_loss: 0.1698 - val_precision: 0.9168 - val_recall: 0.8759 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9373 - loss: 0.1725 - precision: 0.9560 - recall: 0.8518 - val_accuracy: 0.9391 - val_loss: 0.1621 - val_precision: 0.9215 - val_recall: 0.8844 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9410 - loss: 0.1560 - precision: 0.9571 - recall: 0.8631 - val_accuracy: 0.9431 - val_loss: 0.1604 - val_precision: 0.9398 - val_recall: 0.8780 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9443 - loss: 0.1570 - precision: 0.9573 - recall: 0.8719 - val_accuracy: 0.9411 - val_loss: 0.1574 - val_precision: 0.9561 - val_recall: 0.8547 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.1545 - precision: 0.9532 - recall: 0.8698 - val_accuracy: 0.9428 - val_loss: 0.1518 - val_precision: 0.9542 - val_recall: 0.8621 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9463 - loss: 0.1422 - precision: 0.9621 - recall: 0.8756 - val_accuracy: 0.9435 - val_loss: 0.1545 - val_precision: 0.9522 - val_recall: 0.8664 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9525 - loss: 0.1362 - precision: 0.9688 - recall: 0.8887 - val_accuracy: 0.9435 - val_loss: 0.1557 - val_precision: 0.9663 - val_recall: 0.8526 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9473 - loss: 0.1418 - precision: 0.9604 - recall: 0.8811 - val_accuracy: 0.9482 - val_loss: 0.1500 - val_precision: 0.9748 - val_recall: 0.8600 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9458 - loss: 0.1455 - precision: 0.9657 - recall: 0.8700 - val_accuracy: 0.9469 - val_loss: 0.1522 - val_precision: 0.9613 - val_recall: 0.8685 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9478 - loss: 0.1431 - precision: 0.9631 - recall: 0.8816 - val_accuracy: 0.9442 - val_loss: 0.1621 - val_precision: 0.9709 - val_recall: 0.8505 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1340 - precision: 0.9619 - recall: 0.8769 - val_accuracy: 0.9486 - val_loss: 0.1488 - val_precision: 0.9510 - val_recall: 0.8844 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9570 - loss: 0.1215 - precision: 0.9698 - recall: 0.8999 - val_accuracy: 0.9489 - val_loss: 0.1441 - val_precision: 0.9531 - val_recall: 0.8834 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.1280 - precision: 0.9686 - recall: 0.8881 - val_accuracy: 0.9509 - val_loss: 0.1491 - val_precision: 0.9683 - val_recall: 0.8749 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9500 - loss: 0.1337 - precision: 0.9690 - recall: 0.8830 - val_accuracy: 0.9499 - val_loss: 0.1460 - val_precision: 0.9660 - val_recall: 0.8738 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9531 - loss: 0.1249 - precision: 0.9689 - recall: 0.8871 - val_accuracy: 0.9486 - val_loss: 0.1464 - val_precision: 0.9782 - val_recall: 0.8579 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9582 - loss: 0.1136 - precision: 0.9725 - recall: 0.9014 - val_accuracy: 0.9509 - val_loss: 0.1379 - val_precision: 0.9503 - val_recall: 0.8929 - learning_rate: 5.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8330 - loss: 0.3966 - precision: 0.9037 - recall: 0.7414 - val_accuracy: 0.9140 - val_loss: 0.2329 - val_precision: 0.9688 - val_recall: 0.7724 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9196 - loss: 0.2170 - precision: 0.9210 - recall: 0.8271 - val_accuracy: 0.9367 - val_loss: 0.1845 - val_precision: 0.9565 - val_recall: 0.8529 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.1994 - precision: 0.9364 - recall: 0.8478 - val_accuracy: 0.9381 - val_loss: 0.1785 - val_precision: 0.9229 - val_recall: 0.8926 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9368 - loss: 0.1746 - precision: 0.9426 - recall: 0.8618 - val_accuracy: 0.9347 - val_loss: 0.1756 - val_precision: 0.9766 - val_recall: 0.8280 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9372 - loss: 0.1723 - precision: 0.9489 - recall: 0.8543 - val_accuracy: 0.9394 - val_loss: 0.1582 - val_precision: 0.9683 - val_recall: 0.8499 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9407 - loss: 0.1667 - precision: 0.9546 - recall: 0.8588 - val_accuracy: 0.9462 - val_loss: 0.1474 - val_precision: 0.9549 - val_recall: 0.8837 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9405 - loss: 0.1589 - precision: 0.9537 - recall: 0.8640 - val_accuracy: 0.9479 - val_loss: 0.1463 - val_precision: 0.9620 - val_recall: 0.8817 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9388 - loss: 0.1579 - precision: 0.9457 - recall: 0.8660 - val_accuracy: 0.9472 - val_loss: 0.1395 - val_precision: 0.9620 - val_recall: 0.8797 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9485 - loss: 0.1430 - precision: 0.9612 - recall: 0.8794 - val_accuracy: 0.9472 - val_loss: 0.1416 - val_precision: 0.9701 - val_recall: 0.8718 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.1446 - precision: 0.9638 - recall: 0.8861 - val_accuracy: 0.9472 - val_loss: 0.1447 - val_precision: 0.9400 - val_recall: 0.9026 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9469 - loss: 0.1443 - precision: 0.9654 - recall: 0.8728 - val_accuracy: 0.9472 - val_loss: 0.1446 - val_precision: 0.9400 - val_recall: 0.9026 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9514 - loss: 0.1321 - precision: 0.9630 - recall: 0.8891 - val_accuracy: 0.9509 - val_loss: 0.1316 - val_precision: 0.9575 - val_recall: 0.8956 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9546 - loss: 0.1260 - precision: 0.9707 - recall: 0.8905 - val_accuracy: 0.9516 - val_loss: 0.1291 - val_precision: 0.9695 - val_recall: 0.8857 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9536 - loss: 0.1276 - precision: 0.9713 - recall: 0.8872 - val_accuracy: 0.9513 - val_loss: 0.1320 - val_precision: 0.9757 - val_recall: 0.8787 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9531 - loss: 0.1307 - precision: 0.9670 - recall: 0.8873 - val_accuracy: 0.9516 - val_loss: 0.1267 - val_precision: 0.9665 - val_recall: 0.8887 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9545 - loss: 0.1223 - precision: 0.9673 - recall: 0.8898 - val_accuracy: 0.9519 - val_loss: 0.1307 - val_precision: 0.9726 - val_recall: 0.8837 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9530 - loss: 0.1245 - precision: 0.9678 - recall: 0.8872 - val_accuracy: 0.9516 - val_loss: 0.1294 - val_precision: 0.9716 - val_recall: 0.8837 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1121 - precision: 0.9751 - recall: 0.9058 - val_accuracy: 0.9513 - val_loss: 0.1286 - val_precision: 0.9605 - val_recall: 0.8936 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9576 - loss: 0.1163 - precision: 0.9717 - recall: 0.8977 - val_accuracy: 0.9533 - val_loss: 0.1262 - val_precision: 0.9597 - val_recall: 0.9006 - learning_rate: 2.5000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9574 - loss: 0.1164 - precision: 0.9736 - recall: 0.8989 - val_accuracy: 0.9496 - val_loss: 0.1272 - val_precision: 0.9642 - val_recall: 0.8847 - learning_rate: 2.5000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8289 - loss: 0.4049 - precision: 0.8964 - recall: 0.7542 - val_accuracy: 0.9144 - val_loss: 0.2285 - val_precision: 0.8917 - val_recall: 0.8517 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9165 - loss: 0.2267 - precision: 0.9177 - recall: 0.8308 - val_accuracy: 0.9313 - val_loss: 0.1980 - val_precision: 0.9557 - val_recall: 0.8368 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9279 - loss: 0.1975 - precision: 0.9369 - recall: 0.8396 - val_accuracy: 0.9350 - val_loss: 0.1846 - val_precision: 0.9689 - val_recall: 0.8358 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.1784 - precision: 0.9484 - recall: 0.8492 - val_accuracy: 0.9377 - val_loss: 0.1745 - val_precision: 0.9702 - val_recall: 0.8428 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.1741 - precision: 0.9469 - recall: 0.8540 - val_accuracy: 0.9364 - val_loss: 0.1711 - val_precision: 0.9369 - val_recall: 0.8716 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9385 - loss: 0.1644 - precision: 0.9485 - recall: 0.8630 - val_accuracy: 0.9408 - val_loss: 0.1641 - val_precision: 0.9663 - val_recall: 0.8557 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9393 - loss: 0.1638 - precision: 0.9552 - recall: 0.8626 - val_accuracy: 0.9408 - val_loss: 0.1659 - val_precision: 0.9727 - val_recall: 0.8498 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9477 - loss: 0.1455 - precision: 0.9628 - recall: 0.8806 - val_accuracy: 0.9404 - val_loss: 0.1637 - val_precision: 0.9377 - val_recall: 0.8836 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.1448 - precision: 0.9587 - recall: 0.8712 - val_accuracy: 0.9448 - val_loss: 0.1716 - val_precision: 0.9637 - val_recall: 0.8706 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9458 - loss: 0.1453 - precision: 0.9568 - recall: 0.8779 - val_accuracy: 0.9448 - val_loss: 0.1608 - val_precision: 0.9678 - val_recall: 0.8667 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9450 - loss: 0.1459 - precision: 0.9572 - recall: 0.8736 - val_accuracy: 0.9455 - val_loss: 0.1637 - val_precision: 0.9720 - val_recall: 0.8647 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9522 - loss: 0.1355 - precision: 0.9671 - recall: 0.8824 - val_accuracy: 0.9445 - val_loss: 0.1573 - val_precision: 0.9719 - val_recall: 0.8617 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9526 - loss: 0.1269 - precision: 0.9661 - recall: 0.8860 - val_accuracy: 0.9408 - val_loss: 0.1684 - val_precision: 0.9270 - val_recall: 0.8965 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9511 - loss: 0.1360 - precision: 0.9614 - recall: 0.8890 - val_accuracy: 0.9459 - val_loss: 0.1612 - val_precision: 0.9658 - val_recall: 0.8716 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9517 - loss: 0.1303 - precision: 0.9688 - recall: 0.8790 - val_accuracy: 0.9442 - val_loss: 0.1548 - val_precision: 0.9545 - val_recall: 0.8776 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9545 - loss: 0.1265 - precision: 0.9677 - recall: 0.8928 - val_accuracy: 0.9445 - val_loss: 0.1651 - val_precision: 0.9431 - val_recall: 0.8905 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9516 - loss: 0.1276 - precision: 0.9665 - recall: 0.8858 - val_accuracy: 0.9448 - val_loss: 0.1557 - val_precision: 0.9460 - val_recall: 0.8886 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9509 - loss: 0.1283 - precision: 0.9627 - recall: 0.8849 - val_accuracy: 0.9462 - val_loss: 0.1562 - val_precision: 0.9443 - val_recall: 0.8945 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1088 - precision: 0.9751 - recall: 0.9081 - val_accuracy: 0.9489 - val_loss: 0.1603 - val_precision: 0.9692 - val_recall: 0.8776 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9627 - loss: 0.1033 - precision: 0.9763 - recall: 0.9091 - val_accuracy: 0.9455 - val_loss: 0.1550 - val_precision: 0.9567 - val_recall: 0.8796 - learning_rate: 5.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.8109 - loss: 0.4260 - precision: 0.8903 - recall: 0.7150 - val_accuracy: 0.9144 - val_loss: 0.2376 - val_precision: 0.8730 - val_recall: 0.8756 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9122 - loss: 0.2334 - precision: 0.9174 - recall: 0.8141 - val_accuracy: 0.9252 - val_loss: 0.2046 - val_precision: 0.9000 - val_recall: 0.8776 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9267 - loss: 0.2007 - precision: 0.9335 - recall: 0.8449 - val_accuracy: 0.9310 - val_loss: 0.1845 - val_precision: 0.9673 - val_recall: 0.8249 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9387 - loss: 0.1732 - precision: 0.9503 - recall: 0.8617 - val_accuracy: 0.9347 - val_loss: 0.1750 - val_precision: 0.9645 - val_recall: 0.8388 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.1747 - precision: 0.9555 - recall: 0.8504 - val_accuracy: 0.9371 - val_loss: 0.1717 - val_precision: 0.9756 - val_recall: 0.8358 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.1797 - precision: 0.9531 - recall: 0.8469 - val_accuracy: 0.9354 - val_loss: 0.1685 - val_precision: 0.9744 - val_recall: 0.8318 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9446 - loss: 0.1625 - precision: 0.9636 - recall: 0.8636 - val_accuracy: 0.9431 - val_loss: 0.1569 - val_precision: 0.9645 - val_recall: 0.8647 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9459 - loss: 0.1485 - precision: 0.9615 - recall: 0.8694 - val_accuracy: 0.9394 - val_loss: 0.1585 - val_precision: 0.9704 - val_recall: 0.8478 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.1539 - precision: 0.9585 - recall: 0.8655 - val_accuracy: 0.9428 - val_loss: 0.1536 - val_precision: 0.9563 - val_recall: 0.8716 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9447 - loss: 0.1452 - precision: 0.9651 - recall: 0.8637 - val_accuracy: 0.9411 - val_loss: 0.1618 - val_precision: 0.9815 - val_recall: 0.8428 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1395 - precision: 0.9690 - recall: 0.8795 - val_accuracy: 0.9381 - val_loss: 0.1695 - val_precision: 0.9824 - val_recall: 0.8328 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9445 - loss: 0.1487 - precision: 0.9611 - recall: 0.8690 - val_accuracy: 0.9425 - val_loss: 0.1528 - val_precision: 0.9654 - val_recall: 0.8617 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9502 - loss: 0.1373 - precision: 0.9631 - recall: 0.8865 - val_accuracy: 0.9442 - val_loss: 0.1514 - val_precision: 0.9526 - val_recall: 0.8796 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1331 - precision: 0.9652 - recall: 0.8820 - val_accuracy: 0.9442 - val_loss: 0.1566 - val_precision: 0.9321 - val_recall: 0.9015 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1316 - precision: 0.9644 - recall: 0.8859 - val_accuracy: 0.9408 - val_loss: 0.1585 - val_precision: 0.9792 - val_recall: 0.8438 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9500 - loss: 0.1357 - precision: 0.9670 - recall: 0.8821 - val_accuracy: 0.9425 - val_loss: 0.1476 - val_precision: 0.9514 - val_recall: 0.8756 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9568 - loss: 0.1266 - precision: 0.9712 - recall: 0.8973 - val_accuracy: 0.9438 - val_loss: 0.1436 - val_precision: 0.9374 - val_recall: 0.8945 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.1219 - precision: 0.9725 - recall: 0.8963 - val_accuracy: 0.9465 - val_loss: 0.1438 - val_precision: 0.9598 - val_recall: 0.8796 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.1271 - precision: 0.9687 - recall: 0.8853 - val_accuracy: 0.9479 - val_loss: 0.1416 - val_precision: 0.9610 - val_recall: 0.8826 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1187 - precision: 0.9714 - recall: 0.8965 - val_accuracy: 0.9452 - val_loss: 0.1527 - val_precision: 0.9607 - val_recall: 0.8746 - learning_rate: 0.0010\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8199 - loss: 0.4096 - precision: 0.8984 - recall: 0.7270 - val_accuracy: 0.9201 - val_loss: 0.2237 - val_precision: 0.9129 - val_recall: 0.8354 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9174 - loss: 0.2259 - precision: 0.9203 - recall: 0.8162 - val_accuracy: 0.9292 - val_loss: 0.1945 - val_precision: 0.9326 - val_recall: 0.8447 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9340 - loss: 0.1907 - precision: 0.9393 - recall: 0.8555 - val_accuracy: 0.9323 - val_loss: 0.1881 - val_precision: 0.9485 - val_recall: 0.8385 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9347 - loss: 0.1762 - precision: 0.9420 - recall: 0.8563 - val_accuracy: 0.9228 - val_loss: 0.1923 - val_precision: 0.8773 - val_recall: 0.8882 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9385 - loss: 0.1709 - precision: 0.9498 - recall: 0.8637 - val_accuracy: 0.9367 - val_loss: 0.1883 - val_precision: 0.9962 - val_recall: 0.8095 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9386 - loss: 0.1643 - precision: 0.9505 - recall: 0.8610 - val_accuracy: 0.9428 - val_loss: 0.1644 - val_precision: 0.9661 - val_recall: 0.8551 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9379 - loss: 0.1616 - precision: 0.9465 - recall: 0.8604 - val_accuracy: 0.9418 - val_loss: 0.1677 - val_precision: 0.9818 - val_recall: 0.8375 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9420 - loss: 0.1496 - precision: 0.9531 - recall: 0.8711 - val_accuracy: 0.9397 - val_loss: 0.1668 - val_precision: 0.9713 - val_recall: 0.8406 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.1442 - precision: 0.9598 - recall: 0.8808 - val_accuracy: 0.9452 - val_loss: 0.1629 - val_precision: 0.9879 - val_recall: 0.8427 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9440 - loss: 0.1500 - precision: 0.9598 - recall: 0.8692 - val_accuracy: 0.9452 - val_loss: 0.1591 - val_precision: 0.9696 - val_recall: 0.8592 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9453 - loss: 0.1473 - precision: 0.9588 - recall: 0.8744 - val_accuracy: 0.9462 - val_loss: 0.1591 - val_precision: 0.9821 - val_recall: 0.8509 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9468 - loss: 0.1413 - precision: 0.9632 - recall: 0.8757 - val_accuracy: 0.9408 - val_loss: 0.1705 - val_precision: 0.9925 - val_recall: 0.8251 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9526 - loss: 0.1310 - precision: 0.9696 - recall: 0.8869 - val_accuracy: 0.9441 - val_loss: 0.1664 - val_precision: 0.9878 - val_recall: 0.8395 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9535 - loss: 0.1297 - precision: 0.9706 - recall: 0.8848 - val_accuracy: 0.9475 - val_loss: 0.1521 - val_precision: 0.9765 - val_recall: 0.8602 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9584 - loss: 0.1160 - precision: 0.9732 - recall: 0.9001 - val_accuracy: 0.9485 - val_loss: 0.1517 - val_precision: 0.9822 - val_recall: 0.8582 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9516 - loss: 0.1285 - precision: 0.9763 - recall: 0.8777 - val_accuracy: 0.9499 - val_loss: 0.1509 - val_precision: 0.9627 - val_recall: 0.8810 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9563 - loss: 0.1182 - precision: 0.9719 - recall: 0.8972 - val_accuracy: 0.9475 - val_loss: 0.1539 - val_precision: 0.9721 - val_recall: 0.8644 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9572 - loss: 0.1176 - precision: 0.9691 - recall: 0.8999 - val_accuracy: 0.9482 - val_loss: 0.1501 - val_precision: 0.9656 - val_recall: 0.8727 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.1076 - precision: 0.9652 - recall: 0.8990 - val_accuracy: 0.9475 - val_loss: 0.1499 - val_precision: 0.9656 - val_recall: 0.8706 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9598 - loss: 0.1091 - precision: 0.9752 - recall: 0.9052 - val_accuracy: 0.9479 - val_loss: 0.1538 - val_precision: 0.9471 - val_recall: 0.8903 - learning_rate: 5.0000e-04\n",
            "[3/6] Finished batch_size=16, lr=0.001 in 14.73 min. Estimated remaining: 68.83 min (4129.8 sec)\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6322 - loss: 0.6411 - precision: 0.6978 - recall: 0.5775 - val_accuracy: 0.8457 - val_loss: 0.4014 - val_precision: 0.9656 - val_recall: 0.5355 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8442 - loss: 0.3979 - precision: 0.8639 - recall: 0.6496 - val_accuracy: 0.8880 - val_loss: 0.3187 - val_precision: 0.9026 - val_recall: 0.7275 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8800 - loss: 0.3270 - precision: 0.8948 - recall: 0.7338 - val_accuracy: 0.8971 - val_loss: 0.2810 - val_precision: 0.9300 - val_recall: 0.7328 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8961 - loss: 0.2850 - precision: 0.9061 - recall: 0.7682 - val_accuracy: 0.9096 - val_loss: 0.2574 - val_precision: 0.9102 - val_recall: 0.7953 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9080 - loss: 0.2596 - precision: 0.9194 - recall: 0.7931 - val_accuracy: 0.9110 - val_loss: 0.2401 - val_precision: 0.9271 - val_recall: 0.7826 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9135 - loss: 0.2420 - precision: 0.9240 - recall: 0.8102 - val_accuracy: 0.9178 - val_loss: 0.2286 - val_precision: 0.9237 - val_recall: 0.8091 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9177 - loss: 0.2298 - precision: 0.9265 - recall: 0.8260 - val_accuracy: 0.9201 - val_loss: 0.2183 - val_precision: 0.9274 - val_recall: 0.8134 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9212 - loss: 0.2212 - precision: 0.9326 - recall: 0.8276 - val_accuracy: 0.9245 - val_loss: 0.2155 - val_precision: 0.9072 - val_recall: 0.8505 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9248 - loss: 0.2185 - precision: 0.9393 - recall: 0.8309 - val_accuracy: 0.9239 - val_loss: 0.2049 - val_precision: 0.9378 - val_recall: 0.8155 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9294 - loss: 0.2057 - precision: 0.9385 - recall: 0.8492 - val_accuracy: 0.9266 - val_loss: 0.1999 - val_precision: 0.9261 - val_recall: 0.8367 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9314 - loss: 0.1978 - precision: 0.9443 - recall: 0.8453 - val_accuracy: 0.9276 - val_loss: 0.1950 - val_precision: 0.9355 - val_recall: 0.8303 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.1993 - precision: 0.9409 - recall: 0.8447 - val_accuracy: 0.9296 - val_loss: 0.1915 - val_precision: 0.9401 - val_recall: 0.8324 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9313 - loss: 0.1932 - precision: 0.9462 - recall: 0.8442 - val_accuracy: 0.9299 - val_loss: 0.1879 - val_precision: 0.9381 - val_recall: 0.8356 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9304 - loss: 0.1962 - precision: 0.9468 - recall: 0.8452 - val_accuracy: 0.9320 - val_loss: 0.1842 - val_precision: 0.9365 - val_recall: 0.8441 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9316 - loss: 0.1894 - precision: 0.9450 - recall: 0.8491 - val_accuracy: 0.9327 - val_loss: 0.1821 - val_precision: 0.9316 - val_recall: 0.8515 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.1800 - precision: 0.9484 - recall: 0.8591 - val_accuracy: 0.9330 - val_loss: 0.1801 - val_precision: 0.9306 - val_recall: 0.8537 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.1776 - precision: 0.9536 - recall: 0.8573 - val_accuracy: 0.9347 - val_loss: 0.1773 - val_precision: 0.9401 - val_recall: 0.8494 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9366 - loss: 0.1749 - precision: 0.9547 - recall: 0.8559 - val_accuracy: 0.9350 - val_loss: 0.1758 - val_precision: 0.9311 - val_recall: 0.8600 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1696 - precision: 0.9606 - recall: 0.8654 - val_accuracy: 0.9340 - val_loss: 0.1732 - val_precision: 0.9452 - val_recall: 0.8420 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9401 - loss: 0.1705 - precision: 0.9581 - recall: 0.8587 - val_accuracy: 0.9350 - val_loss: 0.1714 - val_precision: 0.9465 - val_recall: 0.8441 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6822 - loss: 0.5947 - precision: 0.7749 - recall: 0.5241 - val_accuracy: 0.8484 - val_loss: 0.4026 - val_precision: 0.9152 - val_recall: 0.6113 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8446 - loss: 0.3902 - precision: 0.8761 - recall: 0.6054 - val_accuracy: 0.8822 - val_loss: 0.3280 - val_precision: 0.9318 - val_recall: 0.7058 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8796 - loss: 0.3262 - precision: 0.9035 - recall: 0.7109 - val_accuracy: 0.9022 - val_loss: 0.2868 - val_precision: 0.9164 - val_recall: 0.7843 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8964 - loss: 0.2894 - precision: 0.9116 - recall: 0.7674 - val_accuracy: 0.9090 - val_loss: 0.2613 - val_precision: 0.9382 - val_recall: 0.7843 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9048 - loss: 0.2607 - precision: 0.9151 - recall: 0.7805 - val_accuracy: 0.9137 - val_loss: 0.2438 - val_precision: 0.9412 - val_recall: 0.7962 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9094 - loss: 0.2491 - precision: 0.9275 - recall: 0.7918 - val_accuracy: 0.9188 - val_loss: 0.2295 - val_precision: 0.9412 - val_recall: 0.8121 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9213 - loss: 0.2308 - precision: 0.9405 - recall: 0.8097 - val_accuracy: 0.9249 - val_loss: 0.2191 - val_precision: 0.9455 - val_recall: 0.8270 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9184 - loss: 0.2245 - precision: 0.9262 - recall: 0.8203 - val_accuracy: 0.9316 - val_loss: 0.2111 - val_precision: 0.9497 - val_recall: 0.8439 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9220 - loss: 0.2205 - precision: 0.9322 - recall: 0.8252 - val_accuracy: 0.9316 - val_loss: 0.2053 - val_precision: 0.9487 - val_recall: 0.8449 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9262 - loss: 0.2122 - precision: 0.9390 - recall: 0.8287 - val_accuracy: 0.9350 - val_loss: 0.2029 - val_precision: 0.9302 - val_recall: 0.8748 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9280 - loss: 0.2025 - precision: 0.9345 - recall: 0.8363 - val_accuracy: 0.9364 - val_loss: 0.1938 - val_precision: 0.9544 - val_recall: 0.8539 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9263 - loss: 0.2050 - precision: 0.9363 - recall: 0.8329 - val_accuracy: 0.9387 - val_loss: 0.1888 - val_precision: 0.9528 - val_recall: 0.8628 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9263 - loss: 0.2062 - precision: 0.9373 - recall: 0.8386 - val_accuracy: 0.9377 - val_loss: 0.1854 - val_precision: 0.9567 - val_recall: 0.8559 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9306 - loss: 0.1953 - precision: 0.9419 - recall: 0.8460 - val_accuracy: 0.9377 - val_loss: 0.1820 - val_precision: 0.9557 - val_recall: 0.8569 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.1945 - precision: 0.9417 - recall: 0.8410 - val_accuracy: 0.9377 - val_loss: 0.1792 - val_precision: 0.9587 - val_recall: 0.8539 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9323 - loss: 0.1907 - precision: 0.9464 - recall: 0.8417 - val_accuracy: 0.9401 - val_loss: 0.1758 - val_precision: 0.9520 - val_recall: 0.8678 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9319 - loss: 0.1886 - precision: 0.9478 - recall: 0.8389 - val_accuracy: 0.9347 - val_loss: 0.1773 - val_precision: 0.9646 - val_recall: 0.8390 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9373 - loss: 0.1796 - precision: 0.9546 - recall: 0.8522 - val_accuracy: 0.9404 - val_loss: 0.1703 - val_precision: 0.9581 - val_recall: 0.8628 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9354 - loss: 0.1779 - precision: 0.9518 - recall: 0.8495 - val_accuracy: 0.9411 - val_loss: 0.1685 - val_precision: 0.9581 - val_recall: 0.8648 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9397 - loss: 0.1694 - precision: 0.9549 - recall: 0.8600 - val_accuracy: 0.9421 - val_loss: 0.1661 - val_precision: 0.9543 - val_recall: 0.8718 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6935 - loss: 0.5781 - precision: 0.8077 - recall: 0.5446 - val_accuracy: 0.8481 - val_loss: 0.4104 - val_precision: 0.9052 - val_recall: 0.6179 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8327 - loss: 0.4031 - precision: 0.8440 - recall: 0.6121 - val_accuracy: 0.8717 - val_loss: 0.3404 - val_precision: 0.9484 - val_recall: 0.6587 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8725 - loss: 0.3292 - precision: 0.8795 - recall: 0.7146 - val_accuracy: 0.8944 - val_loss: 0.2930 - val_precision: 0.9414 - val_recall: 0.7353 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8955 - loss: 0.2892 - precision: 0.9091 - recall: 0.7631 - val_accuracy: 0.9019 - val_loss: 0.2697 - val_precision: 0.8890 - val_recall: 0.8129 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9031 - loss: 0.2705 - precision: 0.9156 - recall: 0.7878 - val_accuracy: 0.9093 - val_loss: 0.2512 - val_precision: 0.9510 - val_recall: 0.7731 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9127 - loss: 0.2475 - precision: 0.9181 - recall: 0.8040 - val_accuracy: 0.9171 - val_loss: 0.2366 - val_precision: 0.9232 - val_recall: 0.8249 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9158 - loss: 0.2431 - precision: 0.9257 - recall: 0.8082 - val_accuracy: 0.9188 - val_loss: 0.2268 - val_precision: 0.9381 - val_recall: 0.8149 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9184 - loss: 0.2314 - precision: 0.9290 - recall: 0.8243 - val_accuracy: 0.9201 - val_loss: 0.2251 - val_precision: 0.9661 - val_recall: 0.7930 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9314 - loss: 0.2056 - precision: 0.9437 - recall: 0.8393 - val_accuracy: 0.9225 - val_loss: 0.2128 - val_precision: 0.9311 - val_recall: 0.8338 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9251 - loss: 0.2126 - precision: 0.9313 - recall: 0.8351 - val_accuracy: 0.9242 - val_loss: 0.2088 - val_precision: 0.9535 - val_recall: 0.8169 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9299 - loss: 0.2035 - precision: 0.9418 - recall: 0.8385 - val_accuracy: 0.9262 - val_loss: 0.2030 - val_precision: 0.9291 - val_recall: 0.8478 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9314 - loss: 0.1981 - precision: 0.9405 - recall: 0.8462 - val_accuracy: 0.9283 - val_loss: 0.1986 - val_precision: 0.9401 - val_recall: 0.8428 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9311 - loss: 0.1960 - precision: 0.9424 - recall: 0.8481 - val_accuracy: 0.9306 - val_loss: 0.1963 - val_precision: 0.9505 - val_recall: 0.8398 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.1894 - precision: 0.9456 - recall: 0.8501 - val_accuracy: 0.9306 - val_loss: 0.1938 - val_precision: 0.9556 - val_recall: 0.8348 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9345 - loss: 0.1844 - precision: 0.9515 - recall: 0.8463 - val_accuracy: 0.9293 - val_loss: 0.1891 - val_precision: 0.9354 - val_recall: 0.8507 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9346 - loss: 0.1862 - precision: 0.9444 - recall: 0.8504 - val_accuracy: 0.9323 - val_loss: 0.1865 - val_precision: 0.9448 - val_recall: 0.8507 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9384 - loss: 0.1765 - precision: 0.9470 - recall: 0.8651 - val_accuracy: 0.9320 - val_loss: 0.1862 - val_precision: 0.9313 - val_recall: 0.8637 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9361 - loss: 0.1801 - precision: 0.9459 - recall: 0.8545 - val_accuracy: 0.9313 - val_loss: 0.1879 - val_precision: 0.9641 - val_recall: 0.8289 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.1784 - precision: 0.9502 - recall: 0.8511 - val_accuracy: 0.9337 - val_loss: 0.1821 - val_precision: 0.9335 - val_recall: 0.8667 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9352 - loss: 0.1772 - precision: 0.9499 - recall: 0.8537 - val_accuracy: 0.9354 - val_loss: 0.1785 - val_precision: 0.9443 - val_recall: 0.8607 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6972 - loss: 0.5834 - precision: 0.7990 - recall: 0.5559 - val_accuracy: 0.8423 - val_loss: 0.3944 - val_precision: 0.9514 - val_recall: 0.5652 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8488 - loss: 0.3854 - precision: 0.8815 - recall: 0.6329 - val_accuracy: 0.8907 - val_loss: 0.3113 - val_precision: 0.9383 - val_recall: 0.7264 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8876 - loss: 0.3172 - precision: 0.9052 - recall: 0.7389 - val_accuracy: 0.9069 - val_loss: 0.2719 - val_precision: 0.9430 - val_recall: 0.7731 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9013 - loss: 0.2764 - precision: 0.9168 - recall: 0.7807 - val_accuracy: 0.9181 - val_loss: 0.2526 - val_precision: 0.9169 - val_recall: 0.8348 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9092 - loss: 0.2554 - precision: 0.9190 - recall: 0.7907 - val_accuracy: 0.9228 - val_loss: 0.2353 - val_precision: 0.9293 - val_recall: 0.8368 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9128 - loss: 0.2480 - precision: 0.9294 - recall: 0.8034 - val_accuracy: 0.9225 - val_loss: 0.2251 - val_precision: 0.9533 - val_recall: 0.8119 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9195 - loss: 0.2263 - precision: 0.9286 - recall: 0.8158 - val_accuracy: 0.9259 - val_loss: 0.2171 - val_precision: 0.9347 - val_recall: 0.8408 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9259 - loss: 0.2150 - precision: 0.9407 - recall: 0.8196 - val_accuracy: 0.9269 - val_loss: 0.2132 - val_precision: 0.9192 - val_recall: 0.8607 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9273 - loss: 0.2120 - precision: 0.9382 - recall: 0.8376 - val_accuracy: 0.9293 - val_loss: 0.2032 - val_precision: 0.9442 - val_recall: 0.8418 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9216 - loss: 0.2153 - precision: 0.9351 - recall: 0.8324 - val_accuracy: 0.9303 - val_loss: 0.1995 - val_precision: 0.9535 - val_recall: 0.8358 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9283 - loss: 0.2052 - precision: 0.9444 - recall: 0.8324 - val_accuracy: 0.9313 - val_loss: 0.1947 - val_precision: 0.9446 - val_recall: 0.8478 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9319 - loss: 0.1985 - precision: 0.9482 - recall: 0.8390 - val_accuracy: 0.9313 - val_loss: 0.1914 - val_precision: 0.9526 - val_recall: 0.8398 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.1909 - precision: 0.9522 - recall: 0.8457 - val_accuracy: 0.9320 - val_loss: 0.1880 - val_precision: 0.9497 - val_recall: 0.8448 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9332 - loss: 0.1880 - precision: 0.9441 - recall: 0.8451 - val_accuracy: 0.9330 - val_loss: 0.1858 - val_precision: 0.9570 - val_recall: 0.8408 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.1874 - precision: 0.9522 - recall: 0.8464 - val_accuracy: 0.9323 - val_loss: 0.1834 - val_precision: 0.9389 - val_recall: 0.8567 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9344 - loss: 0.1824 - precision: 0.9512 - recall: 0.8531 - val_accuracy: 0.9327 - val_loss: 0.1803 - val_precision: 0.9478 - val_recall: 0.8488 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9379 - loss: 0.1768 - precision: 0.9546 - recall: 0.8545 - val_accuracy: 0.9354 - val_loss: 0.1796 - val_precision: 0.9594 - val_recall: 0.8458 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9398 - loss: 0.1685 - precision: 0.9528 - recall: 0.8599 - val_accuracy: 0.9357 - val_loss: 0.1761 - val_precision: 0.9553 - val_recall: 0.8507 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9379 - loss: 0.1746 - precision: 0.9544 - recall: 0.8548 - val_accuracy: 0.9360 - val_loss: 0.1744 - val_precision: 0.9503 - val_recall: 0.8567 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.1697 - precision: 0.9551 - recall: 0.8591 - val_accuracy: 0.9350 - val_loss: 0.1733 - val_precision: 0.9573 - val_recall: 0.8468 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6820 - loss: 0.5898 - precision: 0.8312 - recall: 0.4735 - val_accuracy: 0.8571 - val_loss: 0.4257 - val_precision: 0.8747 - val_recall: 0.6573 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8453 - loss: 0.4093 - precision: 0.8828 - recall: 0.6222 - val_accuracy: 0.8846 - val_loss: 0.3280 - val_precision: 0.9195 - val_recall: 0.7091 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8777 - loss: 0.3306 - precision: 0.8982 - recall: 0.7076 - val_accuracy: 0.9015 - val_loss: 0.2868 - val_precision: 0.8947 - val_recall: 0.7919 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.2934 - precision: 0.9009 - recall: 0.7621 - val_accuracy: 0.9123 - val_loss: 0.2601 - val_precision: 0.9183 - val_recall: 0.8033 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9019 - loss: 0.2609 - precision: 0.9075 - recall: 0.7855 - val_accuracy: 0.9154 - val_loss: 0.2430 - val_precision: 0.9355 - val_recall: 0.7961 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9140 - loss: 0.2452 - precision: 0.9170 - recall: 0.8148 - val_accuracy: 0.9218 - val_loss: 0.2319 - val_precision: 0.9249 - val_recall: 0.8282 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9208 - loss: 0.2293 - precision: 0.9240 - recall: 0.8329 - val_accuracy: 0.9208 - val_loss: 0.2217 - val_precision: 0.9357 - val_recall: 0.8137 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9272 - loss: 0.2139 - precision: 0.9383 - recall: 0.8393 - val_accuracy: 0.9262 - val_loss: 0.2156 - val_precision: 0.9463 - val_recall: 0.8209 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9242 - loss: 0.2147 - precision: 0.9334 - recall: 0.8358 - val_accuracy: 0.9276 - val_loss: 0.2085 - val_precision: 0.9372 - val_recall: 0.8344 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9308 - loss: 0.1978 - precision: 0.9383 - recall: 0.8494 - val_accuracy: 0.9292 - val_loss: 0.2043 - val_precision: 0.9490 - val_recall: 0.8282 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9296 - loss: 0.1984 - precision: 0.9397 - recall: 0.8461 - val_accuracy: 0.9303 - val_loss: 0.2000 - val_precision: 0.9378 - val_recall: 0.8427 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9304 - loss: 0.1985 - precision: 0.9368 - recall: 0.8445 - val_accuracy: 0.9313 - val_loss: 0.1961 - val_precision: 0.9494 - val_recall: 0.8344 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9328 - loss: 0.1846 - precision: 0.9368 - recall: 0.8540 - val_accuracy: 0.9309 - val_loss: 0.1934 - val_precision: 0.9536 - val_recall: 0.8292 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9325 - loss: 0.1923 - precision: 0.9485 - recall: 0.8489 - val_accuracy: 0.9330 - val_loss: 0.1895 - val_precision: 0.9414 - val_recall: 0.8478 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.1831 - precision: 0.9432 - recall: 0.8590 - val_accuracy: 0.9340 - val_loss: 0.1876 - val_precision: 0.9477 - val_recall: 0.8447 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.1898 - precision: 0.9467 - recall: 0.8531 - val_accuracy: 0.9336 - val_loss: 0.1847 - val_precision: 0.9487 - val_recall: 0.8427 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.1773 - precision: 0.9486 - recall: 0.8506 - val_accuracy: 0.9364 - val_loss: 0.1842 - val_precision: 0.9664 - val_recall: 0.8344 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.1788 - precision: 0.9492 - recall: 0.8522 - val_accuracy: 0.9374 - val_loss: 0.1832 - val_precision: 0.9699 - val_recall: 0.8344 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9359 - loss: 0.1799 - precision: 0.9490 - recall: 0.8519 - val_accuracy: 0.9374 - val_loss: 0.1789 - val_precision: 0.9600 - val_recall: 0.8437 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9388 - loss: 0.1718 - precision: 0.9453 - recall: 0.8637 - val_accuracy: 0.9384 - val_loss: 0.1783 - val_precision: 0.9645 - val_recall: 0.8427 - learning_rate: 1.0000e-04\n",
            "[4/6] Finished batch_size=16, lr=0.0001 in 14.28 min. Estimated remaining: 41.56 min (2493.4 sec)\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7883 - loss: 0.4545 - precision: 0.8891 - recall: 0.6775 - val_accuracy: 0.9113 - val_loss: 0.2482 - val_precision: 0.8813 - val_recall: 0.8346 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9095 - loss: 0.2418 - precision: 0.9049 - recall: 0.8131 - val_accuracy: 0.9279 - val_loss: 0.2037 - val_precision: 0.9195 - val_recall: 0.8484 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9264 - loss: 0.2086 - precision: 0.9388 - recall: 0.8397 - val_accuracy: 0.9289 - val_loss: 0.1903 - val_precision: 0.9453 - val_recall: 0.8250 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9315 - loss: 0.1929 - precision: 0.9425 - recall: 0.8437 - val_accuracy: 0.9299 - val_loss: 0.1842 - val_precision: 0.9488 - val_recall: 0.8250 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9344 - loss: 0.1804 - precision: 0.9457 - recall: 0.8579 - val_accuracy: 0.9398 - val_loss: 0.1732 - val_precision: 0.9371 - val_recall: 0.8696 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9374 - loss: 0.1700 - precision: 0.9476 - recall: 0.8603 - val_accuracy: 0.9343 - val_loss: 0.1769 - val_precision: 0.9747 - val_recall: 0.8155 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9349 - loss: 0.1735 - precision: 0.9483 - recall: 0.8534 - val_accuracy: 0.9401 - val_loss: 0.1663 - val_precision: 0.9362 - val_recall: 0.8717 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9389 - loss: 0.1611 - precision: 0.9564 - recall: 0.8567 - val_accuracy: 0.9404 - val_loss: 0.1597 - val_precision: 0.9626 - val_recall: 0.8462 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9400 - loss: 0.1610 - precision: 0.9586 - recall: 0.8585 - val_accuracy: 0.9462 - val_loss: 0.1541 - val_precision: 0.9558 - val_recall: 0.8717 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9430 - loss: 0.1529 - precision: 0.9630 - recall: 0.8690 - val_accuracy: 0.9438 - val_loss: 0.1570 - val_precision: 0.9709 - val_recall: 0.8494 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9468 - loss: 0.1447 - precision: 0.9632 - recall: 0.8730 - val_accuracy: 0.9459 - val_loss: 0.1489 - val_precision: 0.9622 - val_recall: 0.8643 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9422 - loss: 0.1572 - precision: 0.9594 - recall: 0.8698 - val_accuracy: 0.9398 - val_loss: 0.1584 - val_precision: 0.9153 - val_recall: 0.8940 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9480 - loss: 0.1406 - precision: 0.9594 - recall: 0.8829 - val_accuracy: 0.9438 - val_loss: 0.1490 - val_precision: 0.9341 - val_recall: 0.8865 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9506 - loss: 0.1396 - precision: 0.9654 - recall: 0.8833 - val_accuracy: 0.9486 - val_loss: 0.1453 - val_precision: 0.9510 - val_recall: 0.8844 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9464 - loss: 0.1461 - precision: 0.9675 - recall: 0.8695 - val_accuracy: 0.9455 - val_loss: 0.1564 - val_precision: 0.9815 - val_recall: 0.8452 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9466 - loss: 0.1428 - precision: 0.9656 - recall: 0.8719 - val_accuracy: 0.9479 - val_loss: 0.1458 - val_precision: 0.9478 - val_recall: 0.8855 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9507 - loss: 0.1346 - precision: 0.9649 - recall: 0.8853 - val_accuracy: 0.9516 - val_loss: 0.1414 - val_precision: 0.9662 - val_recall: 0.8791 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9510 - loss: 0.1328 - precision: 0.9616 - recall: 0.8873 - val_accuracy: 0.9496 - val_loss: 0.1411 - val_precision: 0.9522 - val_recall: 0.8865 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9551 - loss: 0.1268 - precision: 0.9684 - recall: 0.8948 - val_accuracy: 0.9374 - val_loss: 0.1631 - val_precision: 0.8883 - val_recall: 0.9194 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9513 - loss: 0.1283 - precision: 0.9640 - recall: 0.8900 - val_accuracy: 0.9479 - val_loss: 0.1427 - val_precision: 0.9448 - val_recall: 0.8887 - learning_rate: 0.0010\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7819 - loss: 0.4555 - precision: 0.8575 - recall: 0.6970 - val_accuracy: 0.9073 - val_loss: 0.2668 - val_precision: 0.8466 - val_recall: 0.8887 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9136 - loss: 0.2410 - precision: 0.9124 - recall: 0.8195 - val_accuracy: 0.9320 - val_loss: 0.2002 - val_precision: 0.9361 - val_recall: 0.8588 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9230 - loss: 0.2145 - precision: 0.9298 - recall: 0.8298 - val_accuracy: 0.9283 - val_loss: 0.1945 - val_precision: 0.9671 - val_recall: 0.8171 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9296 - loss: 0.2021 - precision: 0.9378 - recall: 0.8437 - val_accuracy: 0.9401 - val_loss: 0.1704 - val_precision: 0.9501 - val_recall: 0.8698 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9321 - loss: 0.1869 - precision: 0.9378 - recall: 0.8505 - val_accuracy: 0.9411 - val_loss: 0.1675 - val_precision: 0.9541 - val_recall: 0.8688 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9353 - loss: 0.1768 - precision: 0.9514 - recall: 0.8498 - val_accuracy: 0.9425 - val_loss: 0.1584 - val_precision: 0.9583 - val_recall: 0.8688 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9361 - loss: 0.1681 - precision: 0.9473 - recall: 0.8540 - val_accuracy: 0.9445 - val_loss: 0.1503 - val_precision: 0.9678 - val_recall: 0.8658 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9399 - loss: 0.1644 - precision: 0.9540 - recall: 0.8574 - val_accuracy: 0.9459 - val_loss: 0.1487 - val_precision: 0.9539 - val_recall: 0.8837 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9423 - loss: 0.1581 - precision: 0.9564 - recall: 0.8657 - val_accuracy: 0.9421 - val_loss: 0.1537 - val_precision: 0.9761 - val_recall: 0.8509 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9408 - loss: 0.1667 - precision: 0.9571 - recall: 0.8614 - val_accuracy: 0.9509 - val_loss: 0.1396 - val_precision: 0.9684 - val_recall: 0.8847 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9475 - loss: 0.1431 - precision: 0.9598 - recall: 0.8788 - val_accuracy: 0.9489 - val_loss: 0.1396 - val_precision: 0.9777 - val_recall: 0.8698 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9478 - loss: 0.1362 - precision: 0.9623 - recall: 0.8767 - val_accuracy: 0.9486 - val_loss: 0.1366 - val_precision: 0.9734 - val_recall: 0.8728 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9461 - loss: 0.1460 - precision: 0.9643 - recall: 0.8697 - val_accuracy: 0.9516 - val_loss: 0.1318 - val_precision: 0.9716 - val_recall: 0.8837 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9491 - loss: 0.1364 - precision: 0.9632 - recall: 0.8791 - val_accuracy: 0.9543 - val_loss: 0.1338 - val_precision: 0.9570 - val_recall: 0.9066 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9545 - loss: 0.1379 - precision: 0.9718 - recall: 0.8916 - val_accuracy: 0.9513 - val_loss: 0.1351 - val_precision: 0.9757 - val_recall: 0.8787 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9528 - loss: 0.1347 - precision: 0.9653 - recall: 0.8867 - val_accuracy: 0.9486 - val_loss: 0.1396 - val_precision: 0.9467 - val_recall: 0.8996 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9577 - loss: 0.1240 - precision: 0.9766 - recall: 0.8958 - val_accuracy: 0.9526 - val_loss: 0.1286 - val_precision: 0.9606 - val_recall: 0.8976 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9562 - loss: 0.1256 - precision: 0.9709 - recall: 0.8952 - val_accuracy: 0.9486 - val_loss: 0.1290 - val_precision: 0.9504 - val_recall: 0.8956 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9573 - loss: 0.1233 - precision: 0.9715 - recall: 0.8979 - val_accuracy: 0.9503 - val_loss: 0.1315 - val_precision: 0.9469 - val_recall: 0.9046 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 0.1164 - precision: 0.9706 - recall: 0.8995 - val_accuracy: 0.9530 - val_loss: 0.1278 - val_precision: 0.9587 - val_recall: 0.9006 - learning_rate: 5.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8035 - loss: 0.4275 - precision: 0.8847 - recall: 0.7152 - val_accuracy: 0.9100 - val_loss: 0.2401 - val_precision: 0.9074 - val_recall: 0.8189 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9175 - loss: 0.2333 - precision: 0.9204 - recall: 0.8232 - val_accuracy: 0.9269 - val_loss: 0.2098 - val_precision: 0.9603 - val_recall: 0.8189 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9257 - loss: 0.2070 - precision: 0.9302 - recall: 0.8347 - val_accuracy: 0.9259 - val_loss: 0.1916 - val_precision: 0.9068 - val_recall: 0.8716 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9281 - loss: 0.1987 - precision: 0.9402 - recall: 0.8429 - val_accuracy: 0.9289 - val_loss: 0.1962 - val_precision: 0.9877 - val_recall: 0.8010 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9368 - loss: 0.1735 - precision: 0.9483 - recall: 0.8596 - val_accuracy: 0.9381 - val_loss: 0.1724 - val_precision: 0.9681 - val_recall: 0.8458 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9416 - loss: 0.1619 - precision: 0.9568 - recall: 0.8622 - val_accuracy: 0.9377 - val_loss: 0.1698 - val_precision: 0.9438 - val_recall: 0.8687 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9419 - loss: 0.1646 - precision: 0.9552 - recall: 0.8654 - val_accuracy: 0.9391 - val_loss: 0.1708 - val_precision: 0.9393 - val_recall: 0.8776 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9400 - loss: 0.1610 - precision: 0.9527 - recall: 0.8611 - val_accuracy: 0.9418 - val_loss: 0.1622 - val_precision: 0.9633 - val_recall: 0.8617 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9439 - loss: 0.1496 - precision: 0.9583 - recall: 0.8694 - val_accuracy: 0.9391 - val_loss: 0.1626 - val_precision: 0.9328 - val_recall: 0.8846 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9479 - loss: 0.1446 - precision: 0.9605 - recall: 0.8785 - val_accuracy: 0.9415 - val_loss: 0.1680 - val_precision: 0.9749 - val_recall: 0.8498 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9498 - loss: 0.1451 - precision: 0.9663 - recall: 0.8810 - val_accuracy: 0.9418 - val_loss: 0.1609 - val_precision: 0.9464 - val_recall: 0.8786 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9497 - loss: 0.1420 - precision: 0.9624 - recall: 0.8820 - val_accuracy: 0.9445 - val_loss: 0.1578 - val_precision: 0.9636 - val_recall: 0.8697 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9508 - loss: 0.1330 - precision: 0.9639 - recall: 0.8837 - val_accuracy: 0.9425 - val_loss: 0.1553 - val_precision: 0.9838 - val_recall: 0.8448 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9500 - loss: 0.1378 - precision: 0.9695 - recall: 0.8736 - val_accuracy: 0.9445 - val_loss: 0.1539 - val_precision: 0.9698 - val_recall: 0.8637 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9526 - loss: 0.1275 - precision: 0.9632 - recall: 0.8911 - val_accuracy: 0.9445 - val_loss: 0.1526 - val_precision: 0.9596 - val_recall: 0.8736 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9480 - loss: 0.1357 - precision: 0.9601 - recall: 0.8787 - val_accuracy: 0.9455 - val_loss: 0.1557 - val_precision: 0.9528 - val_recall: 0.8836 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9533 - loss: 0.1318 - precision: 0.9666 - recall: 0.8929 - val_accuracy: 0.9459 - val_loss: 0.1557 - val_precision: 0.9617 - val_recall: 0.8756 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9545 - loss: 0.1196 - precision: 0.9659 - recall: 0.8951 - val_accuracy: 0.9486 - val_loss: 0.1534 - val_precision: 0.9744 - val_recall: 0.8716 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9606 - loss: 0.1122 - precision: 0.9725 - recall: 0.9069 - val_accuracy: 0.9469 - val_loss: 0.1510 - val_precision: 0.9599 - val_recall: 0.8806 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9564 - loss: 0.1109 - precision: 0.9706 - recall: 0.8951 - val_accuracy: 0.9472 - val_loss: 0.1485 - val_precision: 0.9639 - val_recall: 0.8776 - learning_rate: 5.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7944 - loss: 0.4385 - precision: 0.8782 - recall: 0.7108 - val_accuracy: 0.9130 - val_loss: 0.2373 - val_precision: 0.9506 - val_recall: 0.7851 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9116 - loss: 0.2432 - precision: 0.9178 - recall: 0.8049 - val_accuracy: 0.9289 - val_loss: 0.2038 - val_precision: 0.9461 - val_recall: 0.8388 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9305 - loss: 0.2021 - precision: 0.9388 - recall: 0.8470 - val_accuracy: 0.9330 - val_loss: 0.1925 - val_precision: 0.9665 - val_recall: 0.8318 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9386 - loss: 0.1846 - precision: 0.9531 - recall: 0.8530 - val_accuracy: 0.9340 - val_loss: 0.1811 - val_precision: 0.9571 - val_recall: 0.8438 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9341 - loss: 0.1782 - precision: 0.9462 - recall: 0.8486 - val_accuracy: 0.9330 - val_loss: 0.1822 - val_precision: 0.9676 - val_recall: 0.8308 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9434 - loss: 0.1623 - precision: 0.9572 - recall: 0.8700 - val_accuracy: 0.9384 - val_loss: 0.1665 - val_precision: 0.9577 - val_recall: 0.8567 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9352 - loss: 0.1756 - precision: 0.9493 - recall: 0.8523 - val_accuracy: 0.9398 - val_loss: 0.1670 - val_precision: 0.9726 - val_recall: 0.8468 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9398 - loss: 0.1631 - precision: 0.9588 - recall: 0.8526 - val_accuracy: 0.9408 - val_loss: 0.1609 - val_precision: 0.9632 - val_recall: 0.8587 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9462 - loss: 0.1510 - precision: 0.9562 - recall: 0.8789 - val_accuracy: 0.9404 - val_loss: 0.1600 - val_precision: 0.9631 - val_recall: 0.8577 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9446 - loss: 0.1510 - precision: 0.9596 - recall: 0.8722 - val_accuracy: 0.9381 - val_loss: 0.1620 - val_precision: 0.9263 - val_recall: 0.8886 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9430 - loss: 0.1499 - precision: 0.9590 - recall: 0.8677 - val_accuracy: 0.9398 - val_loss: 0.1597 - val_precision: 0.9321 - val_recall: 0.8876 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9479 - loss: 0.1432 - precision: 0.9648 - recall: 0.8749 - val_accuracy: 0.9415 - val_loss: 0.1529 - val_precision: 0.9483 - val_recall: 0.8756 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.1424 - precision: 0.9639 - recall: 0.8784 - val_accuracy: 0.9418 - val_loss: 0.1496 - val_precision: 0.9464 - val_recall: 0.8786 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9518 - loss: 0.1383 - precision: 0.9659 - recall: 0.8871 - val_accuracy: 0.9411 - val_loss: 0.1525 - val_precision: 0.9632 - val_recall: 0.8597 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9481 - loss: 0.1386 - precision: 0.9636 - recall: 0.8755 - val_accuracy: 0.9455 - val_loss: 0.1502 - val_precision: 0.9518 - val_recall: 0.8846 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9536 - loss: 0.1288 - precision: 0.9659 - recall: 0.8916 - val_accuracy: 0.9452 - val_loss: 0.1477 - val_precision: 0.9577 - val_recall: 0.8776 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9516 - loss: 0.1354 - precision: 0.9656 - recall: 0.8871 - val_accuracy: 0.9442 - val_loss: 0.1496 - val_precision: 0.9421 - val_recall: 0.8905 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9552 - loss: 0.1273 - precision: 0.9705 - recall: 0.8890 - val_accuracy: 0.9435 - val_loss: 0.1525 - val_precision: 0.9615 - val_recall: 0.8687 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9608 - loss: 0.1148 - precision: 0.9729 - recall: 0.9072 - val_accuracy: 0.9455 - val_loss: 0.1473 - val_precision: 0.9557 - val_recall: 0.8806 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9574 - loss: 0.1222 - precision: 0.9710 - recall: 0.8981 - val_accuracy: 0.9445 - val_loss: 0.1558 - val_precision: 0.9358 - val_recall: 0.8985 - learning_rate: 0.0010\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.8047 - loss: 0.4361 - precision: 0.8942 - recall: 0.7022 - val_accuracy: 0.9072 - val_loss: 0.2486 - val_precision: 0.8597 - val_recall: 0.8561 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9070 - loss: 0.2511 - precision: 0.9008 - recall: 0.8128 - val_accuracy: 0.9262 - val_loss: 0.2148 - val_precision: 0.9734 - val_recall: 0.7961 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.2008 - precision: 0.9364 - recall: 0.8485 - val_accuracy: 0.9343 - val_loss: 0.1898 - val_precision: 0.9662 - val_recall: 0.8282 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9359 - loss: 0.1802 - precision: 0.9419 - recall: 0.8596 - val_accuracy: 0.9336 - val_loss: 0.1797 - val_precision: 0.9375 - val_recall: 0.8540 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9320 - loss: 0.1789 - precision: 0.9448 - recall: 0.8453 - val_accuracy: 0.9357 - val_loss: 0.1774 - val_precision: 0.9429 - val_recall: 0.8551 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9373 - loss: 0.1691 - precision: 0.9462 - recall: 0.8558 - val_accuracy: 0.9391 - val_loss: 0.1702 - val_precision: 0.9602 - val_recall: 0.8489 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9418 - loss: 0.1566 - precision: 0.9513 - recall: 0.8714 - val_accuracy: 0.9394 - val_loss: 0.1714 - val_precision: 0.9852 - val_recall: 0.8271 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9400 - loss: 0.1588 - precision: 0.9554 - recall: 0.8577 - val_accuracy: 0.9418 - val_loss: 0.1642 - val_precision: 0.9660 - val_recall: 0.8520 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9479 - loss: 0.1502 - precision: 0.9606 - recall: 0.8766 - val_accuracy: 0.9404 - val_loss: 0.1639 - val_precision: 0.9540 - val_recall: 0.8592 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9485 - loss: 0.1407 - precision: 0.9609 - recall: 0.8821 - val_accuracy: 0.9377 - val_loss: 0.1694 - val_precision: 0.9142 - val_recall: 0.8934 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9471 - loss: 0.1415 - precision: 0.9522 - recall: 0.8867 - val_accuracy: 0.9347 - val_loss: 0.1711 - val_precision: 0.9056 - val_recall: 0.8934 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9439 - loss: 0.1483 - precision: 0.9548 - recall: 0.8748 - val_accuracy: 0.9465 - val_loss: 0.1606 - val_precision: 0.9856 - val_recall: 0.8489 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9498 - loss: 0.1382 - precision: 0.9601 - recall: 0.8871 - val_accuracy: 0.9462 - val_loss: 0.1575 - val_precision: 0.9697 - val_recall: 0.8623 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9484 - loss: 0.1339 - precision: 0.9574 - recall: 0.8834 - val_accuracy: 0.9438 - val_loss: 0.1611 - val_precision: 0.9415 - val_recall: 0.8830 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9539 - loss: 0.1262 - precision: 0.9652 - recall: 0.8942 - val_accuracy: 0.9455 - val_loss: 0.1537 - val_precision: 0.9528 - val_recall: 0.8768 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9516 - loss: 0.1290 - precision: 0.9652 - recall: 0.8902 - val_accuracy: 0.9431 - val_loss: 0.1658 - val_precision: 0.9842 - val_recall: 0.8395 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9560 - loss: 0.1285 - precision: 0.9734 - recall: 0.8911 - val_accuracy: 0.9485 - val_loss: 0.1541 - val_precision: 0.9744 - val_recall: 0.8654 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1190 - precision: 0.9648 - recall: 0.9013 - val_accuracy: 0.9465 - val_loss: 0.1524 - val_precision: 0.9676 - val_recall: 0.8654 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9537 - loss: 0.1233 - precision: 0.9647 - recall: 0.8947 - val_accuracy: 0.9448 - val_loss: 0.1526 - val_precision: 0.9578 - val_recall: 0.8696 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9494 - loss: 0.1290 - precision: 0.9576 - recall: 0.8903 - val_accuracy: 0.9472 - val_loss: 0.1560 - val_precision: 0.9856 - val_recall: 0.8509 - learning_rate: 0.0010\n",
            "[5/6] Finished batch_size=32, lr=0.001 in 8.77 min. Estimated remaining: 18.38 min (1102.7 sec)\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.6696 - loss: 0.6265 - precision: 0.8481 - recall: 0.4142 - val_accuracy: 0.8274 - val_loss: 0.4680 - val_precision: 0.9446 - val_recall: 0.4878 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8162 - loss: 0.4586 - precision: 0.8578 - recall: 0.5352 - val_accuracy: 0.8724 - val_loss: 0.3733 - val_precision: 0.9186 - val_recall: 0.6585 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8604 - loss: 0.3726 - precision: 0.8842 - recall: 0.6709 - val_accuracy: 0.8860 - val_loss: 0.3273 - val_precision: 0.8826 - val_recall: 0.7413 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8757 - loss: 0.3334 - precision: 0.8788 - recall: 0.7348 - val_accuracy: 0.8948 - val_loss: 0.2942 - val_precision: 0.9093 - val_recall: 0.7444 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8970 - loss: 0.2929 - precision: 0.9182 - recall: 0.7650 - val_accuracy: 0.9032 - val_loss: 0.2738 - val_precision: 0.9163 - val_recall: 0.7667 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9007 - loss: 0.2742 - precision: 0.9189 - recall: 0.7678 - val_accuracy: 0.9069 - val_loss: 0.2585 - val_precision: 0.9196 - val_recall: 0.7762 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9052 - loss: 0.2705 - precision: 0.9145 - recall: 0.7893 - val_accuracy: 0.9113 - val_loss: 0.2482 - val_precision: 0.9078 - val_recall: 0.8038 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9130 - loss: 0.2470 - precision: 0.9241 - recall: 0.8085 - val_accuracy: 0.9151 - val_loss: 0.2412 - val_precision: 0.8995 - val_recall: 0.8261 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9121 - loss: 0.2462 - precision: 0.9239 - recall: 0.8059 - val_accuracy: 0.9171 - val_loss: 0.2318 - val_precision: 0.9106 - val_recall: 0.8208 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9182 - loss: 0.2324 - precision: 0.9246 - recall: 0.8225 - val_accuracy: 0.9188 - val_loss: 0.2281 - val_precision: 0.8999 - val_recall: 0.8388 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9213 - loss: 0.2269 - precision: 0.9255 - recall: 0.8294 - val_accuracy: 0.9205 - val_loss: 0.2200 - val_precision: 0.9194 - val_recall: 0.8229 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9200 - loss: 0.2269 - precision: 0.9275 - recall: 0.8301 - val_accuracy: 0.9218 - val_loss: 0.2153 - val_precision: 0.9218 - val_recall: 0.8250 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9248 - loss: 0.2158 - precision: 0.9327 - recall: 0.8357 - val_accuracy: 0.9218 - val_loss: 0.2121 - val_precision: 0.9120 - val_recall: 0.8356 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9255 - loss: 0.2137 - precision: 0.9348 - recall: 0.8347 - val_accuracy: 0.9239 - val_loss: 0.2083 - val_precision: 0.9214 - val_recall: 0.8324 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9235 - loss: 0.2117 - precision: 0.9341 - recall: 0.8364 - val_accuracy: 0.9235 - val_loss: 0.2047 - val_precision: 0.9193 - val_recall: 0.8335 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9288 - loss: 0.2031 - precision: 0.9394 - recall: 0.8437 - val_accuracy: 0.9266 - val_loss: 0.2040 - val_precision: 0.9088 - val_recall: 0.8558 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9334 - loss: 0.1967 - precision: 0.9387 - recall: 0.8548 - val_accuracy: 0.9266 - val_loss: 0.1991 - val_precision: 0.9291 - val_recall: 0.8335 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9291 - loss: 0.2007 - precision: 0.9350 - recall: 0.8478 - val_accuracy: 0.9279 - val_loss: 0.1972 - val_precision: 0.9215 - val_recall: 0.8462 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9316 - loss: 0.1944 - precision: 0.9373 - recall: 0.8502 - val_accuracy: 0.9296 - val_loss: 0.1956 - val_precision: 0.9162 - val_recall: 0.8579 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9286 - loss: 0.1973 - precision: 0.9384 - recall: 0.8469 - val_accuracy: 0.9299 - val_loss: 0.1926 - val_precision: 0.9211 - val_recall: 0.8537 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.6408 - loss: 0.6370 - precision: 0.6997 - recall: 0.4993 - val_accuracy: 0.8000 - val_loss: 0.4780 - val_precision: 0.9814 - val_recall: 0.4205 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8032 - loss: 0.4579 - precision: 0.8378 - recall: 0.4922 - val_accuracy: 0.8531 - val_loss: 0.3838 - val_precision: 0.9583 - val_recall: 0.5944 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8566 - loss: 0.3696 - precision: 0.8864 - recall: 0.6295 - val_accuracy: 0.8937 - val_loss: 0.3283 - val_precision: 0.9129 - val_recall: 0.7604 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8826 - loss: 0.3231 - precision: 0.9004 - recall: 0.7220 - val_accuracy: 0.9022 - val_loss: 0.2945 - val_precision: 0.9304 - val_recall: 0.7704 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8907 - loss: 0.2959 - precision: 0.9104 - recall: 0.7475 - val_accuracy: 0.9076 - val_loss: 0.2731 - val_precision: 0.9368 - val_recall: 0.7813 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9020 - loss: 0.2711 - precision: 0.9236 - recall: 0.7728 - val_accuracy: 0.9161 - val_loss: 0.2583 - val_precision: 0.9278 - val_recall: 0.8171 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9058 - loss: 0.2654 - precision: 0.9216 - recall: 0.7806 - val_accuracy: 0.9140 - val_loss: 0.2453 - val_precision: 0.9413 - val_recall: 0.7972 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9141 - loss: 0.2454 - precision: 0.9292 - recall: 0.8028 - val_accuracy: 0.9151 - val_loss: 0.2355 - val_precision: 0.9489 - val_recall: 0.7932 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9141 - loss: 0.2404 - precision: 0.9262 - recall: 0.8090 - val_accuracy: 0.9245 - val_loss: 0.2269 - val_precision: 0.9365 - val_recall: 0.8350 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9142 - loss: 0.2391 - precision: 0.9276 - recall: 0.8104 - val_accuracy: 0.9239 - val_loss: 0.2196 - val_precision: 0.9494 - val_recall: 0.8201 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9193 - loss: 0.2293 - precision: 0.9305 - recall: 0.8188 - val_accuracy: 0.9320 - val_loss: 0.2135 - val_precision: 0.9487 - val_recall: 0.8459 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9237 - loss: 0.2169 - precision: 0.9326 - recall: 0.8215 - val_accuracy: 0.9245 - val_loss: 0.2100 - val_precision: 0.9526 - val_recall: 0.8191 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9186 - loss: 0.2200 - precision: 0.9288 - recall: 0.8138 - val_accuracy: 0.9350 - val_loss: 0.2051 - val_precision: 0.9405 - val_recall: 0.8638 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9213 - loss: 0.2130 - precision: 0.9288 - recall: 0.8270 - val_accuracy: 0.9343 - val_loss: 0.2002 - val_precision: 0.9521 - val_recall: 0.8499 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9279 - loss: 0.2026 - precision: 0.9410 - recall: 0.8346 - val_accuracy: 0.9364 - val_loss: 0.2002 - val_precision: 0.9305 - val_recall: 0.8787 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9274 - loss: 0.2026 - precision: 0.9350 - recall: 0.8406 - val_accuracy: 0.9333 - val_loss: 0.1937 - val_precision: 0.9520 - val_recall: 0.8469 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9260 - loss: 0.2040 - precision: 0.9394 - recall: 0.8332 - val_accuracy: 0.9374 - val_loss: 0.1902 - val_precision: 0.9496 - val_recall: 0.8618 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9322 - loss: 0.1940 - precision: 0.9451 - recall: 0.8432 - val_accuracy: 0.9367 - val_loss: 0.1872 - val_precision: 0.9525 - val_recall: 0.8569 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9320 - loss: 0.1900 - precision: 0.9425 - recall: 0.8476 - val_accuracy: 0.9374 - val_loss: 0.1870 - val_precision: 0.9326 - val_recall: 0.8797 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9304 - loss: 0.1921 - precision: 0.9389 - recall: 0.8479 - val_accuracy: 0.9391 - val_loss: 0.1821 - val_precision: 0.9422 - val_recall: 0.8748 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.6885 - loss: 0.5954 - precision: 0.8251 - recall: 0.4844 - val_accuracy: 0.8088 - val_loss: 0.4581 - val_precision: 0.9641 - val_recall: 0.4547 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8172 - loss: 0.4461 - precision: 0.8526 - recall: 0.5341 - val_accuracy: 0.8653 - val_loss: 0.3734 - val_precision: 0.8886 - val_recall: 0.6905 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8671 - loss: 0.3609 - precision: 0.8899 - recall: 0.6732 - val_accuracy: 0.8816 - val_loss: 0.3251 - val_precision: 0.9130 - val_recall: 0.7204 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8833 - loss: 0.3189 - precision: 0.9000 - recall: 0.7330 - val_accuracy: 0.8944 - val_loss: 0.2953 - val_precision: 0.9448 - val_recall: 0.7323 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8905 - loss: 0.2927 - precision: 0.9045 - recall: 0.7472 - val_accuracy: 0.9052 - val_loss: 0.2738 - val_precision: 0.9240 - val_recall: 0.7861 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9090 - loss: 0.2629 - precision: 0.9239 - recall: 0.7897 - val_accuracy: 0.9107 - val_loss: 0.2588 - val_precision: 0.9354 - val_recall: 0.7920 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9113 - loss: 0.2555 - precision: 0.9243 - recall: 0.7950 - val_accuracy: 0.9140 - val_loss: 0.2469 - val_precision: 0.9282 - val_recall: 0.8100 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9165 - loss: 0.2484 - precision: 0.9315 - recall: 0.8043 - val_accuracy: 0.9171 - val_loss: 0.2371 - val_precision: 0.9388 - val_recall: 0.8090 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9185 - loss: 0.2362 - precision: 0.9271 - recall: 0.8137 - val_accuracy: 0.9198 - val_loss: 0.2304 - val_precision: 0.9550 - val_recall: 0.8020 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9169 - loss: 0.2288 - precision: 0.9257 - recall: 0.8151 - val_accuracy: 0.9218 - val_loss: 0.2238 - val_precision: 0.9521 - val_recall: 0.8109 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9238 - loss: 0.2216 - precision: 0.9311 - recall: 0.8272 - val_accuracy: 0.9252 - val_loss: 0.2180 - val_precision: 0.9465 - val_recall: 0.8269 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9274 - loss: 0.2121 - precision: 0.9353 - recall: 0.8345 - val_accuracy: 0.9266 - val_loss: 0.2133 - val_precision: 0.9487 - val_recall: 0.8289 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9272 - loss: 0.2106 - precision: 0.9385 - recall: 0.8348 - val_accuracy: 0.9279 - val_loss: 0.2094 - val_precision: 0.9521 - val_recall: 0.8299 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9295 - loss: 0.2081 - precision: 0.9449 - recall: 0.8416 - val_accuracy: 0.9296 - val_loss: 0.2052 - val_precision: 0.9534 - val_recall: 0.8338 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9303 - loss: 0.2015 - precision: 0.9387 - recall: 0.8456 - val_accuracy: 0.9283 - val_loss: 0.2042 - val_precision: 0.9594 - val_recall: 0.8239 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9322 - loss: 0.1949 - precision: 0.9433 - recall: 0.8455 - val_accuracy: 0.9310 - val_loss: 0.1982 - val_precision: 0.9465 - val_recall: 0.8448 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9324 - loss: 0.2016 - precision: 0.9405 - recall: 0.8435 - val_accuracy: 0.9330 - val_loss: 0.1962 - val_precision: 0.9601 - val_recall: 0.8378 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9296 - loss: 0.1965 - precision: 0.9437 - recall: 0.8386 - val_accuracy: 0.9330 - val_loss: 0.1939 - val_precision: 0.9570 - val_recall: 0.8408 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9304 - loss: 0.1956 - precision: 0.9438 - recall: 0.8366 - val_accuracy: 0.9303 - val_loss: 0.1914 - val_precision: 0.9319 - val_recall: 0.8577 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9292 - loss: 0.1932 - precision: 0.9322 - recall: 0.8456 - val_accuracy: 0.9337 - val_loss: 0.1900 - val_precision: 0.9633 - val_recall: 0.8368 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.6286 - loss: 0.6376 - precision: 0.7078 - recall: 0.4884 - val_accuracy: 0.8152 - val_loss: 0.4741 - val_precision: 0.9491 - val_recall: 0.4826 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8195 - loss: 0.4516 - precision: 0.8642 - recall: 0.5262 - val_accuracy: 0.8714 - val_loss: 0.3769 - val_precision: 0.8844 - val_recall: 0.7154 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8584 - loss: 0.3758 - precision: 0.8775 - recall: 0.6645 - val_accuracy: 0.8897 - val_loss: 0.3246 - val_precision: 0.9292 - val_recall: 0.7313 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8803 - loss: 0.3271 - precision: 0.8953 - recall: 0.7180 - val_accuracy: 0.8931 - val_loss: 0.2930 - val_precision: 0.9400 - val_recall: 0.7323 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8934 - loss: 0.2967 - precision: 0.9054 - recall: 0.7514 - val_accuracy: 0.9042 - val_loss: 0.2714 - val_precision: 0.9413 - val_recall: 0.7662 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9059 - loss: 0.2707 - precision: 0.9199 - recall: 0.7834 - val_accuracy: 0.9117 - val_loss: 0.2554 - val_precision: 0.9376 - val_recall: 0.7930 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9084 - loss: 0.2596 - precision: 0.9175 - recall: 0.7876 - val_accuracy: 0.9113 - val_loss: 0.2476 - val_precision: 0.9547 - val_recall: 0.7761 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9076 - loss: 0.2599 - precision: 0.9257 - recall: 0.7909 - val_accuracy: 0.9184 - val_loss: 0.2344 - val_precision: 0.9411 - val_recall: 0.8109 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9188 - loss: 0.2350 - precision: 0.9313 - recall: 0.8138 - val_accuracy: 0.9215 - val_loss: 0.2264 - val_precision: 0.9407 - val_recall: 0.8209 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9204 - loss: 0.2308 - precision: 0.9308 - recall: 0.8169 - val_accuracy: 0.9178 - val_loss: 0.2236 - val_precision: 0.9514 - val_recall: 0.7990 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9217 - loss: 0.2247 - precision: 0.9366 - recall: 0.8230 - val_accuracy: 0.9262 - val_loss: 0.2146 - val_precision: 0.9406 - val_recall: 0.8358 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9199 - loss: 0.2259 - precision: 0.9306 - recall: 0.8225 - val_accuracy: 0.9269 - val_loss: 0.2100 - val_precision: 0.9350 - val_recall: 0.8438 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9313 - loss: 0.2053 - precision: 0.9386 - recall: 0.8478 - val_accuracy: 0.9252 - val_loss: 0.2068 - val_precision: 0.9475 - val_recall: 0.8259 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9294 - loss: 0.2122 - precision: 0.9427 - recall: 0.8393 - val_accuracy: 0.9269 - val_loss: 0.2021 - val_precision: 0.9359 - val_recall: 0.8428 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9291 - loss: 0.2045 - precision: 0.9439 - recall: 0.8362 - val_accuracy: 0.9296 - val_loss: 0.1994 - val_precision: 0.9384 - val_recall: 0.8488 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9283 - loss: 0.2026 - precision: 0.9428 - recall: 0.8387 - val_accuracy: 0.9286 - val_loss: 0.1963 - val_precision: 0.9451 - val_recall: 0.8388 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9269 - loss: 0.2002 - precision: 0.9375 - recall: 0.8377 - val_accuracy: 0.9286 - val_loss: 0.1963 - val_precision: 0.9584 - val_recall: 0.8259 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9389 - loss: 0.1839 - precision: 0.9514 - recall: 0.8586 - val_accuracy: 0.9286 - val_loss: 0.1965 - val_precision: 0.9649 - val_recall: 0.8199 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9322 - loss: 0.1973 - precision: 0.9538 - recall: 0.8411 - val_accuracy: 0.9313 - val_loss: 0.1896 - val_precision: 0.9349 - val_recall: 0.8577 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9332 - loss: 0.1859 - precision: 0.9415 - recall: 0.8484 - val_accuracy: 0.9330 - val_loss: 0.1885 - val_precision: 0.9580 - val_recall: 0.8398 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.6400 - loss: 0.6226 - precision: 0.7142 - recall: 0.5392 - val_accuracy: 0.8436 - val_loss: 0.4379 - val_precision: 0.9375 - val_recall: 0.5590 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8287 - loss: 0.4260 - precision: 0.8649 - recall: 0.5671 - val_accuracy: 0.8734 - val_loss: 0.3544 - val_precision: 0.9181 - val_recall: 0.6729 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8602 - loss: 0.3591 - precision: 0.8859 - recall: 0.6685 - val_accuracy: 0.8873 - val_loss: 0.3136 - val_precision: 0.9378 - val_recall: 0.7019 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8808 - loss: 0.3219 - precision: 0.9052 - recall: 0.7252 - val_accuracy: 0.8991 - val_loss: 0.2870 - val_precision: 0.9453 - val_recall: 0.7340 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8901 - loss: 0.2942 - precision: 0.9084 - recall: 0.7406 - val_accuracy: 0.9100 - val_loss: 0.2675 - val_precision: 0.9397 - val_recall: 0.7743 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9016 - loss: 0.2739 - precision: 0.9170 - recall: 0.7807 - val_accuracy: 0.9147 - val_loss: 0.2533 - val_precision: 0.9270 - val_recall: 0.8023 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9134 - loss: 0.2481 - precision: 0.9269 - recall: 0.7922 - val_accuracy: 0.9150 - val_loss: 0.2432 - val_precision: 0.9408 - val_recall: 0.7899 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9115 - loss: 0.2463 - precision: 0.9251 - recall: 0.8014 - val_accuracy: 0.9191 - val_loss: 0.2350 - val_precision: 0.9449 - val_recall: 0.7992 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9125 - loss: 0.2426 - precision: 0.9242 - recall: 0.8021 - val_accuracy: 0.9221 - val_loss: 0.2271 - val_precision: 0.9488 - val_recall: 0.8054 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9145 - loss: 0.2295 - precision: 0.9286 - recall: 0.8071 - val_accuracy: 0.9265 - val_loss: 0.2213 - val_precision: 0.9485 - val_recall: 0.8199 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9197 - loss: 0.2283 - precision: 0.9284 - recall: 0.8209 - val_accuracy: 0.9272 - val_loss: 0.2160 - val_precision: 0.9382 - val_recall: 0.8323 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9242 - loss: 0.2136 - precision: 0.9350 - recall: 0.8317 - val_accuracy: 0.9272 - val_loss: 0.2111 - val_precision: 0.9497 - val_recall: 0.8209 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9273 - loss: 0.2073 - precision: 0.9458 - recall: 0.8293 - val_accuracy: 0.9272 - val_loss: 0.2080 - val_precision: 0.9311 - val_recall: 0.8395 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9246 - loss: 0.2079 - precision: 0.9334 - recall: 0.8442 - val_accuracy: 0.9296 - val_loss: 0.2030 - val_precision: 0.9397 - val_recall: 0.8385 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9331 - loss: 0.1975 - precision: 0.9426 - recall: 0.8533 - val_accuracy: 0.9309 - val_loss: 0.2006 - val_precision: 0.9482 - val_recall: 0.8344 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9255 - loss: 0.1981 - precision: 0.9320 - recall: 0.8405 - val_accuracy: 0.9292 - val_loss: 0.1975 - val_precision: 0.9366 - val_recall: 0.8406 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9326 - loss: 0.1932 - precision: 0.9462 - recall: 0.8543 - val_accuracy: 0.9303 - val_loss: 0.1948 - val_precision: 0.9408 - val_recall: 0.8395 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9331 - loss: 0.1893 - precision: 0.9489 - recall: 0.8464 - val_accuracy: 0.9316 - val_loss: 0.1951 - val_precision: 0.9625 - val_recall: 0.8230 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9335 - loss: 0.1855 - precision: 0.9450 - recall: 0.8501 - val_accuracy: 0.9306 - val_loss: 0.1904 - val_precision: 0.9492 - val_recall: 0.8323 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9361 - loss: 0.1815 - precision: 0.9529 - recall: 0.8522 - val_accuracy: 0.9326 - val_loss: 0.1905 - val_precision: 0.9615 - val_recall: 0.8271 - learning_rate: 1.0000e-04\n",
            "[6/6] Finished batch_size=32, lr=0.0001 in 8.74 min. Estimated remaining: 0.00 min (0.0 sec)\n",
            "✅ 最佳模型与参数已保存： {'batch_size': 8, 'learning_rate': 0.001, 'accuracy': np.float64(0.9497087597846985), 'recall': np.float64(0.8856665968894959), 'precision': np.float64(0.9603936553001404)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the test set using the best model\n",
        "scores = best_vgg_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Set Metrics: loss: {scores[0]:.4f} - recall: {scores[1]:.4f} - precision: {scores[2]:.4f} - accuracy: {scores[3]:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZLwQtQy_B6rg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b459287-b5dd-4232-d9c8-3aac0a47d90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9500 - loss: 0.1594 - precision: 0.9576 - recall: 0.8826\n",
            "Test Set Metrics: loss: 0.1632 - recall: 0.8757 - precision: 0.9574 - accuracy: 0.9456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN - Rebecca"
      ],
      "metadata": {
        "id": "w5mTXinXgLfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import Recall\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(128, activation='relu'),\n",
        "\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', Recall(name='recall'), Precision(name='precision')])\n"
      ],
      "metadata": {
        "id": "LigANY5exmju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e2a405-56a1-4bde-dbda-5ab2e7a1e66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### monitor = recall"
      ],
      "metadata": {
        "id": "0SirbY7rLLcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_recall',mode='max',patience=5,restore_best_weights=True,verbose=1),\n",
        "    ModelCheckpoint('best_model_recall.keras',monitor='val_recall',mode='max',save_best_only=True,verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_recall',mode='max',factor=0.5,patience=3,min_lr=1e-6,verbose=1)\n",
        "]\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XrQR6CNv_ks",
        "outputId": "d759033b-4a07-4c0f-c6f7-08195d740939",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8057 - loss: 0.4441 - precision: 0.7589 - recall: 0.5762\n",
            "Epoch 1: val_recall improved from -inf to 0.84728, saving model to best_model_recall.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.8057 - loss: 0.4440 - precision: 0.7590 - recall: 0.5764 - val_accuracy: 0.9017 - val_loss: 0.2488 - val_precision: 0.8563 - val_recall: 0.8473 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2368 - precision: 0.9195 - recall: 0.8095\n",
            "Epoch 2: val_recall improved from 0.84728 to 0.86190, saving model to best_model_recall.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2368 - precision: 0.9196 - recall: 0.8095 - val_accuracy: 0.9231 - val_loss: 0.1984 - val_precision: 0.9030 - val_recall: 0.8619 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m691/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.1865 - precision: 0.9520 - recall: 0.8410\n",
            "Epoch 3: val_recall improved from 0.86190 to 0.88058, saving model to best_model_recall.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.1864 - precision: 0.9520 - recall: 0.8411 - val_accuracy: 0.9302 - val_loss: 0.2020 - val_precision: 0.9071 - val_recall: 0.8806 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m690/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1552 - precision: 0.9539 - recall: 0.8733\n",
            "Epoch 4: val_recall did not improve from 0.88058\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9435 - loss: 0.1552 - precision: 0.9539 - recall: 0.8733 - val_accuracy: 0.9404 - val_loss: 0.1608 - val_precision: 0.9659 - val_recall: 0.8513 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m680/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9533 - loss: 0.1338 - precision: 0.9678 - recall: 0.8889\n",
            "Epoch 5: val_recall did not improve from 0.88058\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9533 - loss: 0.1339 - precision: 0.9676 - recall: 0.8888 - val_accuracy: 0.9396 - val_loss: 0.1732 - val_precision: 0.9837 - val_recall: 0.8327 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m677/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1267 - precision: 0.9685 - recall: 0.8981\n",
            "Epoch 6: val_recall did not improve from 0.88058\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1265 - precision: 0.9685 - recall: 0.8983 - val_accuracy: 0.9448 - val_loss: 0.1589 - val_precision: 0.9647 - val_recall: 0.8660 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m680/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.0889 - precision: 0.9733 - recall: 0.9300\n",
            "Epoch 7: val_recall did not improve from 0.88058\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.0888 - precision: 0.9734 - recall: 0.9301 - val_accuracy: 0.9475 - val_loss: 0.1762 - val_precision: 0.9905 - val_recall: 0.8505 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.0676 - precision: 0.9830 - recall: 0.9457\n",
            "Epoch 8: val_recall improved from 0.88058 to 0.88952, saving model to best_model_recall.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9761 - loss: 0.0676 - precision: 0.9830 - recall: 0.9456 - val_accuracy: 0.9491 - val_loss: 0.1520 - val_precision: 0.9547 - val_recall: 0.8895 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0596 - precision: 0.9869 - recall: 0.9573\n",
            "Epoch 9: val_recall did not improve from 0.88952\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0597 - precision: 0.9868 - recall: 0.9572 - val_accuracy: 0.9464 - val_loss: 0.1763 - val_precision: 0.9760 - val_recall: 0.8603 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m680/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0525 - precision: 0.9845 - recall: 0.9578\n",
            "Epoch 10: val_recall improved from 0.88952 to 0.90820, saving model to best_model_recall.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0525 - precision: 0.9844 - recall: 0.9578 - val_accuracy: 0.9486 - val_loss: 0.1778 - val_precision: 0.9356 - val_recall: 0.9082 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0429 - precision: 0.9863 - recall: 0.9709\n",
            "Epoch 11: val_recall did not improve from 0.90820\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9860 - loss: 0.0430 - precision: 0.9863 - recall: 0.9709 - val_accuracy: 0.9337 - val_loss: 0.2213 - val_precision: 0.9660 - val_recall: 0.8302 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m678/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0403 - precision: 0.9871 - recall: 0.9708\n",
            "Epoch 12: val_recall improved from 0.90820 to 0.92201, saving model to best_model_recall.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0404 - precision: 0.9871 - recall: 0.9708 - val_accuracy: 0.9299 - val_loss: 0.2670 - val_precision: 0.8744 - val_recall: 0.9220 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m688/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0325 - precision: 0.9914 - recall: 0.9767\n",
            "Epoch 13: val_recall did not improve from 0.92201\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0325 - precision: 0.9914 - recall: 0.9767 - val_accuracy: 0.9467 - val_loss: 0.1975 - val_precision: 0.9352 - val_recall: 0.9025 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m680/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0290 - precision: 0.9925 - recall: 0.9814\n",
            "Epoch 14: val_recall did not improve from 0.92201\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0290 - precision: 0.9925 - recall: 0.9813 - val_accuracy: 0.9486 - val_loss: 0.2373 - val_precision: 0.9643 - val_recall: 0.8781 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m685/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0207 - precision: 0.9914 - recall: 0.9852\n",
            "Epoch 15: val_recall did not improve from 0.92201\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0208 - precision: 0.9914 - recall: 0.9851 - val_accuracy: 0.9445 - val_loss: 0.2768 - val_precision: 0.9385 - val_recall: 0.8920 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m682/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0210 - precision: 0.9911 - recall: 0.9882\n",
            "Epoch 16: val_recall did not improve from 0.92201\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0209 - precision: 0.9912 - recall: 0.9883 - val_accuracy: 0.9491 - val_loss: 0.2363 - val_precision: 0.9539 - val_recall: 0.8903 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m683/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0078 - precision: 0.9979 - recall: 0.9950\n",
            "Epoch 17: val_recall did not improve from 0.92201\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0079 - precision: 0.9979 - recall: 0.9950 - val_accuracy: 0.9502 - val_loss: 0.2955 - val_precision: 0.9755 - val_recall: 0.8725 - learning_rate: 2.5000e-04\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('best_model_recall.keras')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Recall(name='recall'), Precision(name='precision')])\n",
        "results = model.evaluate(X_test, y_test, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-kcaPgpxtFG",
        "outputId": "6b9e864c-7f74-401a-a669-b447f4b6f171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.2523 - precision: 0.8620 - recall: 0.9394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### monitor = loss"
      ],
      "metadata": {
        "id": "ek5lzv9kLRiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss',mode='min',patience=5,restore_best_weights=True,verbose=1),\n",
        "    ModelCheckpoint('best_model_loss.keras',monitor='val_loss',mode='min',save_best_only=True,verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss',mode='min',factor=0.5,patience=3,min_lr=1e-6,verbose=1)\n",
        "]\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2hCuJjYwLf5J",
        "outputId": "c4361361-60b0-4bce-e3da-6dbe9cd0d0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0596 - precision: 0.9767 - recall: 0.9603\n",
            "Epoch 1: val_loss improved from inf to 0.20770, saving model to best_model_loss.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0596 - precision: 0.9767 - recall: 0.9603 - val_accuracy: 0.9448 - val_loss: 0.2077 - val_precision: 0.9355 - val_recall: 0.8960 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0571 - precision: 0.9826 - recall: 0.9594\n",
            "Epoch 2: val_loss did not improve from 0.20770\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0571 - precision: 0.9826 - recall: 0.9594 - val_accuracy: 0.9461 - val_loss: 0.2092 - val_precision: 0.9503 - val_recall: 0.8846 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0531 - precision: 0.9842 - recall: 0.9626\n",
            "Epoch 3: val_loss did not improve from 0.20770\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0531 - precision: 0.9841 - recall: 0.9626 - val_accuracy: 0.9375 - val_loss: 0.2199 - val_precision: 0.9587 - val_recall: 0.8489 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m687/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0436 - precision: 0.9842 - recall: 0.9663\n",
            "Epoch 4: val_loss did not improve from 0.20770\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0436 - precision: 0.9841 - recall: 0.9663 - val_accuracy: 0.9423 - val_loss: 0.2291 - val_precision: 0.9249 - val_recall: 0.9001 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m689/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0207 - precision: 0.9926 - recall: 0.9858\n",
            "Epoch 5: val_loss did not improve from 0.20770\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0208 - precision: 0.9926 - recall: 0.9858 - val_accuracy: 0.9488 - val_loss: 0.2731 - val_precision: 0.9771 - val_recall: 0.8668 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m683/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0144 - precision: 0.9963 - recall: 0.9906\n",
            "Epoch 6: val_loss did not improve from 0.20770\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0144 - precision: 0.9963 - recall: 0.9906 - val_accuracy: 0.9472 - val_loss: 0.3191 - val_precision: 0.9718 - val_recall: 0.8668 - learning_rate: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('best_model_loss.keras')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Recall(name='recall'), Precision(name='precision')])\n",
        "results = model.evaluate(X_test, y_test, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaTLxe1QLTya",
        "outputId": "0a8dcf2b-d256-421d-dbe6-89db1c24cd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9486 - loss: 0.1865 - precision: 0.9294 - recall: 0.9072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use CV to find the best design of CNN"
      ],
      "metadata": {
        "id": "NSt60lIM1tZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(version='A'):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(32, 32, 3)))\n",
        "\n",
        "    if version == 'A':\n",
        "        convs = [32, 64, 128]\n",
        "        dense = 128\n",
        "        dropout = None\n",
        "    elif version == 'B':\n",
        "        convs = [32, 64]\n",
        "        dense = 64\n",
        "        dropout = None\n",
        "    elif version == 'C':\n",
        "        convs = [64, 128, 256]\n",
        "        dense = 256\n",
        "        dropout = 0.3\n",
        "    elif version == 'D':\n",
        "        convs = [32, 64, 64]\n",
        "        dense = 128\n",
        "        dropout = 0.5\n",
        "\n",
        "    for c in convs:\n",
        "        model.add(layers.Conv2D(c, (3,3), activation='relu', padding='same'))\n",
        "        model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    if dropout:\n",
        "        model.add(layers.Dropout(dropout))\n",
        "    model.add(layers.Dense(dense, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', Recall(name='recall'), Precision(name='precision')]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "Fb0uWeMJ17Bt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cross validation to find the best design"
      ],
      "metadata": {
        "id": "wQspV8ZBCfaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "model_versions = ['A', 'B', 'C', 'D']\n",
        "results = {}\n",
        "\n",
        "for version in model_versions:\n",
        "    print(f\"\\nEvaluating Model Version {version}\")\n",
        "    all_scores = {'accuracy': [], 'recall': [], 'precision': []}\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_new, y_train_new)):\n",
        "        print(f\"  Fold {fold+1}\")\n",
        "\n",
        "        X_train, X_val = X_train_new[train_idx], X_train_new[val_idx]\n",
        "        y_train, y_val = y_train_new[train_idx], y_train_new[val_idx]\n",
        "\n",
        "        model = build_model(version)\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_recall', mode='max', patience=5, restore_best_weights=True, verbose=0),\n",
        "            ReduceLROnPlateau(monitor='val_recall', mode='max', factor=0.5, patience=3, min_lr=1e-6, verbose=0),\n",
        "        ]\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=50,\n",
        "            batch_size=16,\n",
        "            callbacks=callbacks,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
        "        all_scores['accuracy'].append(scores[1])\n",
        "        all_scores['recall'].append(scores[2])\n",
        "        all_scores['precision'].append(scores[3])\n",
        "\n",
        "    results[version] = {\n",
        "        'accuracy': np.mean(all_scores['accuracy']),\n",
        "        'recall': np.mean(all_scores['recall']),\n",
        "        'precision': np.mean(all_scores['precision']),\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y-hJGzl3N3Y",
        "outputId": "2bf2a225-ff86-465f-cc3c-510de70a9e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Model Version A\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "\n",
            "Evaluating Model Version B\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "\n",
            "Evaluating Model Version C\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "\n",
            "Evaluating Model Version D\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### print results and model summary"
      ],
      "metadata": {
        "id": "_YZ5KJ_cCtFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCV Results：\")\n",
        "for version, metrics in results.items():\n",
        "    print(f\"Model {version}: acc={metrics['accuracy']:.4f}, recall={metrics['recall']:.4f}, precision={metrics['precision']:.4f}\")\n",
        "best_version = max(results.items(), key=lambda x: x[1]['recall'])[0]\n",
        "print(f\"\\nVersion of the best design is {best_version}, based on Recall\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGoYidO3AOJU",
        "outputId": "ea192d94-99e6-4386-cdc5-9969079dfe4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CV Results：\n",
            "Model A: acc=0.9557, recall=0.9357, precision=0.9317\n",
            "Model B: acc=0.9291, recall=0.9464, precision=0.8642\n",
            "Model C: acc=0.9368, recall=0.9342, precision=0.8864\n",
            "Model D: acc=0.9542, recall=0.9268, precision=0.9375\n",
            "\n",
            "Version of the best design is B, based on Recall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = build_model(best_version)\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "o2Uy8fnSC9N5",
        "outputId": "baabd266-dacb-48dd-f9e0-80aa0dc735cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m262,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m281,665\u001b[0m (1.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">281,665</span> (1.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m281,665\u001b[0m (1.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">281,665</span> (1.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train the best model on the entire train set"
      ],
      "metadata": {
        "id": "nSSrwDEYD3SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(\n",
        "    X_train_new, y_train_new,\n",
        "    validation_split=0.1,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[\n",
        "        ModelCheckpoint('best_cnn.keras',monitor='val_recall',mode='max',save_best_only=True,verbose=1),\n",
        "        EarlyStopping(monitor='val_recall', mode='max', patience=5, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_recall', mode='max', factor=0.5, patience=3, min_lr=1e-6)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iDVHAKrwAhVz",
        "outputId": "a59ae93e-51b6-48ed-de83-f2371bbde131"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m819/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0677 - precision: 0.9817 - recall: 0.9524\n",
            "Epoch 1: val_recall improved from -inf to 0.92184, saving model to best_cnn.keras\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.0678 - precision: 0.9817 - recall: 0.9523 - val_accuracy: 0.9398 - val_loss: 0.1590 - val_precision: 0.9020 - val_recall: 0.9218 - learning_rate: 2.5000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m814/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0678 - precision: 0.9821 - recall: 0.9523\n",
            "Epoch 2: val_recall did not improve from 0.92184\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0678 - precision: 0.9821 - recall: 0.9523 - val_accuracy: 0.9486 - val_loss: 0.1486 - val_precision: 0.9273 - val_recall: 0.9198 - learning_rate: 2.5000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m819/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0603 - precision: 0.9838 - recall: 0.9569\n",
            "Epoch 3: val_recall did not improve from 0.92184\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0603 - precision: 0.9837 - recall: 0.9569 - val_accuracy: 0.9526 - val_loss: 0.1563 - val_precision: 0.9777 - val_recall: 0.8798 - learning_rate: 2.5000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m829/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0609 - precision: 0.9814 - recall: 0.9570\n",
            "Epoch 4: val_recall did not improve from 0.92184\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0609 - precision: 0.9814 - recall: 0.9570 - val_accuracy: 0.9533 - val_loss: 0.1406 - val_precision: 0.9479 - val_recall: 0.9118 - learning_rate: 2.5000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m827/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0467 - precision: 0.9887 - recall: 0.9654\n",
            "Epoch 5: val_recall did not improve from 0.92184\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0467 - precision: 0.9887 - recall: 0.9653 - val_accuracy: 0.9486 - val_loss: 0.1445 - val_precision: 0.9343 - val_recall: 0.9118 - learning_rate: 1.2500e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m815/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0449 - precision: 0.9877 - recall: 0.9670\n",
            "Epoch 6: val_recall did not improve from 0.92184\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0449 - precision: 0.9877 - recall: 0.9670 - val_accuracy: 0.9479 - val_loss: 0.1488 - val_precision: 0.9237 - val_recall: 0.9218 - learning_rate: 1.2500e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cc7cb459290>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### use performance on testset as the final performance evaluation result of simple cnn"
      ],
      "metadata": {
        "id": "IKfY8va1Ej1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('best_cnn.keras')\n",
        "model.save('/content/drive/MyDrive/best_cnn_model.keras')"
      ],
      "metadata": {
        "id": "uHGGDC3QBnbh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID7k14plEjcU",
        "outputId": "9c599246-9990-4afa-9966-f7200bd825ef"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9565 - loss: 0.1352 - precision: 0.9266 - recall: 0.9374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## InceptionV3 - Vicki"
      ],
      "metadata": {
        "id": "kieVUtDM7fvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Resizing\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "\n",
        "def build_inception_model():\n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "    x = Resizing(128, 128)(inputs)\n",
        "    base = InceptionV3(weights=None, include_top=False, input_tensor=x)\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    return Model(inputs=inputs, outputs=output)\n"
      ],
      "metadata": {
        "id": "dnbgy0bI7j11",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception = build_inception_model()\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "]\n",
        "\n",
        "inception.compile(\n",
        "    optimizer=Adam(1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
        ")\n",
        "\n",
        "inception.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "IFgCIufnywKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54e3482-a45f-42ef-a9be-293f6b7e549f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7392 - loss: 0.5307 - precision: 0.6299 - recall: 0.5651\n",
            "Epoch 1: val_loss improved from inf to 0.34998, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 153ms/step - accuracy: 0.7392 - loss: 0.5306 - precision: 0.6301 - recall: 0.5652 - val_accuracy: 0.8609 - val_loss: 0.3500 - val_precision: 0.8030 - val_recall: 0.7717 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8624 - loss: 0.3403 - precision: 0.8098 - recall: 0.7478\n",
            "Epoch 2: val_loss improved from 0.34998 to 0.24251, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 75ms/step - accuracy: 0.8624 - loss: 0.3403 - precision: 0.8099 - recall: 0.7479 - val_accuracy: 0.9082 - val_loss: 0.2425 - val_precision: 0.8919 - val_recall: 0.8245 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8963 - loss: 0.2774 - precision: 0.8698 - recall: 0.8104\n",
            "Epoch 3: val_loss did not improve from 0.24251\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 69ms/step - accuracy: 0.8963 - loss: 0.2774 - precision: 0.8698 - recall: 0.8104 - val_accuracy: 0.8990 - val_loss: 0.5224 - val_precision: 0.8326 - val_recall: 0.8725 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9101 - loss: 0.2427 - precision: 0.8950 - recall: 0.8296\n",
            "Epoch 4: val_loss improved from 0.24251 to 0.20441, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.9101 - loss: 0.2426 - precision: 0.8951 - recall: 0.8296 - val_accuracy: 0.9174 - val_loss: 0.2044 - val_precision: 0.8646 - val_recall: 0.8920 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9301 - loss: 0.2059 - precision: 0.9202 - recall: 0.8675\n",
            "Epoch 5: val_loss did not improve from 0.20441\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 66ms/step - accuracy: 0.9301 - loss: 0.2059 - precision: 0.9202 - recall: 0.8675 - val_accuracy: 0.9031 - val_loss: 0.6302 - val_precision: 0.8616 - val_recall: 0.8448 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9259 - loss: 0.2052 - precision: 0.9133 - recall: 0.8584\n",
            "Epoch 6: val_loss did not improve from 0.20441\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 66ms/step - accuracy: 0.9259 - loss: 0.2052 - precision: 0.9133 - recall: 0.8584 - val_accuracy: 0.9220 - val_loss: 0.2438 - val_precision: 0.9306 - val_recall: 0.8278 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9408 - loss: 0.1742 - precision: 0.9416 - recall: 0.8746\n",
            "Epoch 7: val_loss did not improve from 0.20441\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 66ms/step - accuracy: 0.9408 - loss: 0.1742 - precision: 0.9416 - recall: 0.8746 - val_accuracy: 0.9239 - val_loss: 0.2113 - val_precision: 0.9005 - val_recall: 0.8676 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9487 - loss: 0.1452 - precision: 0.9491 - recall: 0.8923\n",
            "Epoch 8: val_loss improved from 0.20441 to 0.14536, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.9487 - loss: 0.1452 - precision: 0.9492 - recall: 0.8924 - val_accuracy: 0.9486 - val_loss: 0.1454 - val_precision: 0.9677 - val_recall: 0.8749 - learning_rate: 5.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9576 - loss: 0.1279 - precision: 0.9631 - recall: 0.9080\n",
            "Epoch 9: val_loss did not improve from 0.14536\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.9576 - loss: 0.1279 - precision: 0.9631 - recall: 0.9080 - val_accuracy: 0.9437 - val_loss: 0.1716 - val_precision: 0.9794 - val_recall: 0.8489 - learning_rate: 5.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9596 - loss: 0.1206 - precision: 0.9550 - recall: 0.9216\n",
            "Epoch 10: val_loss improved from 0.14536 to 0.14342, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 71ms/step - accuracy: 0.9596 - loss: 0.1206 - precision: 0.9550 - recall: 0.9216 - val_accuracy: 0.9502 - val_loss: 0.1434 - val_precision: 0.9704 - val_recall: 0.8773 - learning_rate: 5.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9620 - loss: 0.1106 - precision: 0.9651 - recall: 0.9178\n",
            "Epoch 11: val_loss did not improve from 0.14342\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 66ms/step - accuracy: 0.9620 - loss: 0.1106 - precision: 0.9651 - recall: 0.9178 - val_accuracy: 0.9364 - val_loss: 0.2148 - val_precision: 0.9102 - val_recall: 0.8976 - learning_rate: 5.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9674 - loss: 0.1067 - precision: 0.9661 - recall: 0.9327\n",
            "Epoch 12: val_loss did not improve from 0.14342\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 66ms/step - accuracy: 0.9674 - loss: 0.1067 - precision: 0.9661 - recall: 0.9327 - val_accuracy: 0.9486 - val_loss: 0.1491 - val_precision: 0.9291 - val_recall: 0.9155 - learning_rate: 5.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9691 - loss: 0.0989 - precision: 0.9699 - recall: 0.9365\n",
            "Epoch 13: val_loss did not improve from 0.14342\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 67ms/step - accuracy: 0.9691 - loss: 0.0989 - precision: 0.9699 - recall: 0.9365 - val_accuracy: 0.9285 - val_loss: 0.6387 - val_precision: 0.8769 - val_recall: 0.9139 - learning_rate: 5.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9796 - loss: 0.0663 - precision: 0.9814 - recall: 0.9576\n",
            "Epoch 14: val_loss did not improve from 0.14342\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 66ms/step - accuracy: 0.9796 - loss: 0.0663 - precision: 0.9814 - recall: 0.9576 - val_accuracy: 0.9450 - val_loss: 0.2780 - val_precision: 0.9341 - val_recall: 0.8985 - learning_rate: 2.5000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9817 - loss: 0.0590 - precision: 0.9830 - recall: 0.9614\n",
            "Epoch 15: val_loss did not improve from 0.14342\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.9817 - loss: 0.0590 - precision: 0.9830 - recall: 0.9615 - val_accuracy: 0.9421 - val_loss: 0.2730 - val_precision: 0.9206 - val_recall: 0.9041 - learning_rate: 2.5000e-05\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79a0e9897850>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CV"
      ],
      "metadata": {
        "id": "2a7y02jxKsRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "acc_list, recall_list, precision_list = [], [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train)):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "\n",
        "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    inception = build_inception_model()\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "    ]\n",
        "\n",
        "    inception.compile(\n",
        "        optimizer=Adam(1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
        "    )\n",
        "\n",
        "    inception.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=10,\n",
        "        batch_size=16,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    best_inception = load_model(\"best_model.keras\",\n",
        "                            custom_objects={'Precision': Precision, 'Recall': Recall})\n",
        "\n",
        "    scores = best_inception.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "    #scores = model.evaluate(X_val, y_val, verbose=0)\n",
        "    acc_list.append(scores[3])        # accuracy\n",
        "    recall_list.append(scores[1])     # recall\n",
        "    precision_list.append(scores[2])  # precision\n",
        "\n",
        "print(f\"Average Accuracy: {np.mean(acc_list):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recall_list):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precision_list):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kikeJFo0v3FO",
        "outputId": "1b1248b1-8378-425e-e47a-a84b2a2bba94",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch 1/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7642 - loss: 0.5169 - precision: 0.6690 - recall: 0.6065\n",
            "Epoch 1: val_loss improved from inf to 0.41968, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 123ms/step - accuracy: 0.7643 - loss: 0.5168 - precision: 0.6690 - recall: 0.6065 - val_accuracy: 0.8010 - val_loss: 0.4197 - val_precision: 0.7381 - val_recall: 0.6161 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8527 - loss: 0.3673 - precision: 0.8039 - recall: 0.7367\n",
            "Epoch 2: val_loss improved from 0.41968 to 0.25376, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 65ms/step - accuracy: 0.8528 - loss: 0.3672 - precision: 0.8040 - recall: 0.7367 - val_accuracy: 0.8998 - val_loss: 0.2538 - val_precision: 0.8674 - val_recall: 0.8224 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8954 - loss: 0.2753 - precision: 0.8758 - recall: 0.8017\n",
            "Epoch 3: val_loss did not improve from 0.25376\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 63ms/step - accuracy: 0.8954 - loss: 0.2753 - precision: 0.8758 - recall: 0.8017 - val_accuracy: 0.9088 - val_loss: 0.3617 - val_precision: 0.8829 - val_recall: 0.8347 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9040 - loss: 0.2411 - precision: 0.8822 - recall: 0.8240\n",
            "Epoch 4: val_loss improved from 0.25376 to 0.18040, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 66ms/step - accuracy: 0.9041 - loss: 0.2411 - precision: 0.8822 - recall: 0.8240 - val_accuracy: 0.9314 - val_loss: 0.1804 - val_precision: 0.9167 - val_recall: 0.8716 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9224 - loss: 0.2262 - precision: 0.9171 - recall: 0.8432\n",
            "Epoch 5: val_loss did not improve from 0.18040\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 62ms/step - accuracy: 0.9224 - loss: 0.2261 - precision: 0.9171 - recall: 0.8432 - val_accuracy: 0.9282 - val_loss: 0.3087 - val_precision: 0.9195 - val_recall: 0.8579 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9354 - loss: 0.1779 - precision: 0.9308 - recall: 0.8675\n",
            "Epoch 6: val_loss improved from 0.18040 to 0.15026, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 66ms/step - accuracy: 0.9354 - loss: 0.1779 - precision: 0.9308 - recall: 0.8675 - val_accuracy: 0.9517 - val_loss: 0.1503 - val_precision: 0.9275 - val_recall: 0.9262 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9377 - loss: 0.1780 - precision: 0.9335 - recall: 0.8726\n",
            "Epoch 7: val_loss did not improve from 0.15026\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 63ms/step - accuracy: 0.9377 - loss: 0.1780 - precision: 0.9335 - recall: 0.8726 - val_accuracy: 0.8940 - val_loss: 1.0432 - val_precision: 0.8190 - val_recall: 0.8716 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9465 - loss: 0.1576 - precision: 0.9486 - recall: 0.8854\n",
            "Epoch 8: val_loss improved from 0.15026 to 0.13375, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 66ms/step - accuracy: 0.9464 - loss: 0.1577 - precision: 0.9486 - recall: 0.8854 - val_accuracy: 0.9526 - val_loss: 0.1338 - val_precision: 0.9686 - val_recall: 0.8852 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9523 - loss: 0.1428 - precision: 0.9490 - recall: 0.9076\n",
            "Epoch 9: val_loss did not improve from 0.13375\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 62ms/step - accuracy: 0.9523 - loss: 0.1428 - precision: 0.9490 - recall: 0.9075 - val_accuracy: 0.9544 - val_loss: 0.1489 - val_precision: 0.9922 - val_recall: 0.8689 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9535 - loss: 0.1472 - precision: 0.9545 - recall: 0.9024\n",
            "Epoch 10: val_loss improved from 0.13375 to 0.09569, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 65ms/step - accuracy: 0.9535 - loss: 0.1472 - precision: 0.9545 - recall: 0.9024 - val_accuracy: 0.9711 - val_loss: 0.0957 - val_precision: 0.9785 - val_recall: 0.9331 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - accuracy: 0.9536 - loss: 0.1385 - precision: 0.9525 - recall: 0.8979\n",
            "Fold 2\n",
            "Epoch 1/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7742 - loss: 0.4818 - precision: 0.6874 - recall: 0.6285\n",
            "Epoch 1: val_loss improved from inf to 0.38144, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 122ms/step - accuracy: 0.7742 - loss: 0.4817 - precision: 0.6874 - recall: 0.6285 - val_accuracy: 0.8908 - val_loss: 0.3814 - val_precision: 0.8468 - val_recall: 0.8264 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8660 - loss: 0.3237 - precision: 0.8325 - recall: 0.7500\n",
            "Epoch 2: val_loss improved from 0.38144 to 0.27679, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 65ms/step - accuracy: 0.8660 - loss: 0.3237 - precision: 0.8325 - recall: 0.7500 - val_accuracy: 0.8885 - val_loss: 0.2768 - val_precision: 0.9614 - val_recall: 0.6983 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8970 - loss: 0.2611 - precision: 0.8784 - recall: 0.8075\n",
            "Epoch 3: val_loss did not improve from 0.27679\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 63ms/step - accuracy: 0.8970 - loss: 0.2611 - precision: 0.8784 - recall: 0.8075 - val_accuracy: 0.9310 - val_loss: 0.4859 - val_precision: 0.9027 - val_recall: 0.8919 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9219 - loss: 0.2111 - precision: 0.9221 - recall: 0.8409\n",
            "Epoch 4: val_loss improved from 0.27679 to 0.27034, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 65ms/step - accuracy: 0.9219 - loss: 0.2111 - precision: 0.9220 - recall: 0.8409 - val_accuracy: 0.9264 - val_loss: 0.2703 - val_precision: 0.9949 - val_recall: 0.7864 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9262 - loss: 0.2136 - precision: 0.9224 - recall: 0.8502\n",
            "Epoch 5: val_loss did not improve from 0.27034\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 63ms/step - accuracy: 0.9262 - loss: 0.2136 - precision: 0.9224 - recall: 0.8502 - val_accuracy: 0.9269 - val_loss: 0.7592 - val_precision: 0.9211 - val_recall: 0.8571 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9378 - loss: 0.1766 - precision: 0.9327 - recall: 0.8743\n",
            "Epoch 6: val_loss did not improve from 0.27034\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - accuracy: 0.9378 - loss: 0.1766 - precision: 0.9327 - recall: 0.8742 - val_accuracy: 0.9310 - val_loss: 0.5129 - val_precision: 0.9150 - val_recall: 0.8772 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9463 - loss: 0.1602 - precision: 0.9534 - recall: 0.8782\n",
            "Epoch 7: val_loss improved from 0.27034 to 0.14642, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 66ms/step - accuracy: 0.9463 - loss: 0.1602 - precision: 0.9534 - recall: 0.8782 - val_accuracy: 0.9517 - val_loss: 0.1464 - val_precision: 0.9169 - val_recall: 0.9426 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9485 - loss: 0.1544 - precision: 0.9510 - recall: 0.8917\n",
            "Epoch 8: val_loss improved from 0.14642 to 0.10991, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 71ms/step - accuracy: 0.9485 - loss: 0.1544 - precision: 0.9510 - recall: 0.8917 - val_accuracy: 0.9603 - val_loss: 0.1099 - val_precision: 0.9839 - val_recall: 0.8972 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9507 - loss: 0.1472 - precision: 0.9478 - recall: 0.8991\n",
            "Epoch 9: val_loss improved from 0.10991 to 0.10013, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 66ms/step - accuracy: 0.9507 - loss: 0.1472 - precision: 0.9478 - recall: 0.8992 - val_accuracy: 0.9666 - val_loss: 0.1001 - val_precision: 0.9734 - val_recall: 0.9266 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9503 - loss: 0.1404 - precision: 0.9516 - recall: 0.8981\n",
            "Epoch 10: val_loss did not improve from 0.10013\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 63ms/step - accuracy: 0.9504 - loss: 0.1404 - precision: 0.9516 - recall: 0.8981 - val_accuracy: 0.9490 - val_loss: 0.2167 - val_precision: 0.8936 - val_recall: 0.9640 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.9479 - loss: 0.1469 - precision: 0.9414 - recall: 0.8901\n",
            "Fold 3\n",
            "Epoch 1/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7805 - loss: 0.4910 - precision: 0.6996 - recall: 0.6021\n",
            "Epoch 1: val_loss improved from inf to 0.35173, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 124ms/step - accuracy: 0.7805 - loss: 0.4910 - precision: 0.6997 - recall: 0.6022 - val_accuracy: 0.8412 - val_loss: 0.3517 - val_precision: 0.9461 - val_recall: 0.5621 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8755 - loss: 0.3127 - precision: 0.8452 - recall: 0.7663\n",
            "Epoch 2: val_loss did not improve from 0.35173\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 64ms/step - accuracy: 0.8755 - loss: 0.3127 - precision: 0.8453 - recall: 0.7663 - val_accuracy: 0.9116 - val_loss: 0.4434 - val_precision: 0.8956 - val_recall: 0.8358 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9047 - loss: 0.2530 - precision: 0.8848 - recall: 0.8160\n",
            "Epoch 3: val_loss did not improve from 0.35173\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 63ms/step - accuracy: 0.9047 - loss: 0.2530 - precision: 0.8848 - recall: 0.8160 - val_accuracy: 0.9269 - val_loss: 0.6451 - val_precision: 0.9093 - val_recall: 0.8705 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9193 - loss: 0.2133 - precision: 0.9061 - recall: 0.8439\n",
            "Epoch 4: val_loss improved from 0.35173 to 0.15416, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 67ms/step - accuracy: 0.9193 - loss: 0.2133 - precision: 0.9061 - recall: 0.8439 - val_accuracy: 0.9422 - val_loss: 0.1542 - val_precision: 0.9829 - val_recall: 0.8438 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9277 - loss: 0.1938 - precision: 0.9249 - recall: 0.8493\n",
            "Epoch 5: val_loss did not improve from 0.15416\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - accuracy: 0.9278 - loss: 0.1938 - precision: 0.9249 - recall: 0.8493 - val_accuracy: 0.9422 - val_loss: 0.1767 - val_precision: 0.9740 - val_recall: 0.8518 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9450 - loss: 0.1621 - precision: 0.9482 - recall: 0.8833\n",
            "Epoch 6: val_loss did not improve from 0.15416\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 63ms/step - accuracy: 0.9449 - loss: 0.1621 - precision: 0.9482 - recall: 0.8833 - val_accuracy: 0.9468 - val_loss: 0.4018 - val_precision: 0.9437 - val_recall: 0.8959 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9445 - loss: 0.1579 - precision: 0.9447 - recall: 0.8825\n",
            "Epoch 7: val_loss improved from 0.15416 to 0.14303, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 76ms/step - accuracy: 0.9445 - loss: 0.1580 - precision: 0.9447 - recall: 0.8825 - val_accuracy: 0.9648 - val_loss: 0.1430 - val_precision: 0.9732 - val_recall: 0.9212 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9485 - loss: 0.1526 - precision: 0.9438 - recall: 0.8966\n",
            "Epoch 8: val_loss improved from 0.14303 to 0.11166, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 74ms/step - accuracy: 0.9485 - loss: 0.1526 - precision: 0.9438 - recall: 0.8966 - val_accuracy: 0.9607 - val_loss: 0.1117 - val_precision: 0.9839 - val_recall: 0.8985 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9507 - loss: 0.1382 - precision: 0.9438 - recall: 0.9012\n",
            "Epoch 9: val_loss did not improve from 0.11166\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 63ms/step - accuracy: 0.9507 - loss: 0.1382 - precision: 0.9438 - recall: 0.9011 - val_accuracy: 0.9508 - val_loss: 1.2546 - val_precision: 0.9124 - val_recall: 0.9453 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9511 - loss: 0.1394 - precision: 0.9514 - recall: 0.9005\n",
            "Epoch 10: val_loss did not improve from 0.11166\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.9511 - loss: 0.1394 - precision: 0.9514 - recall: 0.9005 - val_accuracy: 0.9535 - val_loss: 0.1293 - val_precision: 0.9969 - val_recall: 0.8652 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.9477 - loss: 0.1502 - precision: 0.9617 - recall: 0.8701\n",
            "Fold 4\n",
            "Epoch 1/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7725 - loss: 0.4992 - precision: 0.6884 - recall: 0.5755\n",
            "Epoch 1: val_loss improved from inf to 0.33105, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 126ms/step - accuracy: 0.7726 - loss: 0.4991 - precision: 0.6885 - recall: 0.5756 - val_accuracy: 0.8723 - val_loss: 0.3310 - val_precision: 0.8042 - val_recall: 0.8204 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8727 - loss: 0.3148 - precision: 0.8289 - recall: 0.7661\n",
            "Epoch 2: val_loss did not improve from 0.33105\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 64ms/step - accuracy: 0.8727 - loss: 0.3148 - precision: 0.8289 - recall: 0.7661 - val_accuracy: 0.8967 - val_loss: 2.0369 - val_precision: 0.8211 - val_recall: 0.8861 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9046 - loss: 0.2543 - precision: 0.8976 - recall: 0.8127\n",
            "Epoch 3: val_loss improved from 0.33105 to 0.18561, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 66ms/step - accuracy: 0.9046 - loss: 0.2543 - precision: 0.8976 - recall: 0.8127 - val_accuracy: 0.9346 - val_loss: 0.1856 - val_precision: 0.9275 - val_recall: 0.8740 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9150 - loss: 0.2288 - precision: 0.8962 - recall: 0.8386\n",
            "Epoch 4: val_loss did not improve from 0.18561\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 64ms/step - accuracy: 0.9150 - loss: 0.2288 - precision: 0.8962 - recall: 0.8386 - val_accuracy: 0.9084 - val_loss: 0.8784 - val_precision: 0.8512 - val_recall: 0.8820 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9310 - loss: 0.2006 - precision: 0.9243 - recall: 0.8587\n",
            "Epoch 5: val_loss did not improve from 0.18561\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 64ms/step - accuracy: 0.9310 - loss: 0.2005 - precision: 0.9243 - recall: 0.8587 - val_accuracy: 0.8858 - val_loss: 0.7289 - val_precision: 0.8002 - val_recall: 0.8807 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9355 - loss: 0.1801 - precision: 0.9370 - recall: 0.8651\n",
            "Epoch 6: val_loss improved from 0.18561 to 0.14607, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 68ms/step - accuracy: 0.9355 - loss: 0.1801 - precision: 0.9370 - recall: 0.8651 - val_accuracy: 0.9499 - val_loss: 0.1461 - val_precision: 0.9529 - val_recall: 0.8954 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9480 - loss: 0.1560 - precision: 0.9476 - recall: 0.8910\n",
            "Epoch 7: val_loss improved from 0.14607 to 0.12339, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 73ms/step - accuracy: 0.9480 - loss: 0.1560 - precision: 0.9476 - recall: 0.8909 - val_accuracy: 0.9625 - val_loss: 0.1234 - val_precision: 0.9825 - val_recall: 0.9048 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9441 - loss: 0.1634 - precision: 0.9361 - recall: 0.8912\n",
            "Epoch 8: val_loss improved from 0.12339 to 0.10716, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 77ms/step - accuracy: 0.9441 - loss: 0.1633 - precision: 0.9362 - recall: 0.8912 - val_accuracy: 0.9662 - val_loss: 0.1072 - val_precision: 0.9772 - val_recall: 0.9209 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9462 - loss: 0.1576 - precision: 0.9467 - recall: 0.8872\n",
            "Epoch 9: val_loss did not improve from 0.10716\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 64ms/step - accuracy: 0.9462 - loss: 0.1576 - precision: 0.9467 - recall: 0.8872 - val_accuracy: 0.9508 - val_loss: 0.1443 - val_precision: 0.9417 - val_recall: 0.9102 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9545 - loss: 0.1338 - precision: 0.9567 - recall: 0.9013\n",
            "Epoch 10: val_loss did not improve from 0.10716\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.9545 - loss: 0.1338 - precision: 0.9567 - recall: 0.9013 - val_accuracy: 0.9328 - val_loss: 0.2559 - val_precision: 0.9671 - val_recall: 0.8284 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.9519 - loss: 0.1414 - precision: 0.9634 - recall: 0.8821\n",
            "Fold 5\n",
            "Epoch 1/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7853 - loss: 0.4870 - precision: 0.7037 - recall: 0.6242\n",
            "Epoch 1: val_loss improved from inf to 0.31337, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 126ms/step - accuracy: 0.7854 - loss: 0.4869 - precision: 0.7037 - recall: 0.6243 - val_accuracy: 0.8804 - val_loss: 0.3134 - val_precision: 0.8268 - val_recall: 0.7981 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8603 - loss: 0.3367 - precision: 0.8142 - recall: 0.7569\n",
            "Epoch 2: val_loss improved from 0.31337 to 0.22909, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 69ms/step - accuracy: 0.8603 - loss: 0.3367 - precision: 0.8142 - recall: 0.7569 - val_accuracy: 0.9116 - val_loss: 0.2291 - val_precision: 0.8861 - val_recall: 0.8343 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8976 - loss: 0.2582 - precision: 0.8697 - recall: 0.8139\n",
            "Epoch 3: val_loss did not improve from 0.22909\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 63ms/step - accuracy: 0.8976 - loss: 0.2582 - precision: 0.8697 - recall: 0.8139 - val_accuracy: 0.8858 - val_loss: 1.0386 - val_precision: 0.8155 - val_recall: 0.8370 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9133 - loss: 0.2330 - precision: 0.9075 - recall: 0.8249\n",
            "Epoch 4: val_loss did not improve from 0.22909\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 64ms/step - accuracy: 0.9133 - loss: 0.2329 - precision: 0.9075 - recall: 0.8249 - val_accuracy: 0.8615 - val_loss: 2.0826 - val_precision: 0.7618 - val_recall: 0.8329 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9109 - loss: 0.2205 - precision: 0.8988 - recall: 0.8306\n",
            "Epoch 5: val_loss did not improve from 0.22909\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - accuracy: 0.9109 - loss: 0.2205 - precision: 0.8989 - recall: 0.8306 - val_accuracy: 0.9183 - val_loss: 0.6285 - val_precision: 0.8819 - val_recall: 0.8635 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9396 - loss: 0.1763 - precision: 0.9436 - recall: 0.8700\n",
            "Epoch 6: val_loss improved from 0.22909 to 0.16564, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 79ms/step - accuracy: 0.9396 - loss: 0.1763 - precision: 0.9436 - recall: 0.8700 - val_accuracy: 0.9440 - val_loss: 0.1656 - val_precision: 0.9569 - val_recall: 0.8663 - learning_rate: 5.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9445 - loss: 0.1594 - precision: 0.9480 - recall: 0.8882\n",
            "Epoch 7: val_loss improved from 0.16564 to 0.13855, saving model to best_model.keras\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 79ms/step - accuracy: 0.9445 - loss: 0.1594 - precision: 0.9480 - recall: 0.8882 - val_accuracy: 0.9486 - val_loss: 0.1385 - val_precision: 0.9218 - val_recall: 0.9192 - learning_rate: 5.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9494 - loss: 0.1503 - precision: 0.9572 - recall: 0.8887\n",
            "Epoch 8: val_loss did not improve from 0.13855\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 64ms/step - accuracy: 0.9494 - loss: 0.1503 - precision: 0.9572 - recall: 0.8887 - val_accuracy: 0.9364 - val_loss: 0.4342 - val_precision: 0.8893 - val_recall: 0.9178 - learning_rate: 5.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9565 - loss: 0.1368 - precision: 0.9564 - recall: 0.9103\n",
            "Epoch 9: val_loss did not improve from 0.13855\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 64ms/step - accuracy: 0.9565 - loss: 0.1368 - precision: 0.9564 - recall: 0.9103 - val_accuracy: 0.9531 - val_loss: 0.3607 - val_precision: 0.9264 - val_recall: 0.9290 - learning_rate: 5.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m692/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9575 - loss: 0.1243 - precision: 0.9604 - recall: 0.9113\n",
            "Epoch 10: val_loss did not improve from 0.13855\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 64ms/step - accuracy: 0.9575 - loss: 0.1244 - precision: 0.9604 - recall: 0.9113 - val_accuracy: 0.9391 - val_loss: 0.2783 - val_precision: 0.9370 - val_recall: 0.8705 - learning_rate: 5.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9487 - loss: 0.1587 - precision: 0.9314 - recall: 0.9066\n",
            "Average Accuracy: 0.8931\n",
            "Average Recall: 0.9490\n",
            "Average Precision: 0.9512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_inception = load_model(\"best_model.keras\",\n",
        "                        custom_objects={'Precision': Precision, 'Recall': Recall})\n",
        "\n",
        "results = best_inception.evaluate(X_test, y_test, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIuraJu-PGqR",
        "outputId": "c44cce3a-1f69-44f2-d112-c69ce3599278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.9487 - loss: 0.1587 - precision: 0.9314 - recall: 0.9066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## California Case - Bimo"
      ],
      "metadata": {
        "id": "4mX98G9lpJV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_cal = np.load(\"/content/drive/MyDrive/cal_fires_128x128.npz\")\n",
        "X_cal, y_cal = data_cal['X_data'], data_cal['y_data']"
      ],
      "metadata": {
        "id": "NQHGNSTPpORU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize to (32, 32, 3) to match model input\n",
        "X_cal_ready = tf.image.resize(X_cal, [32, 32]).numpy()\n"
      ],
      "metadata": {
        "id": "tsWXQNSvsTZI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "# Load model with custom_objects\n",
        "model = load_model('/content/drive/MyDrive/best_cnn_model.keras',\n",
        "                   custom_objects={'recall': Recall(), 'precision': Precision()})\n",
        "\n",
        "# Recompile loaded model in terms for evaluation\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', Recall(name='recall'), Precision(name='precision')])\n",
        "\n",
        "# Evaluate in California Y\n",
        "results = model.evaluate(X_cal_ready, y_cal, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluation Matrices\n",
        "print(f\"\\nAccuracy : {results[1]:.4f}\")\n",
        "print(f\"Recall   : {results[2]:.4f}\")\n",
        "print(f\"Precision: {results[3]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXi2ZmabqI3E",
        "outputId": "d530f760-c114-4a98-c875-0a29ca0beb29"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7446 - loss: 2.5692 - precision: 0.7085 - recall: 0.8086\n",
            "\n",
            "Accuracy : 0.7167\n",
            "Recall   : 0.8393\n",
            "Precision: 0.6528\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JrqyBN0tGNPC",
        "DKgbUvu-GTkh",
        "GmupddkdGX-k",
        "_3a03WfHLhfu",
        "kieVUtDM7fvI"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}